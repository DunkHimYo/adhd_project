{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb의 사본의 사본의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cECpWuNOa-0Q"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "control=[]\n",
        "adhd=[]\n",
        "for i in range(19):\n",
        "    b=[]\n",
        "    for j in os.listdir(f'./drive/MyDrive/psd_corr/ADHD/{i}'):\n",
        "        b.append(pd.read_csv(f'./drive/MyDrive/psd_corr/ADHD/{i}/'+j,index_col='Unnamed: 0').to_numpy())\n",
        "    adhd.append(b)\n",
        "    \n",
        "for i in range(19):\n",
        "    b=[]    \n",
        "    for j in os.listdir(f'./drive/MyDrive/psd_corr/Control/{i}'):\n",
        "        b.append(pd.read_csv(f'./drive/MyDrive/psd_corr/Control/{i}/'+j,index_col='Unnamed: 0').to_numpy())\n",
        "    control.append(b)\n",
        "    \n",
        "control= np.array(control).transpose(1,0,2,3)\n",
        "adhd=np.array(adhd).transpose(1,0,2,3)\n",
        "\n",
        "x=np.append(adhd,control,axis=0)\n",
        "y=np.array([1]*61+[0]*60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex8uYJ5FHvvZ"
      },
      "source": [
        "def crop(dimension, start, end):\n",
        "    # Crops (or slices) a Tensor on a given dimension from start to end\n",
        "    # example : to crop tensor x[:, :, 5:10]\n",
        "    # call slice(2, 5, 10) as you want to crop on the second dimension\n",
        "    def func(x):\n",
        "        if dimension == 0:\n",
        "            return x[start: end]\n",
        "        if dimension == 1:\n",
        "            return x[:, start: end]\n",
        "        if dimension == 2:\n",
        "            return x[:, :, start: end]\n",
        "        if dimension == 3:\n",
        "            return x[:, :, :, start: end]\n",
        "        if dimension == 4:\n",
        "            return x[:, :, :, :, start: end]\n",
        "    return Lambda(func)\n",
        "import math\n",
        "def slice_model(model_input,unit,row_num,col_num,term):\n",
        "  remain=math.ceil(unit/2)\n",
        "  return [crop(3,col_num-(j+unit),col_num-j)(crop(2,row_num-(i+unit),row_num-i)(model_input)) for i in range(0,row_num-unit+1,term) for j in range(0,col_num-unit+1,term)]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7qqXdEjg6OP"
      },
      "source": [
        "import sys\n",
        "import sys\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, GlobalMaxPooling3D,Lambda,concatenate,Conv3D, MaxPooling3D,GlobalAveragePooling3D\n",
        "from tensorflow.keras.regularizers import l1,l2\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "def mk_model(filepath=None):\n",
        "    \n",
        "    FILTER_SIZE=3\n",
        "    NUM_FILTERS=16\n",
        "    INPUT_SIZE=19\n",
        "    MAXPOOL_SIZE=2\n",
        "    BATCH_SIZE=3\n",
        "    STEPS_PER_EPOCH=48//BATCH_SIZE\n",
        "    EPOCHS=1000\n",
        "    densors=[]\n",
        "    model_input=Input(shape=(19,INPUT_SIZE,INPUT_SIZE,1))\n",
        "    print(model_input.shape)\n",
        "    for idx in slice_model(model_input,3,19,19,2):\n",
        "            model_output=Conv3D(NUM_FILTERS, (FILTER_SIZE,FILTER_SIZE,FILTER_SIZE),activation='relu')(idx)\n",
        "            model_output=Dropout(0.5)(model_output)                        \n",
        "            model_output=GlobalMaxPooling3D()(model_output)\n",
        "            densors.append(model_output)\n",
        "\n",
        "    model_output=concatenate(densors)\n",
        "    model_output=Dense(units=512,activation='relu')(model_output)\n",
        "    model_output=Dense(units=512,activation='relu')(model_output)\n",
        "    model_output=Dense(units=512,activation='relu',kernel_regularizer=l1(0.01))(model_output)\n",
        "\n",
        "\n",
        "    model_output=Dense(units=1,activation='sigmoid')(model_output)\n",
        "    model = Model(inputs = model_input, outputs = model_output)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3_Wxk0KWV7Bq",
        "outputId": "161e4a82-0bc4-4630-e698-1fdbb821593d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "\n",
        "x_tra,x_test,y_tra,y_test=train_test_split(x,y,train_size=0.8,stratify=y,random_state=128)\n",
        "\n",
        "kf=KFold(7,True )\n",
        "train_score=[]\n",
        "test_score=[]\n",
        "val_score=[]\n",
        "test_list=[]\n",
        "\n",
        "idx=0\n",
        "\n",
        "val_list=[]\n",
        "\n",
        "for train_index, test_index in kf.split(x_tra):\n",
        "    callback_list = [\n",
        "    EarlyStopping( #성능 향상이 멈추면 훈련을 중지\n",
        "    monitor='val_loss',  #모델 검증 정확도를 모니터링\n",
        "    patience=50        #1 에포크 보다 더 길게(즉, 2에포크 동안 정확도가 향상되지 않으면 훈련 중지\n",
        "),\n",
        "    ModelCheckpoint( #에포크마다 현재 가중치를 저장\n",
        "    filepath=f'./mod{idx}.h5', #모델 파일 경로\n",
        "    monitor='val_loss',  # val_loss 가 좋아지지 않으면 모델 파일을 덮어쓰지 않음.\n",
        "    save_best_only=True,\n",
        "    mode='auto',\n",
        "    verbose=1\n",
        ")\n",
        "]\n",
        "    x_train,x_val=x_tra[train_index],x_tra[test_index]\n",
        "    y_train,y_val=y_tra[train_index],y_tra[test_index]\n",
        "    \n",
        "    #with strategy.scope():\n",
        "    model=mk_model()\n",
        "    print(model.summary())\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n",
        "    hist=model.fit(x_train, y_train, epochs=200, validation_data=(x_val, y_val),batch_size=36,callbacks=callback_list)\n",
        "    \n",
        "    \n",
        "    plt.plot(hist.history['loss'],label='train'+str(idx))\n",
        "    plt.plot(hist.history['val_loss'],label='train'+str(idx))\n",
        "    plt.title('loss',fontsize=15)\n",
        "    plt.legend(['train','val'])\n",
        "    plt.show()\n",
        "    plt.plot(hist.history['accuracy'],label='train'+str(idx))\n",
        "    plt.plot(hist.history['val_accuracy'],label='train'+str(idx))\n",
        "    plt.legend(['train','val'])\n",
        "    plt.title('acc',fontsize=15)\n",
        "    plt.show()\n",
        "    model=load_model(f'./mod{idx}.h5')\n",
        "    \n",
        "    train_score.append(model.evaluate(x_train,y_train))\n",
        "    test_score.append(model.evaluate(x_test,y_test))\n",
        "    val_score.append(model.evaluate(x_val,y_val))\n",
        "    idx+=1\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 19, 19, 19, 1)\n",
            "Model: \"model_20\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_22 (InputLayer)           [(None, 19, 19, 19,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2969 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2971 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2973 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2975 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2977 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2979 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2981 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2983 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2985 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2987 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2989 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2991 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2993 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2995 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2997 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2999 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3001 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3003 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3005 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3007 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3009 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3011 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3013 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3015 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3017 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3019 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3021 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3023 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3025 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3027 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3029 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3031 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3033 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3035 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3037 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3039 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3041 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3043 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3045 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3047 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3049 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3051 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3053 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3055 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3057 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3059 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3061 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3063 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3065 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3067 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3069 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3071 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3073 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3075 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3077 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3079 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3081 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3083 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3085 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3087 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3089 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3091 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3093 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3095 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3097 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3099 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3101 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3103 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3105 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3107 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3109 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3111 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3113 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3115 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3117 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3119 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3121 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3123 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3125 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3127 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3129 (Lambda)            (None, 19, 3, 19, 1) 0           input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2968 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2969[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2970 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2971[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2972 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2973[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2974 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2975[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2976 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2977[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2978 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2979[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2980 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2981[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2982 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2983[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2984 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2985[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2986 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2987[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2988 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2989[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2990 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2991[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2992 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2993[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2994 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2995[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2996 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2997[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2998 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_2999[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3000 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3001[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3002 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3003[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3004 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3005[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3006 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3007[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3008 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3009[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3010 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3011[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3012 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3013[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3014 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3015[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3016 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3017[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3018 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3019[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3020 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3021[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3022 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3023[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3024 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3025[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3026 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3027[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3028 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3029[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3030 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3031[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3032 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3033[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3034 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3035[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3036 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3037[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3038 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3039[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3040 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3041[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3042 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3043[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3044 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3045[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3046 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3047[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3048 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3049[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3050 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3051[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3052 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3053[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3054 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3055[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3056 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3057[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3058 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3059[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3060 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3061[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3062 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3063[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3064 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3065[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3066 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3067[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3068 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3069[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3070 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3071[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3072 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3073[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3074 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3075[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3076 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3077[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3078 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3079[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3080 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3081[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3082 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3083[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3084 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3085[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3086 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3087[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3088 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3089[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3090 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3091[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3092 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3093[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3094 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3095[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3096 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3097[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3098 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3099[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3100 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3101[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3102 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3103[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3104 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3105[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3106 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3107[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3108 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3109[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3110 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3111[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3112 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3113[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3114 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3115[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3116 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3117[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3118 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3119[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3120 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3121[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3122 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3123[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3124 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3125[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3126 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3127[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3128 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3129[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1484 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2968[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1485 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2970[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1486 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2972[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1487 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2974[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1488 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2976[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1489 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2978[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1490 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2980[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1491 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2982[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1492 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2984[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1493 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2986[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1494 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2988[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1495 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2990[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1496 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2992[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1497 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2994[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1498 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2996[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1499 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_2998[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1500 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3000[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1501 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3002[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1502 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3004[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1503 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3006[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1504 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3008[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1505 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3010[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1506 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3012[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1507 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3014[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1508 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3016[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1509 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3018[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1510 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3020[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1511 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3022[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1512 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3024[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1513 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3026[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1514 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3028[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1515 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3030[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1516 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3032[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1517 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3034[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1518 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3036[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1519 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3038[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1520 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3040[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1521 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3042[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1522 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3044[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1523 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3046[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1524 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3048[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1525 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3050[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1526 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3052[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1527 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3054[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1528 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3056[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1529 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3058[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1530 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3060[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1531 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3062[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1532 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3064[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1533 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3066[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1534 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3068[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1535 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3070[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1536 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3072[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1537 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3074[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1538 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3076[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1539 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3078[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1540 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3080[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1541 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3082[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1542 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3084[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1543 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3086[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1544 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3088[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1545 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3090[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1546 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3092[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1547 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3094[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1548 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3096[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1549 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3098[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1550 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3100[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1551 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3102[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1552 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3104[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1553 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3106[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1554 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3108[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1555 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3110[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1556 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3112[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1557 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3114[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1558 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3116[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1559 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3118[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1560 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3120[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1561 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3122[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1562 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3124[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1563 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3126[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1564 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3128[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1484 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1484[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1485 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1485[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1486 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1486[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1487 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1487[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1488 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1488[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1489 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1489[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1490 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1490[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1491 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1491[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1492 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1492[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1493 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1493[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1494 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1494[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1495 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1495[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1496 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1496[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1497 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1497[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1498 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1498[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1499 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1499[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1500 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1500[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1501 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1501[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1502 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1502[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1503 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1503[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1504 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1504[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1505 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1505[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1506 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1506[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1507 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1507[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1508 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1508[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1509 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1509[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1510 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1510[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1511 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1511[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1512 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1512[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1513 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1513[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1514 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1514[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1515 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1515[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1516 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1516[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1517 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1517[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1518 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1518[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1519 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1519[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1520 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1520[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1521 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1521[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1522 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1522[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1523 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1523[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1524 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1524[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1525 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1525[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1526 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1526[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1527 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1527[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1528 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1528[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1529 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1529[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1530 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1530[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1531 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1531[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1532 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1532[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1533 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1533[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1534 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1534[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1535 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1535[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1536 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1536[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1537 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1537[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1538 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1538[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1539 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1539[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1540 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1540[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1541 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1541[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1542 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1542[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1543 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1543[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1544 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1544[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1545 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1545[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1546 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1546[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1547 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1547[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1548 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1548[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1549 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1549[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1550 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1550[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1551 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1551[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1552 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1552[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1553 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1553[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1554 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1554[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1555 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1555[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1556 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1556[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1557 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1557[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1558 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1558[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1559 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1559[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1560 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1560[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1561 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1561[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1562 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1562[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1563 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1563[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1564 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1564[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1032 (Glob (None, 16)           0           dropout_1484[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1033 (Glob (None, 16)           0           dropout_1485[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1034 (Glob (None, 16)           0           dropout_1486[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1035 (Glob (None, 16)           0           dropout_1487[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1036 (Glob (None, 16)           0           dropout_1488[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1037 (Glob (None, 16)           0           dropout_1489[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1038 (Glob (None, 16)           0           dropout_1490[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1039 (Glob (None, 16)           0           dropout_1491[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1040 (Glob (None, 16)           0           dropout_1492[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1041 (Glob (None, 16)           0           dropout_1493[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1042 (Glob (None, 16)           0           dropout_1494[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1043 (Glob (None, 16)           0           dropout_1495[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1044 (Glob (None, 16)           0           dropout_1496[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1045 (Glob (None, 16)           0           dropout_1497[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1046 (Glob (None, 16)           0           dropout_1498[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1047 (Glob (None, 16)           0           dropout_1499[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1048 (Glob (None, 16)           0           dropout_1500[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1049 (Glob (None, 16)           0           dropout_1501[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1050 (Glob (None, 16)           0           dropout_1502[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1051 (Glob (None, 16)           0           dropout_1503[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1052 (Glob (None, 16)           0           dropout_1504[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1053 (Glob (None, 16)           0           dropout_1505[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1054 (Glob (None, 16)           0           dropout_1506[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1055 (Glob (None, 16)           0           dropout_1507[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1056 (Glob (None, 16)           0           dropout_1508[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1057 (Glob (None, 16)           0           dropout_1509[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1058 (Glob (None, 16)           0           dropout_1510[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1059 (Glob (None, 16)           0           dropout_1511[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1060 (Glob (None, 16)           0           dropout_1512[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1061 (Glob (None, 16)           0           dropout_1513[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1062 (Glob (None, 16)           0           dropout_1514[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1063 (Glob (None, 16)           0           dropout_1515[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1064 (Glob (None, 16)           0           dropout_1516[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1065 (Glob (None, 16)           0           dropout_1517[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1066 (Glob (None, 16)           0           dropout_1518[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1067 (Glob (None, 16)           0           dropout_1519[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1068 (Glob (None, 16)           0           dropout_1520[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1069 (Glob (None, 16)           0           dropout_1521[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1070 (Glob (None, 16)           0           dropout_1522[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1071 (Glob (None, 16)           0           dropout_1523[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1072 (Glob (None, 16)           0           dropout_1524[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1073 (Glob (None, 16)           0           dropout_1525[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1074 (Glob (None, 16)           0           dropout_1526[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1075 (Glob (None, 16)           0           dropout_1527[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1076 (Glob (None, 16)           0           dropout_1528[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1077 (Glob (None, 16)           0           dropout_1529[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1078 (Glob (None, 16)           0           dropout_1530[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1079 (Glob (None, 16)           0           dropout_1531[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1080 (Glob (None, 16)           0           dropout_1532[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1081 (Glob (None, 16)           0           dropout_1533[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1082 (Glob (None, 16)           0           dropout_1534[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1083 (Glob (None, 16)           0           dropout_1535[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1084 (Glob (None, 16)           0           dropout_1536[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1085 (Glob (None, 16)           0           dropout_1537[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1086 (Glob (None, 16)           0           dropout_1538[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1087 (Glob (None, 16)           0           dropout_1539[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1088 (Glob (None, 16)           0           dropout_1540[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1089 (Glob (None, 16)           0           dropout_1541[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1090 (Glob (None, 16)           0           dropout_1542[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1091 (Glob (None, 16)           0           dropout_1543[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1092 (Glob (None, 16)           0           dropout_1544[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1093 (Glob (None, 16)           0           dropout_1545[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1094 (Glob (None, 16)           0           dropout_1546[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1095 (Glob (None, 16)           0           dropout_1547[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1096 (Glob (None, 16)           0           dropout_1548[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1097 (Glob (None, 16)           0           dropout_1549[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1098 (Glob (None, 16)           0           dropout_1550[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1099 (Glob (None, 16)           0           dropout_1551[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1100 (Glob (None, 16)           0           dropout_1552[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1101 (Glob (None, 16)           0           dropout_1553[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1102 (Glob (None, 16)           0           dropout_1554[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1103 (Glob (None, 16)           0           dropout_1555[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1104 (Glob (None, 16)           0           dropout_1556[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1105 (Glob (None, 16)           0           dropout_1557[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1106 (Glob (None, 16)           0           dropout_1558[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1107 (Glob (None, 16)           0           dropout_1559[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1108 (Glob (None, 16)           0           dropout_1560[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1109 (Glob (None, 16)           0           dropout_1561[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1110 (Glob (None, 16)           0           dropout_1562[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1111 (Glob (None, 16)           0           dropout_1563[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1112 (Glob (None, 16)           0           dropout_1564[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 1296)         0           global_max_pooling3d_1032[0][0]  \n",
            "                                                                 global_max_pooling3d_1033[0][0]  \n",
            "                                                                 global_max_pooling3d_1034[0][0]  \n",
            "                                                                 global_max_pooling3d_1035[0][0]  \n",
            "                                                                 global_max_pooling3d_1036[0][0]  \n",
            "                                                                 global_max_pooling3d_1037[0][0]  \n",
            "                                                                 global_max_pooling3d_1038[0][0]  \n",
            "                                                                 global_max_pooling3d_1039[0][0]  \n",
            "                                                                 global_max_pooling3d_1040[0][0]  \n",
            "                                                                 global_max_pooling3d_1041[0][0]  \n",
            "                                                                 global_max_pooling3d_1042[0][0]  \n",
            "                                                                 global_max_pooling3d_1043[0][0]  \n",
            "                                                                 global_max_pooling3d_1044[0][0]  \n",
            "                                                                 global_max_pooling3d_1045[0][0]  \n",
            "                                                                 global_max_pooling3d_1046[0][0]  \n",
            "                                                                 global_max_pooling3d_1047[0][0]  \n",
            "                                                                 global_max_pooling3d_1048[0][0]  \n",
            "                                                                 global_max_pooling3d_1049[0][0]  \n",
            "                                                                 global_max_pooling3d_1050[0][0]  \n",
            "                                                                 global_max_pooling3d_1051[0][0]  \n",
            "                                                                 global_max_pooling3d_1052[0][0]  \n",
            "                                                                 global_max_pooling3d_1053[0][0]  \n",
            "                                                                 global_max_pooling3d_1054[0][0]  \n",
            "                                                                 global_max_pooling3d_1055[0][0]  \n",
            "                                                                 global_max_pooling3d_1056[0][0]  \n",
            "                                                                 global_max_pooling3d_1057[0][0]  \n",
            "                                                                 global_max_pooling3d_1058[0][0]  \n",
            "                                                                 global_max_pooling3d_1059[0][0]  \n",
            "                                                                 global_max_pooling3d_1060[0][0]  \n",
            "                                                                 global_max_pooling3d_1061[0][0]  \n",
            "                                                                 global_max_pooling3d_1062[0][0]  \n",
            "                                                                 global_max_pooling3d_1063[0][0]  \n",
            "                                                                 global_max_pooling3d_1064[0][0]  \n",
            "                                                                 global_max_pooling3d_1065[0][0]  \n",
            "                                                                 global_max_pooling3d_1066[0][0]  \n",
            "                                                                 global_max_pooling3d_1067[0][0]  \n",
            "                                                                 global_max_pooling3d_1068[0][0]  \n",
            "                                                                 global_max_pooling3d_1069[0][0]  \n",
            "                                                                 global_max_pooling3d_1070[0][0]  \n",
            "                                                                 global_max_pooling3d_1071[0][0]  \n",
            "                                                                 global_max_pooling3d_1072[0][0]  \n",
            "                                                                 global_max_pooling3d_1073[0][0]  \n",
            "                                                                 global_max_pooling3d_1074[0][0]  \n",
            "                                                                 global_max_pooling3d_1075[0][0]  \n",
            "                                                                 global_max_pooling3d_1076[0][0]  \n",
            "                                                                 global_max_pooling3d_1077[0][0]  \n",
            "                                                                 global_max_pooling3d_1078[0][0]  \n",
            "                                                                 global_max_pooling3d_1079[0][0]  \n",
            "                                                                 global_max_pooling3d_1080[0][0]  \n",
            "                                                                 global_max_pooling3d_1081[0][0]  \n",
            "                                                                 global_max_pooling3d_1082[0][0]  \n",
            "                                                                 global_max_pooling3d_1083[0][0]  \n",
            "                                                                 global_max_pooling3d_1084[0][0]  \n",
            "                                                                 global_max_pooling3d_1085[0][0]  \n",
            "                                                                 global_max_pooling3d_1086[0][0]  \n",
            "                                                                 global_max_pooling3d_1087[0][0]  \n",
            "                                                                 global_max_pooling3d_1088[0][0]  \n",
            "                                                                 global_max_pooling3d_1089[0][0]  \n",
            "                                                                 global_max_pooling3d_1090[0][0]  \n",
            "                                                                 global_max_pooling3d_1091[0][0]  \n",
            "                                                                 global_max_pooling3d_1092[0][0]  \n",
            "                                                                 global_max_pooling3d_1093[0][0]  \n",
            "                                                                 global_max_pooling3d_1094[0][0]  \n",
            "                                                                 global_max_pooling3d_1095[0][0]  \n",
            "                                                                 global_max_pooling3d_1096[0][0]  \n",
            "                                                                 global_max_pooling3d_1097[0][0]  \n",
            "                                                                 global_max_pooling3d_1098[0][0]  \n",
            "                                                                 global_max_pooling3d_1099[0][0]  \n",
            "                                                                 global_max_pooling3d_1100[0][0]  \n",
            "                                                                 global_max_pooling3d_1101[0][0]  \n",
            "                                                                 global_max_pooling3d_1102[0][0]  \n",
            "                                                                 global_max_pooling3d_1103[0][0]  \n",
            "                                                                 global_max_pooling3d_1104[0][0]  \n",
            "                                                                 global_max_pooling3d_1105[0][0]  \n",
            "                                                                 global_max_pooling3d_1106[0][0]  \n",
            "                                                                 global_max_pooling3d_1107[0][0]  \n",
            "                                                                 global_max_pooling3d_1108[0][0]  \n",
            "                                                                 global_max_pooling3d_1109[0][0]  \n",
            "                                                                 global_max_pooling3d_1110[0][0]  \n",
            "                                                                 global_max_pooling3d_1111[0][0]  \n",
            "                                                                 global_max_pooling3d_1112[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_80 (Dense)                (None, 512)          664064      concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_81 (Dense)                (None, 512)          262656      dense_80[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_82 (Dense)                (None, 512)          262656      dense_81[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_83 (Dense)                (None, 1)            513         dense_82[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,226,177\n",
            "Trainable params: 1,226,177\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 14s 1s/step - loss: 99.4902 - accuracy: 0.4146 - val_loss: 93.5838 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 93.58382, saving model to ./mod0.h5\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 91.9085 - accuracy: 0.5244 - val_loss: 86.3880 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00002: val_loss improved from 93.58382 to 86.38799, saving model to ./mod0.h5\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 84.8844 - accuracy: 0.4756 - val_loss: 79.5626 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00003: val_loss improved from 86.38799 to 79.56263, saving model to ./mod0.h5\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 78.0623 - accuracy: 0.5732 - val_loss: 73.0237 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00004: val_loss improved from 79.56263 to 73.02373, saving model to ./mod0.h5\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 71.5644 - accuracy: 0.5244 - val_loss: 66.7385 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00005: val_loss improved from 73.02373 to 66.73853, saving model to ./mod0.h5\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 65.3746 - accuracy: 0.5610 - val_loss: 60.7809 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00006: val_loss improved from 66.73853 to 60.78091, saving model to ./mod0.h5\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 59.4563 - accuracy: 0.6220 - val_loss: 55.1377 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00007: val_loss improved from 60.78091 to 55.13770, saving model to ./mod0.h5\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 53.8478 - accuracy: 0.5244 - val_loss: 49.6989 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00008: val_loss improved from 55.13770 to 49.69892, saving model to ./mod0.h5\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 48.5192 - accuracy: 0.6585 - val_loss: 44.6056 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00009: val_loss improved from 49.69892 to 44.60559, saving model to ./mod0.h5\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 43.4775 - accuracy: 0.6585 - val_loss: 39.8146 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00010: val_loss improved from 44.60559 to 39.81458, saving model to ./mod0.h5\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 38.7206 - accuracy: 0.6098 - val_loss: 35.2545 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00011: val_loss improved from 39.81458 to 35.25453, saving model to ./mod0.h5\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 34.2559 - accuracy: 0.6463 - val_loss: 30.9998 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00012: val_loss improved from 35.25453 to 30.99981, saving model to ./mod0.h5\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 30.0929 - accuracy: 0.5366 - val_loss: 27.0909 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00013: val_loss improved from 30.99981 to 27.09091, saving model to ./mod0.h5\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 26.2519 - accuracy: 0.5732 - val_loss: 23.5525 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00014: val_loss improved from 27.09091 to 23.55254, saving model to ./mod0.h5\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 22.6996 - accuracy: 0.5244 - val_loss: 20.1047 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00015: val_loss improved from 23.55254 to 20.10471, saving model to ./mod0.h5\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 1s 227ms/step - loss: 19.3823 - accuracy: 0.6463 - val_loss: 17.0150 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00016: val_loss improved from 20.10471 to 17.01500, saving model to ./mod0.h5\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 16.3521 - accuracy: 0.7195 - val_loss: 14.3431 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00017: val_loss improved from 17.01500 to 14.34309, saving model to ./mod0.h5\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 13.7457 - accuracy: 0.5244 - val_loss: 11.8982 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00018: val_loss improved from 14.34309 to 11.89824, saving model to ./mod0.h5\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 11.3189 - accuracy: 0.5244 - val_loss: 9.6540 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00019: val_loss improved from 11.89824 to 9.65399, saving model to ./mod0.h5\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 9.1732 - accuracy: 0.5610 - val_loss: 7.7541 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00020: val_loss improved from 9.65399 to 7.75408, saving model to ./mod0.h5\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 7.3498 - accuracy: 0.8780 - val_loss: 6.1520 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00021: val_loss improved from 7.75408 to 6.15201, saving model to ./mod0.h5\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 5.8148 - accuracy: 0.8537 - val_loss: 4.8640 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00022: val_loss improved from 6.15201 to 4.86404, saving model to ./mod0.h5\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 4.5886 - accuracy: 0.8171 - val_loss: 3.8728 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00023: val_loss improved from 4.86404 to 3.87278, saving model to ./mod0.h5\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 3.6655 - accuracy: 0.8171 - val_loss: 3.1793 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00024: val_loss improved from 3.87278 to 3.17926, saving model to ./mod0.h5\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 3.0387 - accuracy: 0.8537 - val_loss: 2.7683 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00025: val_loss improved from 3.17926 to 2.76826, saving model to ./mod0.h5\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 2.7016 - accuracy: 0.7805 - val_loss: 2.6125 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00026: val_loss improved from 2.76826 to 2.61252, saving model to ./mod0.h5\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 2.5400 - accuracy: 0.7317 - val_loss: 2.3771 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00027: val_loss improved from 2.61252 to 2.37708, saving model to ./mod0.h5\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 2.2685 - accuracy: 0.8537 - val_loss: 2.0828 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00028: val_loss improved from 2.37708 to 2.08284, saving model to ./mod0.h5\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 1.9554 - accuracy: 0.8537 - val_loss: 1.9265 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00029: val_loss improved from 2.08284 to 1.92654, saving model to ./mod0.h5\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 1.7975 - accuracy: 0.5244 - val_loss: 1.6834 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.92654 to 1.68340, saving model to ./mod0.h5\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 1.5974 - accuracy: 0.6463 - val_loss: 1.5645 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.68340 to 1.56450, saving model to ./mod0.h5\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 1.4574 - accuracy: 0.7683 - val_loss: 1.4302 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.56450 to 1.43023, saving model to ./mod0.h5\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 1.3432 - accuracy: 0.8171 - val_loss: 1.4711 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.43023\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 1.3278 - accuracy: 0.5976 - val_loss: 1.2362 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.43023 to 1.23624, saving model to ./mod0.h5\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 1.3169 - accuracy: 0.5610 - val_loss: 1.2773 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.23624\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.1260 - accuracy: 0.7317 - val_loss: 1.1776 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00036: val_loss improved from 1.23624 to 1.17760, saving model to ./mod0.h5\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 1.0449 - accuracy: 0.8780 - val_loss: 1.1871 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.17760\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.9723 - accuracy: 0.8902 - val_loss: 1.3402 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.17760\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 1.0363 - accuracy: 0.7073 - val_loss: 0.9978 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.17760 to 0.99783, saving model to ./mod0.h5\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.9608 - accuracy: 0.7683 - val_loss: 0.9667 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.99783 to 0.96673, saving model to ./mod0.h5\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 1.1697 - accuracy: 0.6341 - val_loss: 1.0558 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.96673\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 1.0956 - accuracy: 0.7073 - val_loss: 1.2784 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.96673\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.9825 - accuracy: 0.7317 - val_loss: 1.0657 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.96673\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.1431 - accuracy: 0.4878 - val_loss: 1.0690 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.96673\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 1s 226ms/step - loss: 1.0998 - accuracy: 0.4878 - val_loss: 1.0823 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.96673\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 1.0292 - accuracy: 0.8537 - val_loss: 1.1419 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.96673\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 1.0261 - accuracy: 0.5854 - val_loss: 1.1501 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.96673\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.9754 - accuracy: 0.7805 - val_loss: 1.0294 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.96673\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.9348 - accuracy: 0.8049 - val_loss: 1.1538 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.96673\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.9253 - accuracy: 0.6829 - val_loss: 1.0831 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.96673\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.8341 - accuracy: 0.9268 - val_loss: 1.0822 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.96673\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.7825 - accuracy: 0.9268 - val_loss: 1.0932 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.96673\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.7293 - accuracy: 0.9024 - val_loss: 1.1749 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.96673\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.6953 - accuracy: 0.9268 - val_loss: 1.2332 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.96673\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.6664 - accuracy: 0.9512 - val_loss: 0.8509 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.96673 to 0.85095, saving model to ./mod0.h5\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.7022 - accuracy: 0.9024 - val_loss: 0.9888 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.85095\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.6413 - accuracy: 0.9390 - val_loss: 1.4115 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.85095\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.6585 - accuracy: 0.9024 - val_loss: 1.2549 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.85095\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 0.5970 - accuracy: 0.9512 - val_loss: 0.7737 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.85095 to 0.77367, saving model to ./mod0.h5\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.7131 - accuracy: 0.8780 - val_loss: 1.4838 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.77367\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.9387 - accuracy: 0.7561 - val_loss: 1.2639 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.77367\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 1.1730 - accuracy: 0.7195 - val_loss: 0.8762 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.77367\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 1s 227ms/step - loss: 0.7625 - accuracy: 0.8293 - val_loss: 1.0868 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.77367\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.6919 - accuracy: 0.8659 - val_loss: 1.1235 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.77367\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 0.6473 - accuracy: 0.9390 - val_loss: 0.8739 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.77367\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.5973 - accuracy: 0.9512 - val_loss: 1.2495 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.77367\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.6244 - accuracy: 0.9512 - val_loss: 0.8571 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.77367\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.6300 - accuracy: 0.9268 - val_loss: 0.9706 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.77367\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.5510 - accuracy: 1.0000 - val_loss: 1.0641 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.77367\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 1s 226ms/step - loss: 0.5397 - accuracy: 0.9878 - val_loss: 0.8868 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.77367\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.5837 - accuracy: 0.9268 - val_loss: 1.1665 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.77367\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.5679 - accuracy: 0.9390 - val_loss: 0.8216 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.77367\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.5753 - accuracy: 0.9268 - val_loss: 1.2939 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.77367\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.5904 - accuracy: 0.9390 - val_loss: 0.8300 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.77367\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.5703 - accuracy: 0.9268 - val_loss: 1.1095 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.77367\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.5087 - accuracy: 1.0000 - val_loss: 0.9794 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.77367\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.4733 - accuracy: 1.0000 - val_loss: 0.8112 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.77367\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.5195 - accuracy: 0.9512 - val_loss: 1.1045 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.77367\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.4732 - accuracy: 1.0000 - val_loss: 0.8294 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.77367\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 1s 227ms/step - loss: 0.4745 - accuracy: 0.9878 - val_loss: 1.1005 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.77367\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.4554 - accuracy: 1.0000 - val_loss: 0.8306 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.77367\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.4718 - accuracy: 0.9634 - val_loss: 1.2157 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.77367\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.4578 - accuracy: 1.0000 - val_loss: 0.8983 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.77367\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.4479 - accuracy: 0.9878 - val_loss: 1.0302 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.77367\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.4508 - accuracy: 1.0000 - val_loss: 1.0415 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.77367\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4460 - accuracy: 1.0000 - val_loss: 0.9640 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.77367\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4334 - accuracy: 1.0000 - val_loss: 0.9040 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.77367\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4284 - accuracy: 1.0000 - val_loss: 1.1996 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.77367\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.4415 - accuracy: 1.0000 - val_loss: 0.7898 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.77367\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4446 - accuracy: 0.9878 - val_loss: 1.3532 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.77367\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.4646 - accuracy: 0.9878 - val_loss: 0.8305 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.77367\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 0.4463 - accuracy: 1.0000 - val_loss: 1.1356 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.77367\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.4314 - accuracy: 1.0000 - val_loss: 0.8760 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.77367\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4250 - accuracy: 1.0000 - val_loss: 1.0928 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.77367\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.4235 - accuracy: 1.0000 - val_loss: 0.8507 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.77367\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 1s 224ms/step - loss: 0.4298 - accuracy: 1.0000 - val_loss: 1.1188 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.77367\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.4158 - accuracy: 1.0000 - val_loss: 1.0196 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.77367\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.4105 - accuracy: 1.0000 - val_loss: 0.8588 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.77367\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.4138 - accuracy: 1.0000 - val_loss: 1.1254 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.77367\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.4177 - accuracy: 1.0000 - val_loss: 1.0267 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.77367\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.4141 - accuracy: 1.0000 - val_loss: 0.7688 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00101: val_loss improved from 0.77367 to 0.76880, saving model to ./mod0.h5\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.4443 - accuracy: 0.9878 - val_loss: 1.2929 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.76880\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.4241 - accuracy: 1.0000 - val_loss: 0.9105 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.76880\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4090 - accuracy: 1.0000 - val_loss: 0.9137 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.76880\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.4069 - accuracy: 1.0000 - val_loss: 1.0848 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.76880\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.4013 - accuracy: 1.0000 - val_loss: 0.8494 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.76880\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4133 - accuracy: 1.0000 - val_loss: 1.2093 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.76880\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4078 - accuracy: 1.0000 - val_loss: 0.7935 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.76880\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.4259 - accuracy: 0.9878 - val_loss: 1.0421 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.76880\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3987 - accuracy: 1.0000 - val_loss: 1.0177 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.76880\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3982 - accuracy: 1.0000 - val_loss: 0.9649 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.76880\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3990 - accuracy: 1.0000 - val_loss: 1.3327 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.76880\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4163 - accuracy: 1.0000 - val_loss: 0.8715 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.76880\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.4008 - accuracy: 1.0000 - val_loss: 1.0309 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.76880\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 1s 227ms/step - loss: 0.4030 - accuracy: 1.0000 - val_loss: 1.1767 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.76880\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3947 - accuracy: 1.0000 - val_loss: 0.7984 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.76880\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.4129 - accuracy: 0.9878 - val_loss: 1.1251 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.76880\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.3956 - accuracy: 1.0000 - val_loss: 0.8726 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.76880\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3945 - accuracy: 1.0000 - val_loss: 1.1470 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.76880\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3874 - accuracy: 1.0000 - val_loss: 0.9360 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.76880\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3880 - accuracy: 1.0000 - val_loss: 1.0426 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.76880\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3882 - accuracy: 1.0000 - val_loss: 0.9088 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.76880\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 0.3992 - accuracy: 1.0000 - val_loss: 1.1713 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.76880\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3862 - accuracy: 1.0000 - val_loss: 0.8777 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.76880\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3904 - accuracy: 1.0000 - val_loss: 1.0403 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.76880\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 1s 227ms/step - loss: 0.3843 - accuracy: 1.0000 - val_loss: 1.0733 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.76880\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3825 - accuracy: 1.0000 - val_loss: 0.9086 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.76880\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.3832 - accuracy: 1.0000 - val_loss: 1.0722 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.76880\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3867 - accuracy: 1.0000 - val_loss: 0.9928 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.76880\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.3848 - accuracy: 1.0000 - val_loss: 0.9539 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.76880\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3848 - accuracy: 1.0000 - val_loss: 1.2504 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.76880\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3915 - accuracy: 1.0000 - val_loss: 0.9641 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.76880\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3831 - accuracy: 1.0000 - val_loss: 1.0272 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.76880\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3814 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.76880\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3857 - accuracy: 1.0000 - val_loss: 1.2630 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.76880\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.4056 - accuracy: 0.9878 - val_loss: 0.8252 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.76880\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3967 - accuracy: 1.0000 - val_loss: 0.9424 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.76880\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 0.3774 - accuracy: 1.0000 - val_loss: 1.3252 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.76880\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.3860 - accuracy: 1.0000 - val_loss: 0.8464 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.76880\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3876 - accuracy: 0.9878 - val_loss: 1.3795 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.76880\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3920 - accuracy: 1.0000 - val_loss: 0.9521 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.76880\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 0.3841 - accuracy: 1.0000 - val_loss: 1.1402 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.76880\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.3873 - accuracy: 1.0000 - val_loss: 1.0626 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.76880\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3781 - accuracy: 1.0000 - val_loss: 0.8658 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.76880\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3739 - accuracy: 1.0000 - val_loss: 1.1557 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.76880\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.3758 - accuracy: 1.0000 - val_loss: 0.9818 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.76880\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.3755 - accuracy: 1.0000 - val_loss: 0.9028 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.76880\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3697 - accuracy: 1.0000 - val_loss: 1.1844 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.76880\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3729 - accuracy: 1.0000 - val_loss: 0.9373 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.76880\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3702 - accuracy: 1.0000 - val_loss: 0.9519 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.76880\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3713 - accuracy: 1.0000 - val_loss: 1.0281 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.76880\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 23ms/step - loss: 0.4375 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6832 - accuracy: 0.8800\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7688 - accuracy: 0.7857\n",
            "(None, 19, 19, 19, 1)\n",
            "Model: \"model_21\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_23 (InputLayer)           [(None, 19, 19, 19,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3131 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3133 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3135 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3137 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3139 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3141 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3143 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3145 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3147 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3149 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3151 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3153 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3155 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3157 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3159 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3161 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3163 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3165 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3167 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3169 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3171 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3173 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3175 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3177 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3179 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3181 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3183 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3185 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3187 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3189 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3191 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3193 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3195 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3197 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3199 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3201 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3203 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3205 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3207 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3209 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3211 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3213 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3215 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3217 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3219 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3221 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3223 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3225 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3227 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3229 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3231 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3233 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3235 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3237 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3239 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3241 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3243 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3245 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3247 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3249 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3251 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3253 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3255 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3257 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3259 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3261 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3263 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3265 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3267 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3269 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3271 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3273 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3275 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3277 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3279 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3281 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3283 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3285 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3287 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3289 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3291 (Lambda)            (None, 19, 3, 19, 1) 0           input_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3130 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3131[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3132 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3133[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3134 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3135[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3136 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3137[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3138 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3139[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3140 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3141[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3142 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3143[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3144 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3145[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3146 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3147[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3148 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3149[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3150 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3151[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3152 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3153[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3154 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3155[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3156 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3157[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3158 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3159[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3160 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3161[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3162 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3163[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3164 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3165[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3166 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3167[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3168 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3169[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3170 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3171[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3172 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3173[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3174 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3175[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3176 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3177[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3178 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3179[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3180 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3181[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3182 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3183[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3184 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3185[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3186 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3187[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3188 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3189[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3190 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3191[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3192 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3193[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3194 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3195[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3196 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3197[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3198 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3199[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3200 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3201[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3202 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3203[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3204 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3205[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3206 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3207[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3208 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3209[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3210 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3211[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3212 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3213[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3214 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3215[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3216 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3217[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3218 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3219[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3220 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3221[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3222 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3223[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3224 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3225[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3226 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3227[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3228 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3229[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3230 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3231[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3232 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3233[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3234 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3235[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3236 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3237[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3238 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3239[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3240 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3241[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3242 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3243[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3244 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3245[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3246 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3247[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3248 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3249[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3250 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3251[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3252 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3253[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3254 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3255[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3256 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3257[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3258 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3259[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3260 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3261[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3262 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3263[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3264 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3265[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3266 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3267[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3268 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3269[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3270 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3271[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3272 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3273[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3274 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3275[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3276 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3277[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3278 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3279[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3280 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3281[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3282 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3283[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3284 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3285[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3286 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3287[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3288 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3289[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3290 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3291[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1565 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3130[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1566 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3132[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1567 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3134[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1568 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3136[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1569 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3138[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1570 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3140[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1571 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3142[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1572 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3144[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1573 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3146[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1574 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3148[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1575 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3150[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1576 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3152[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1577 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3154[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1578 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3156[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1579 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3158[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1580 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3160[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1581 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3162[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1582 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3164[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1583 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3166[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1584 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3168[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1585 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3170[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1586 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3172[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1587 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3174[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1588 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3176[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1589 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3178[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1590 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3180[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1591 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3182[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1592 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3184[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1593 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3186[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1594 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3188[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1595 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3190[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1596 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3192[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1597 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3194[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1598 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3196[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1599 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3198[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1600 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3200[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1601 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3202[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1602 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3204[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1603 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3206[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1604 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3208[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1605 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3210[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1606 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3212[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1607 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3214[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1608 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3216[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1609 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3218[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1610 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3220[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1611 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3222[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1612 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3224[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1613 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3226[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1614 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3228[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1615 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3230[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1616 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3232[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1617 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3234[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1618 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3236[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1619 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3238[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1620 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3240[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1621 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3242[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1622 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3244[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1623 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3246[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1624 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3248[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1625 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3250[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1626 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3252[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1627 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3254[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1628 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3256[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1629 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3258[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1630 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3260[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1631 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3262[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1632 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3264[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1633 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3266[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1634 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3268[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1635 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3270[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1636 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3272[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1637 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3274[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1638 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3276[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1639 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3278[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1640 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3280[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1641 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3282[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1642 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3284[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1643 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3286[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1644 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3288[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1645 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3290[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1565 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1565[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1566 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1566[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1567 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1567[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1568 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1568[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1569 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1569[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1570 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1570[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1571 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1571[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1572 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1572[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1573 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1573[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1574 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1574[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1575 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1575[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1576 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1576[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1577 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1577[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1578 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1578[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1579 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1579[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1580 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1580[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1581 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1581[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1582 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1582[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1583 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1583[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1584 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1584[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1585 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1585[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1586 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1586[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1587 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1587[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1588 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1588[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1589 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1589[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1590 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1590[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1591 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1591[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1592 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1592[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1593 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1593[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1594 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1594[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1595 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1595[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1596 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1596[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1597 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1597[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1598 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1598[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1599 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1599[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1600 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1600[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1601 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1601[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1602 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1602[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1603 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1603[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1604 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1604[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1605 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1605[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1606 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1606[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1607 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1607[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1608 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1608[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1609 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1609[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1610 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1610[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1611 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1611[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1612 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1612[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1613 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1613[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1614 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1614[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1615 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1615[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1616 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1616[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1617 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1617[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1618 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1618[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1619 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1619[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1620 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1620[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1621 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1621[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1622 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1622[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1623 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1623[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1624 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1624[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1625 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1625[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1626 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1626[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1627 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1627[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1628 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1628[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1629 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1629[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1630 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1630[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1631 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1631[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1632 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1632[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1633 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1633[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1634 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1634[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1635 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1635[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1636 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1636[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1637 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1637[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1638 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1638[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1639 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1639[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1640 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1640[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1641 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1641[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1642 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1642[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1643 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1643[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1644 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1644[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1645 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1645[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1113 (Glob (None, 16)           0           dropout_1565[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1114 (Glob (None, 16)           0           dropout_1566[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1115 (Glob (None, 16)           0           dropout_1567[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1116 (Glob (None, 16)           0           dropout_1568[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1117 (Glob (None, 16)           0           dropout_1569[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1118 (Glob (None, 16)           0           dropout_1570[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1119 (Glob (None, 16)           0           dropout_1571[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1120 (Glob (None, 16)           0           dropout_1572[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1121 (Glob (None, 16)           0           dropout_1573[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1122 (Glob (None, 16)           0           dropout_1574[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1123 (Glob (None, 16)           0           dropout_1575[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1124 (Glob (None, 16)           0           dropout_1576[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1125 (Glob (None, 16)           0           dropout_1577[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1126 (Glob (None, 16)           0           dropout_1578[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1127 (Glob (None, 16)           0           dropout_1579[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1128 (Glob (None, 16)           0           dropout_1580[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1129 (Glob (None, 16)           0           dropout_1581[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1130 (Glob (None, 16)           0           dropout_1582[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1131 (Glob (None, 16)           0           dropout_1583[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1132 (Glob (None, 16)           0           dropout_1584[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1133 (Glob (None, 16)           0           dropout_1585[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1134 (Glob (None, 16)           0           dropout_1586[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1135 (Glob (None, 16)           0           dropout_1587[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1136 (Glob (None, 16)           0           dropout_1588[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1137 (Glob (None, 16)           0           dropout_1589[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1138 (Glob (None, 16)           0           dropout_1590[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1139 (Glob (None, 16)           0           dropout_1591[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1140 (Glob (None, 16)           0           dropout_1592[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1141 (Glob (None, 16)           0           dropout_1593[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1142 (Glob (None, 16)           0           dropout_1594[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1143 (Glob (None, 16)           0           dropout_1595[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1144 (Glob (None, 16)           0           dropout_1596[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1145 (Glob (None, 16)           0           dropout_1597[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1146 (Glob (None, 16)           0           dropout_1598[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1147 (Glob (None, 16)           0           dropout_1599[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1148 (Glob (None, 16)           0           dropout_1600[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1149 (Glob (None, 16)           0           dropout_1601[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1150 (Glob (None, 16)           0           dropout_1602[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1151 (Glob (None, 16)           0           dropout_1603[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1152 (Glob (None, 16)           0           dropout_1604[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1153 (Glob (None, 16)           0           dropout_1605[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1154 (Glob (None, 16)           0           dropout_1606[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1155 (Glob (None, 16)           0           dropout_1607[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1156 (Glob (None, 16)           0           dropout_1608[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1157 (Glob (None, 16)           0           dropout_1609[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1158 (Glob (None, 16)           0           dropout_1610[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1159 (Glob (None, 16)           0           dropout_1611[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1160 (Glob (None, 16)           0           dropout_1612[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1161 (Glob (None, 16)           0           dropout_1613[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1162 (Glob (None, 16)           0           dropout_1614[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1163 (Glob (None, 16)           0           dropout_1615[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1164 (Glob (None, 16)           0           dropout_1616[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1165 (Glob (None, 16)           0           dropout_1617[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1166 (Glob (None, 16)           0           dropout_1618[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1167 (Glob (None, 16)           0           dropout_1619[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1168 (Glob (None, 16)           0           dropout_1620[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1169 (Glob (None, 16)           0           dropout_1621[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1170 (Glob (None, 16)           0           dropout_1622[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1171 (Glob (None, 16)           0           dropout_1623[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1172 (Glob (None, 16)           0           dropout_1624[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1173 (Glob (None, 16)           0           dropout_1625[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1174 (Glob (None, 16)           0           dropout_1626[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1175 (Glob (None, 16)           0           dropout_1627[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1176 (Glob (None, 16)           0           dropout_1628[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1177 (Glob (None, 16)           0           dropout_1629[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1178 (Glob (None, 16)           0           dropout_1630[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1179 (Glob (None, 16)           0           dropout_1631[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1180 (Glob (None, 16)           0           dropout_1632[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1181 (Glob (None, 16)           0           dropout_1633[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1182 (Glob (None, 16)           0           dropout_1634[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1183 (Glob (None, 16)           0           dropout_1635[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1184 (Glob (None, 16)           0           dropout_1636[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1185 (Glob (None, 16)           0           dropout_1637[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1186 (Glob (None, 16)           0           dropout_1638[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1187 (Glob (None, 16)           0           dropout_1639[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1188 (Glob (None, 16)           0           dropout_1640[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1189 (Glob (None, 16)           0           dropout_1641[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1190 (Glob (None, 16)           0           dropout_1642[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1191 (Glob (None, 16)           0           dropout_1643[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1192 (Glob (None, 16)           0           dropout_1644[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1193 (Glob (None, 16)           0           dropout_1645[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 1296)         0           global_max_pooling3d_1113[0][0]  \n",
            "                                                                 global_max_pooling3d_1114[0][0]  \n",
            "                                                                 global_max_pooling3d_1115[0][0]  \n",
            "                                                                 global_max_pooling3d_1116[0][0]  \n",
            "                                                                 global_max_pooling3d_1117[0][0]  \n",
            "                                                                 global_max_pooling3d_1118[0][0]  \n",
            "                                                                 global_max_pooling3d_1119[0][0]  \n",
            "                                                                 global_max_pooling3d_1120[0][0]  \n",
            "                                                                 global_max_pooling3d_1121[0][0]  \n",
            "                                                                 global_max_pooling3d_1122[0][0]  \n",
            "                                                                 global_max_pooling3d_1123[0][0]  \n",
            "                                                                 global_max_pooling3d_1124[0][0]  \n",
            "                                                                 global_max_pooling3d_1125[0][0]  \n",
            "                                                                 global_max_pooling3d_1126[0][0]  \n",
            "                                                                 global_max_pooling3d_1127[0][0]  \n",
            "                                                                 global_max_pooling3d_1128[0][0]  \n",
            "                                                                 global_max_pooling3d_1129[0][0]  \n",
            "                                                                 global_max_pooling3d_1130[0][0]  \n",
            "                                                                 global_max_pooling3d_1131[0][0]  \n",
            "                                                                 global_max_pooling3d_1132[0][0]  \n",
            "                                                                 global_max_pooling3d_1133[0][0]  \n",
            "                                                                 global_max_pooling3d_1134[0][0]  \n",
            "                                                                 global_max_pooling3d_1135[0][0]  \n",
            "                                                                 global_max_pooling3d_1136[0][0]  \n",
            "                                                                 global_max_pooling3d_1137[0][0]  \n",
            "                                                                 global_max_pooling3d_1138[0][0]  \n",
            "                                                                 global_max_pooling3d_1139[0][0]  \n",
            "                                                                 global_max_pooling3d_1140[0][0]  \n",
            "                                                                 global_max_pooling3d_1141[0][0]  \n",
            "                                                                 global_max_pooling3d_1142[0][0]  \n",
            "                                                                 global_max_pooling3d_1143[0][0]  \n",
            "                                                                 global_max_pooling3d_1144[0][0]  \n",
            "                                                                 global_max_pooling3d_1145[0][0]  \n",
            "                                                                 global_max_pooling3d_1146[0][0]  \n",
            "                                                                 global_max_pooling3d_1147[0][0]  \n",
            "                                                                 global_max_pooling3d_1148[0][0]  \n",
            "                                                                 global_max_pooling3d_1149[0][0]  \n",
            "                                                                 global_max_pooling3d_1150[0][0]  \n",
            "                                                                 global_max_pooling3d_1151[0][0]  \n",
            "                                                                 global_max_pooling3d_1152[0][0]  \n",
            "                                                                 global_max_pooling3d_1153[0][0]  \n",
            "                                                                 global_max_pooling3d_1154[0][0]  \n",
            "                                                                 global_max_pooling3d_1155[0][0]  \n",
            "                                                                 global_max_pooling3d_1156[0][0]  \n",
            "                                                                 global_max_pooling3d_1157[0][0]  \n",
            "                                                                 global_max_pooling3d_1158[0][0]  \n",
            "                                                                 global_max_pooling3d_1159[0][0]  \n",
            "                                                                 global_max_pooling3d_1160[0][0]  \n",
            "                                                                 global_max_pooling3d_1161[0][0]  \n",
            "                                                                 global_max_pooling3d_1162[0][0]  \n",
            "                                                                 global_max_pooling3d_1163[0][0]  \n",
            "                                                                 global_max_pooling3d_1164[0][0]  \n",
            "                                                                 global_max_pooling3d_1165[0][0]  \n",
            "                                                                 global_max_pooling3d_1166[0][0]  \n",
            "                                                                 global_max_pooling3d_1167[0][0]  \n",
            "                                                                 global_max_pooling3d_1168[0][0]  \n",
            "                                                                 global_max_pooling3d_1169[0][0]  \n",
            "                                                                 global_max_pooling3d_1170[0][0]  \n",
            "                                                                 global_max_pooling3d_1171[0][0]  \n",
            "                                                                 global_max_pooling3d_1172[0][0]  \n",
            "                                                                 global_max_pooling3d_1173[0][0]  \n",
            "                                                                 global_max_pooling3d_1174[0][0]  \n",
            "                                                                 global_max_pooling3d_1175[0][0]  \n",
            "                                                                 global_max_pooling3d_1176[0][0]  \n",
            "                                                                 global_max_pooling3d_1177[0][0]  \n",
            "                                                                 global_max_pooling3d_1178[0][0]  \n",
            "                                                                 global_max_pooling3d_1179[0][0]  \n",
            "                                                                 global_max_pooling3d_1180[0][0]  \n",
            "                                                                 global_max_pooling3d_1181[0][0]  \n",
            "                                                                 global_max_pooling3d_1182[0][0]  \n",
            "                                                                 global_max_pooling3d_1183[0][0]  \n",
            "                                                                 global_max_pooling3d_1184[0][0]  \n",
            "                                                                 global_max_pooling3d_1185[0][0]  \n",
            "                                                                 global_max_pooling3d_1186[0][0]  \n",
            "                                                                 global_max_pooling3d_1187[0][0]  \n",
            "                                                                 global_max_pooling3d_1188[0][0]  \n",
            "                                                                 global_max_pooling3d_1189[0][0]  \n",
            "                                                                 global_max_pooling3d_1190[0][0]  \n",
            "                                                                 global_max_pooling3d_1191[0][0]  \n",
            "                                                                 global_max_pooling3d_1192[0][0]  \n",
            "                                                                 global_max_pooling3d_1193[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_84 (Dense)                (None, 512)          664064      concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_85 (Dense)                (None, 512)          262656      dense_84[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_86 (Dense)                (None, 512)          262656      dense_85[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_87 (Dense)                (None, 1)            513         dense_86[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,226,177\n",
            "Trainable params: 1,226,177\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 14s 1s/step - loss: 99.4398 - accuracy: 0.5122 - val_loss: 93.5044 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 93.50442, saving model to ./mod1.h5\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 91.9596 - accuracy: 0.5000 - val_loss: 86.3818 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00002: val_loss improved from 93.50442 to 86.38184, saving model to ./mod1.h5\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 84.8366 - accuracy: 0.3780 - val_loss: 79.5135 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00003: val_loss improved from 86.38184 to 79.51345, saving model to ./mod1.h5\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 78.0217 - accuracy: 0.5244 - val_loss: 72.9952 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00004: val_loss improved from 79.51345 to 72.99522, saving model to ./mod1.h5\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 71.4992 - accuracy: 0.5244 - val_loss: 66.6661 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00005: val_loss improved from 72.99522 to 66.66611, saving model to ./mod1.h5\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 65.3639 - accuracy: 0.4756 - val_loss: 60.7013 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00006: val_loss improved from 66.66611 to 60.70129, saving model to ./mod1.h5\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 59.4331 - accuracy: 0.5000 - val_loss: 55.0803 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00007: val_loss improved from 60.70129 to 55.08032, saving model to ./mod1.h5\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 53.8035 - accuracy: 0.5244 - val_loss: 49.7006 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00008: val_loss improved from 55.08032 to 49.70062, saving model to ./mod1.h5\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 48.4820 - accuracy: 0.5244 - val_loss: 44.5603 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00009: val_loss improved from 49.70062 to 44.56026, saving model to ./mod1.h5\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 43.4457 - accuracy: 0.3780 - val_loss: 39.7157 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00010: val_loss improved from 44.56026 to 39.71570, saving model to ./mod1.h5\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 38.6740 - accuracy: 0.5732 - val_loss: 35.2084 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00011: val_loss improved from 39.71570 to 35.20839, saving model to ./mod1.h5\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 34.2059 - accuracy: 0.5244 - val_loss: 30.9661 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00012: val_loss improved from 35.20839 to 30.96611, saving model to ./mod1.h5\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 30.0273 - accuracy: 0.6098 - val_loss: 26.9903 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00013: val_loss improved from 30.96611 to 26.99028, saving model to ./mod1.h5\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 26.1429 - accuracy: 0.4878 - val_loss: 23.3340 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00014: val_loss improved from 26.99028 to 23.33403, saving model to ./mod1.h5\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 22.5508 - accuracy: 0.6220 - val_loss: 19.9766 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00015: val_loss improved from 23.33403 to 19.97661, saving model to ./mod1.h5\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 19.2485 - accuracy: 0.5610 - val_loss: 16.8885 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00016: val_loss improved from 19.97661 to 16.88849, saving model to ./mod1.h5\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 16.2159 - accuracy: 0.7195 - val_loss: 14.1049 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00017: val_loss improved from 16.88849 to 14.10495, saving model to ./mod1.h5\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 13.5435 - accuracy: 0.4756 - val_loss: 11.6228 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00018: val_loss improved from 14.10495 to 11.62283, saving model to ./mod1.h5\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 1s 222ms/step - loss: 11.1222 - accuracy: 0.5000 - val_loss: 9.4445 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00019: val_loss improved from 11.62283 to 9.44455, saving model to ./mod1.h5\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 8.9782 - accuracy: 0.8659 - val_loss: 7.5627 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00020: val_loss improved from 9.44455 to 7.56268, saving model to ./mod1.h5\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 7.1593 - accuracy: 0.8049 - val_loss: 5.9630 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00021: val_loss improved from 7.56268 to 5.96301, saving model to ./mod1.h5\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 5.6345 - accuracy: 0.6707 - val_loss: 4.6696 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00022: val_loss improved from 5.96301 to 4.66964, saving model to ./mod1.h5\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 4.4109 - accuracy: 0.6341 - val_loss: 3.6993 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00023: val_loss improved from 4.66964 to 3.69933, saving model to ./mod1.h5\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 3.4834 - accuracy: 0.7683 - val_loss: 3.0097 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00024: val_loss improved from 3.69933 to 3.00968, saving model to ./mod1.h5\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 2.8672 - accuracy: 0.8415 - val_loss: 2.6375 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00025: val_loss improved from 3.00968 to 2.63748, saving model to ./mod1.h5\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 2.5447 - accuracy: 0.8293 - val_loss: 2.5542 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00026: val_loss improved from 2.63748 to 2.55417, saving model to ./mod1.h5\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 2.4101 - accuracy: 0.6098 - val_loss: 2.2744 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00027: val_loss improved from 2.55417 to 2.27442, saving model to ./mod1.h5\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 2.4163 - accuracy: 0.4756 - val_loss: 2.0288 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00028: val_loss improved from 2.27442 to 2.02877, saving model to ./mod1.h5\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 2.0174 - accuracy: 0.4756 - val_loss: 1.8526 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00029: val_loss improved from 2.02877 to 1.85265, saving model to ./mod1.h5\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 1.8046 - accuracy: 0.5244 - val_loss: 1.7062 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.85265 to 1.70624, saving model to ./mod1.h5\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 1.6680 - accuracy: 0.5244 - val_loss: 1.6194 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.70624 to 1.61940, saving model to ./mod1.h5\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.5753 - accuracy: 0.5244 - val_loss: 1.5040 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.61940 to 1.50402, saving model to ./mod1.h5\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 1.4488 - accuracy: 0.5244 - val_loss: 1.3824 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.50402 to 1.38239, saving model to ./mod1.h5\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 1.3374 - accuracy: 0.5244 - val_loss: 1.3097 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.38239 to 1.30967, saving model to ./mod1.h5\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 1s 225ms/step - loss: 1.2693 - accuracy: 0.5244 - val_loss: 1.2581 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.30967 to 1.25808, saving model to ./mod1.h5\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 1.2068 - accuracy: 0.5244 - val_loss: 1.2100 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00036: val_loss improved from 1.25808 to 1.21003, saving model to ./mod1.h5\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 1.1558 - accuracy: 0.5488 - val_loss: 1.1690 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00037: val_loss improved from 1.21003 to 1.16896, saving model to ./mod1.h5\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.1118 - accuracy: 0.8293 - val_loss: 1.1920 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.16896\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.1069 - accuracy: 0.5244 - val_loss: 1.1248 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.16896 to 1.12482, saving model to ./mod1.h5\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 1.0283 - accuracy: 0.9024 - val_loss: 1.1312 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.12482\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 1.0064 - accuracy: 0.5732 - val_loss: 1.0697 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00041: val_loss improved from 1.12482 to 1.06971, saving model to ./mod1.h5\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.9505 - accuracy: 0.8537 - val_loss: 1.0373 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00042: val_loss improved from 1.06971 to 1.03727, saving model to ./mod1.h5\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.9116 - accuracy: 0.8293 - val_loss: 0.9951 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00043: val_loss improved from 1.03727 to 0.99512, saving model to ./mod1.h5\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.9217 - accuracy: 0.8293 - val_loss: 1.1938 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.99512\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.8987 - accuracy: 0.7073 - val_loss: 0.9853 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.99512 to 0.98532, saving model to ./mod1.h5\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.8137 - accuracy: 0.8049 - val_loss: 0.9153 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.98532 to 0.91526, saving model to ./mod1.h5\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.9244 - accuracy: 0.7073 - val_loss: 1.2181 - val_accuracy: 0.3571\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.91526\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.8568 - accuracy: 0.7683 - val_loss: 0.9030 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.91526 to 0.90304, saving model to ./mod1.h5\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.6979 - accuracy: 0.9024 - val_loss: 0.9165 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.90304\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.6706 - accuracy: 0.9268 - val_loss: 1.0215 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.90304\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.6932 - accuracy: 0.8780 - val_loss: 0.8223 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.90304 to 0.82227, saving model to ./mod1.h5\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.6861 - accuracy: 0.9024 - val_loss: 0.8149 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.82227 to 0.81492, saving model to ./mod1.h5\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.8278 - accuracy: 0.8293 - val_loss: 1.0520 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.81492\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.6823 - accuracy: 0.8537 - val_loss: 0.8265 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.81492\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.5811 - accuracy: 0.9756 - val_loss: 0.8433 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.81492\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.5665 - accuracy: 0.9634 - val_loss: 0.8877 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.81492\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.5711 - accuracy: 0.9634 - val_loss: 0.8641 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.81492\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.5508 - accuracy: 0.9878 - val_loss: 0.7722 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.81492 to 0.77222, saving model to ./mod1.h5\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.5356 - accuracy: 0.9756 - val_loss: 0.7086 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.77222 to 0.70856, saving model to ./mod1.h5\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.6207 - accuracy: 0.8659 - val_loss: 0.7037 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.70856 to 0.70367, saving model to ./mod1.h5\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.8045 - accuracy: 0.8293 - val_loss: 1.2559 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.70367\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.6692 - accuracy: 0.8537 - val_loss: 0.6986 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.70367 to 0.69856, saving model to ./mod1.h5\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.5500 - accuracy: 0.9512 - val_loss: 0.8296 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.69856\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.5835 - accuracy: 0.8902 - val_loss: 1.3189 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.69856\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 1.0010 - accuracy: 0.7073 - val_loss: 0.8158 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.69856\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.9622 - accuracy: 0.7195 - val_loss: 0.9400 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.69856\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.6751 - accuracy: 0.8537 - val_loss: 0.8325 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.69856\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.5500 - accuracy: 0.9512 - val_loss: 0.7518 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.69856\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.5099 - accuracy: 0.9634 - val_loss: 0.8942 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.69856\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.5129 - accuracy: 0.9756 - val_loss: 0.7808 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.69856\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.4879 - accuracy: 0.9878 - val_loss: 0.8108 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.69856\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.4892 - accuracy: 0.9878 - val_loss: 0.7479 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.69856\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4801 - accuracy: 1.0000 - val_loss: 0.7497 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.69856\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.4646 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.69856\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.4749 - accuracy: 0.9878 - val_loss: 0.7283 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.69856\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.4478 - accuracy: 1.0000 - val_loss: 0.7186 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.69856\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.4416 - accuracy: 1.0000 - val_loss: 0.7157 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.69856\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.4410 - accuracy: 1.0000 - val_loss: 0.6655 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.69856 to 0.66546, saving model to ./mod1.h5\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.4388 - accuracy: 1.0000 - val_loss: 0.7604 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.66546\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4646 - accuracy: 0.9756 - val_loss: 0.6277 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.66546 to 0.62770, saving model to ./mod1.h5\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.5385 - accuracy: 0.9512 - val_loss: 1.0823 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.62770\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.5648 - accuracy: 0.9268 - val_loss: 0.6832 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.62770\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.6124 - accuracy: 0.9024 - val_loss: 1.2461 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.62770\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.5995 - accuracy: 0.8780 - val_loss: 0.7306 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.62770\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.6960 - accuracy: 0.8415 - val_loss: 1.2343 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.62770\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.5993 - accuracy: 0.8902 - val_loss: 0.6282 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.62770\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.4851 - accuracy: 0.9512 - val_loss: 0.6696 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.62770\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.4828 - accuracy: 0.9634 - val_loss: 0.8556 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.62770\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.4498 - accuracy: 0.9878 - val_loss: 0.6527 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.62770\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.4794 - accuracy: 0.9634 - val_loss: 1.0164 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.62770\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.4996 - accuracy: 0.9634 - val_loss: 0.6256 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00091: val_loss improved from 0.62770 to 0.62565, saving model to ./mod1.h5\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.4568 - accuracy: 0.9756 - val_loss: 0.6171 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00092: val_loss improved from 0.62565 to 0.61707, saving model to ./mod1.h5\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4308 - accuracy: 1.0000 - val_loss: 0.9125 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.61707\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.4443 - accuracy: 1.0000 - val_loss: 0.6103 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.61707 to 0.61031, saving model to ./mod1.h5\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.5445 - accuracy: 0.8902 - val_loss: 0.7407 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.61031\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.5140 - accuracy: 0.9390 - val_loss: 0.6092 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00096: val_loss improved from 0.61031 to 0.60918, saving model to ./mod1.h5\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 1s 227ms/step - loss: 0.5107 - accuracy: 0.9390 - val_loss: 0.7751 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.60918\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.5485 - accuracy: 0.9024 - val_loss: 0.6548 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.60918\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.4666 - accuracy: 0.9512 - val_loss: 0.7577 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.60918\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.5587 - accuracy: 0.9390 - val_loss: 1.3491 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.60918\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.6056 - accuracy: 0.9024 - val_loss: 0.5955 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00101: val_loss improved from 0.60918 to 0.59553, saving model to ./mod1.h5\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.5104 - accuracy: 0.9512 - val_loss: 0.8147 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.59553\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.6857 - accuracy: 0.8171 - val_loss: 0.6233 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.59553\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.5574 - accuracy: 0.8902 - val_loss: 0.6173 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.59553\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4426 - accuracy: 0.9878 - val_loss: 1.5640 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.59553\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.7259 - accuracy: 0.7927 - val_loss: 0.9493 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.59553\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.8444 - accuracy: 0.7561 - val_loss: 0.8895 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.59553\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.6843 - accuracy: 0.8537 - val_loss: 0.7764 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.59553\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.4523 - accuracy: 0.9756 - val_loss: 0.7141 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.59553\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.5435 - accuracy: 0.9512 - val_loss: 0.8100 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.59553\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.5164 - accuracy: 0.9268 - val_loss: 0.8963 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.59553\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.4419 - accuracy: 0.9878 - val_loss: 0.6598 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.59553\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.5261 - accuracy: 0.9268 - val_loss: 0.6621 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.59553\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.4296 - accuracy: 0.9878 - val_loss: 0.9255 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.59553\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.4389 - accuracy: 1.0000 - val_loss: 0.6844 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.59553\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.4132 - accuracy: 1.0000 - val_loss: 0.6152 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.59553\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.4492 - accuracy: 0.9634 - val_loss: 0.7036 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.59553\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.4195 - accuracy: 1.0000 - val_loss: 0.8301 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.59553\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.4176 - accuracy: 1.0000 - val_loss: 0.6126 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.59553\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4125 - accuracy: 0.9878 - val_loss: 0.6151 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.59553\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3980 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.59553\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.4010 - accuracy: 1.0000 - val_loss: 0.7548 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.59553\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.4016 - accuracy: 1.0000 - val_loss: 0.6340 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.59553\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3889 - accuracy: 1.0000 - val_loss: 0.5915 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00124: val_loss improved from 0.59553 to 0.59152, saving model to ./mod1.h5\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.4008 - accuracy: 1.0000 - val_loss: 0.6063 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.59152\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3880 - accuracy: 1.0000 - val_loss: 0.7418 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.59152\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3987 - accuracy: 1.0000 - val_loss: 0.7046 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.59152\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3918 - accuracy: 1.0000 - val_loss: 0.5999 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.59152\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3911 - accuracy: 1.0000 - val_loss: 0.5971 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.59152\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3922 - accuracy: 1.0000 - val_loss: 0.6402 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.59152\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.3879 - accuracy: 1.0000 - val_loss: 0.6610 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.59152\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3864 - accuracy: 1.0000 - val_loss: 0.6382 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.59152\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3865 - accuracy: 1.0000 - val_loss: 0.6005 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.59152\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3848 - accuracy: 1.0000 - val_loss: 0.5959 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.59152\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3836 - accuracy: 1.0000 - val_loss: 0.6542 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.59152\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3832 - accuracy: 1.0000 - val_loss: 0.6625 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.59152\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3878 - accuracy: 1.0000 - val_loss: 0.5835 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00137: val_loss improved from 0.59152 to 0.58349, saving model to ./mod1.h5\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3890 - accuracy: 1.0000 - val_loss: 0.5676 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00138: val_loss improved from 0.58349 to 0.56765, saving model to ./mod1.h5\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3901 - accuracy: 1.0000 - val_loss: 0.5899 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.56765\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3783 - accuracy: 1.0000 - val_loss: 0.6609 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.56765\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.3870 - accuracy: 1.0000 - val_loss: 0.6312 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.56765\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3814 - accuracy: 1.0000 - val_loss: 0.5918 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.56765\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3791 - accuracy: 1.0000 - val_loss: 0.5738 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.56765\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3844 - accuracy: 1.0000 - val_loss: 0.5809 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.56765\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 0.3794 - accuracy: 1.0000 - val_loss: 0.6114 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.56765\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3787 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.56765\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3781 - accuracy: 1.0000 - val_loss: 0.5910 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.56765\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3759 - accuracy: 1.0000 - val_loss: 0.5800 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.56765\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3773 - accuracy: 1.0000 - val_loss: 0.5991 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.56765\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3757 - accuracy: 1.0000 - val_loss: 0.6071 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.56765\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3782 - accuracy: 1.0000 - val_loss: 0.5996 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.56765\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3798 - accuracy: 1.0000 - val_loss: 0.5965 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.56765\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3742 - accuracy: 1.0000 - val_loss: 0.5885 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.56765\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3764 - accuracy: 1.0000 - val_loss: 0.5782 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.56765\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3780 - accuracy: 1.0000 - val_loss: 0.5748 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.56765\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3728 - accuracy: 1.0000 - val_loss: 0.5951 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.56765\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3757 - accuracy: 1.0000 - val_loss: 0.6063 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.56765\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3763 - accuracy: 1.0000 - val_loss: 0.5722 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.56765\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3791 - accuracy: 1.0000 - val_loss: 0.5719 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.56765\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3723 - accuracy: 1.0000 - val_loss: 0.6096 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.56765\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3752 - accuracy: 1.0000 - val_loss: 0.6058 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.56765\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3738 - accuracy: 1.0000 - val_loss: 0.6004 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.56765\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3721 - accuracy: 1.0000 - val_loss: 0.5633 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00163: val_loss improved from 0.56765 to 0.56328, saving model to ./mod1.h5\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3716 - accuracy: 1.0000 - val_loss: 0.5646 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.56328\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3726 - accuracy: 1.0000 - val_loss: 0.6018 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.56328\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3732 - accuracy: 1.0000 - val_loss: 0.5943 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.56328\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3741 - accuracy: 1.0000 - val_loss: 0.5650 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.56328\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3741 - accuracy: 1.0000 - val_loss: 0.6007 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.56328\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3741 - accuracy: 1.0000 - val_loss: 0.5845 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.56328\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.3744 - accuracy: 1.0000 - val_loss: 0.5566 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00170: val_loss improved from 0.56328 to 0.55663, saving model to ./mod1.h5\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3736 - accuracy: 1.0000 - val_loss: 0.5811 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.55663\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3684 - accuracy: 1.0000 - val_loss: 0.5961 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.55663\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3677 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.55663\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3685 - accuracy: 1.0000 - val_loss: 0.5871 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.55663\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.3706 - accuracy: 1.0000 - val_loss: 0.5647 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.55663\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3713 - accuracy: 1.0000 - val_loss: 0.6058 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.55663\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.3699 - accuracy: 1.0000 - val_loss: 0.6092 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.55663\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3689 - accuracy: 1.0000 - val_loss: 0.5811 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.55663\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.3698 - accuracy: 1.0000 - val_loss: 0.5700 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.55663\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3662 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.55663\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3680 - accuracy: 1.0000 - val_loss: 0.5980 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.55663\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3670 - accuracy: 1.0000 - val_loss: 0.5683 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.55663\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.3687 - accuracy: 1.0000 - val_loss: 0.5453 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00183: val_loss improved from 0.55663 to 0.54533, saving model to ./mod1.h5\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3685 - accuracy: 1.0000 - val_loss: 0.5937 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.54533\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3700 - accuracy: 1.0000 - val_loss: 0.5963 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.54533\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3683 - accuracy: 1.0000 - val_loss: 0.5858 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.54533\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3660 - accuracy: 1.0000 - val_loss: 0.5778 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.54533\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3654 - accuracy: 1.0000 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.54533\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3674 - accuracy: 1.0000 - val_loss: 0.5730 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.54533\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3678 - accuracy: 1.0000 - val_loss: 0.6088 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.54533\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3652 - accuracy: 1.0000 - val_loss: 0.6021 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.54533\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3641 - accuracy: 1.0000 - val_loss: 0.5640 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.54533\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3651 - accuracy: 1.0000 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.54533\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3649 - accuracy: 1.0000 - val_loss: 0.5942 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.54533\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3682 - accuracy: 1.0000 - val_loss: 0.5898 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.54533\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3619 - accuracy: 1.0000 - val_loss: 0.5660 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.54533\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3656 - accuracy: 1.0000 - val_loss: 0.5636 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.54533\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3695 - accuracy: 1.0000 - val_loss: 0.5931 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.54533\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3642 - accuracy: 1.0000 - val_loss: 0.5590 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.54533\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.3621 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.54533\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 24ms/step - loss: 0.3816 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6172 - accuracy: 0.8800\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5453 - accuracy: 1.0000\n",
            "(None, 19, 19, 19, 1)\n",
            "Model: \"model_22\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_24 (InputLayer)           [(None, 19, 19, 19,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3293 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3295 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3297 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3299 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3301 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3303 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3305 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3307 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3309 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3311 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3313 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3315 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3317 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3319 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3321 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3323 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3325 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3327 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3329 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3331 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3333 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3335 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3337 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3339 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3341 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3343 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3345 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3347 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3349 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3351 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3353 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3355 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3357 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3359 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3361 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3363 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3365 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3367 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3369 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3371 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3373 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3375 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3377 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3379 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3381 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3383 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3385 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3387 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3389 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3391 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3393 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3395 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3397 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3399 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3401 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3403 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3405 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3407 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3409 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3411 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3413 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3415 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3417 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3419 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3421 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3423 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3425 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3427 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3429 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3431 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3433 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3435 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3437 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3439 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3441 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3443 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3445 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3447 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3449 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3451 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3453 (Lambda)            (None, 19, 3, 19, 1) 0           input_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3292 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3293[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3294 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3295[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3296 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3297[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3298 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3299[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3300 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3301[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3302 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3303[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3304 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3305[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3306 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3307[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3308 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3309[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3310 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3311[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3312 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3313[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3314 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3315[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3316 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3317[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3318 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3319[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3320 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3321[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3322 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3323[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3324 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3325[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3326 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3327[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3328 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3329[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3330 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3331[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3332 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3333[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3334 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3335[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3336 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3337[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3338 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3339[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3340 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3341[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3342 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3343[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3344 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3345[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3346 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3347[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3348 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3349[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3350 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3351[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3352 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3353[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3354 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3355[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3356 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3357[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3358 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3359[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3360 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3361[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3362 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3363[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3364 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3365[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3366 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3367[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3368 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3369[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3370 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3371[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3372 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3373[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3374 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3375[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3376 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3377[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3378 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3379[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3380 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3381[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3382 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3383[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3384 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3385[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3386 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3387[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3388 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3389[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3390 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3391[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3392 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3393[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3394 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3395[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3396 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3397[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3398 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3399[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3400 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3401[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3402 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3403[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3404 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3405[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3406 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3407[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3408 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3409[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3410 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3411[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3412 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3413[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3414 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3415[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3416 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3417[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3418 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3419[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3420 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3421[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3422 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3423[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3424 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3425[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3426 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3427[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3428 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3429[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3430 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3431[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3432 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3433[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3434 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3435[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3436 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3437[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3438 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3439[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3440 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3441[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3442 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3443[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3444 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3445[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3446 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3447[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3448 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3449[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3450 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3451[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3452 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3453[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1646 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3292[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1647 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3294[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1648 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3296[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1649 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3298[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1650 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3300[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1651 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3302[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1652 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3304[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1653 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3306[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1654 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3308[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1655 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3310[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1656 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3312[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1657 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3314[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1658 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3316[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1659 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3318[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1660 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3320[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1661 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3322[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1662 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3324[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1663 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3326[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1664 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3328[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1665 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3330[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1666 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3332[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1667 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3334[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1668 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3336[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1669 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3338[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1670 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3340[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1671 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3342[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1672 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3344[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1673 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3346[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1674 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3348[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1675 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3350[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1676 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3352[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1677 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3354[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1678 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3356[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1679 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3358[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1680 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3360[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1681 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3362[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1682 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3364[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1683 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3366[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1684 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3368[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1685 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3370[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1686 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3372[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1687 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3374[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1688 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3376[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1689 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3378[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1690 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3380[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1691 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3382[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1692 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3384[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1693 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3386[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1694 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3388[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1695 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3390[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1696 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3392[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1697 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3394[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1698 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3396[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1699 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3398[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1700 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3400[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1701 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3402[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1702 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3404[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1703 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3406[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1704 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3408[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1705 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3410[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1706 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3412[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1707 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3414[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1708 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3416[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1709 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3418[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1710 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3420[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1711 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3422[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1712 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3424[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1713 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3426[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1714 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3428[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1715 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3430[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1716 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3432[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1717 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3434[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1718 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3436[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1719 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3438[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1720 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3440[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1721 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3442[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1722 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3444[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1723 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3446[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1724 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3448[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1725 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3450[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1726 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3452[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1646 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1646[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1647 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1647[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1648 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1648[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1649 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1649[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1650 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1650[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1651 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1651[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1652 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1652[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1653 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1653[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1654 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1654[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1655 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1655[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1656 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1656[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1657 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1657[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1658 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1658[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1659 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1659[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1660 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1660[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1661 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1661[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1662 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1662[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1663 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1663[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1664 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1664[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1665 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1665[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1666 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1666[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1667 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1667[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1668 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1668[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1669 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1669[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1670 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1670[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1671 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1671[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1672 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1672[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1673 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1673[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1674 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1674[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1675 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1675[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1676 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1676[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1677 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1677[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1678 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1678[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1679 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1679[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1680 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1680[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1681 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1681[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1682 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1682[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1683 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1683[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1684 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1684[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1685 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1685[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1686 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1686[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1687 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1687[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1688 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1688[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1689 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1689[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1690 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1690[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1691 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1691[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1692 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1692[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1693 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1693[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1694 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1694[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1695 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1695[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1696 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1696[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1697 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1697[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1698 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1698[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1699 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1699[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1700 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1700[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1701 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1701[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1702 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1702[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1703 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1703[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1704 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1704[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1705 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1705[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1706 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1706[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1707 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1707[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1708 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1708[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1709 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1709[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1710 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1710[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1711 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1711[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1712 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1712[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1713 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1713[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1714 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1714[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1715 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1715[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1716 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1716[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1717 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1717[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1718 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1718[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1719 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1719[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1720 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1720[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1721 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1721[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1722 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1722[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1723 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1723[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1724 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1724[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1725 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1725[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1726 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1726[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1194 (Glob (None, 16)           0           dropout_1646[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1195 (Glob (None, 16)           0           dropout_1647[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1196 (Glob (None, 16)           0           dropout_1648[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1197 (Glob (None, 16)           0           dropout_1649[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1198 (Glob (None, 16)           0           dropout_1650[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1199 (Glob (None, 16)           0           dropout_1651[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1200 (Glob (None, 16)           0           dropout_1652[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1201 (Glob (None, 16)           0           dropout_1653[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1202 (Glob (None, 16)           0           dropout_1654[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1203 (Glob (None, 16)           0           dropout_1655[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1204 (Glob (None, 16)           0           dropout_1656[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1205 (Glob (None, 16)           0           dropout_1657[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1206 (Glob (None, 16)           0           dropout_1658[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1207 (Glob (None, 16)           0           dropout_1659[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1208 (Glob (None, 16)           0           dropout_1660[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1209 (Glob (None, 16)           0           dropout_1661[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1210 (Glob (None, 16)           0           dropout_1662[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1211 (Glob (None, 16)           0           dropout_1663[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1212 (Glob (None, 16)           0           dropout_1664[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1213 (Glob (None, 16)           0           dropout_1665[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1214 (Glob (None, 16)           0           dropout_1666[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1215 (Glob (None, 16)           0           dropout_1667[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1216 (Glob (None, 16)           0           dropout_1668[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1217 (Glob (None, 16)           0           dropout_1669[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1218 (Glob (None, 16)           0           dropout_1670[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1219 (Glob (None, 16)           0           dropout_1671[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1220 (Glob (None, 16)           0           dropout_1672[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1221 (Glob (None, 16)           0           dropout_1673[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1222 (Glob (None, 16)           0           dropout_1674[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1223 (Glob (None, 16)           0           dropout_1675[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1224 (Glob (None, 16)           0           dropout_1676[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1225 (Glob (None, 16)           0           dropout_1677[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1226 (Glob (None, 16)           0           dropout_1678[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1227 (Glob (None, 16)           0           dropout_1679[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1228 (Glob (None, 16)           0           dropout_1680[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1229 (Glob (None, 16)           0           dropout_1681[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1230 (Glob (None, 16)           0           dropout_1682[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1231 (Glob (None, 16)           0           dropout_1683[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1232 (Glob (None, 16)           0           dropout_1684[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1233 (Glob (None, 16)           0           dropout_1685[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1234 (Glob (None, 16)           0           dropout_1686[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1235 (Glob (None, 16)           0           dropout_1687[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1236 (Glob (None, 16)           0           dropout_1688[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1237 (Glob (None, 16)           0           dropout_1689[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1238 (Glob (None, 16)           0           dropout_1690[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1239 (Glob (None, 16)           0           dropout_1691[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1240 (Glob (None, 16)           0           dropout_1692[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1241 (Glob (None, 16)           0           dropout_1693[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1242 (Glob (None, 16)           0           dropout_1694[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1243 (Glob (None, 16)           0           dropout_1695[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1244 (Glob (None, 16)           0           dropout_1696[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1245 (Glob (None, 16)           0           dropout_1697[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1246 (Glob (None, 16)           0           dropout_1698[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1247 (Glob (None, 16)           0           dropout_1699[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1248 (Glob (None, 16)           0           dropout_1700[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1249 (Glob (None, 16)           0           dropout_1701[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1250 (Glob (None, 16)           0           dropout_1702[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1251 (Glob (None, 16)           0           dropout_1703[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1252 (Glob (None, 16)           0           dropout_1704[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1253 (Glob (None, 16)           0           dropout_1705[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1254 (Glob (None, 16)           0           dropout_1706[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1255 (Glob (None, 16)           0           dropout_1707[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1256 (Glob (None, 16)           0           dropout_1708[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1257 (Glob (None, 16)           0           dropout_1709[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1258 (Glob (None, 16)           0           dropout_1710[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1259 (Glob (None, 16)           0           dropout_1711[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1260 (Glob (None, 16)           0           dropout_1712[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1261 (Glob (None, 16)           0           dropout_1713[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1262 (Glob (None, 16)           0           dropout_1714[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1263 (Glob (None, 16)           0           dropout_1715[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1264 (Glob (None, 16)           0           dropout_1716[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1265 (Glob (None, 16)           0           dropout_1717[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1266 (Glob (None, 16)           0           dropout_1718[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1267 (Glob (None, 16)           0           dropout_1719[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1268 (Glob (None, 16)           0           dropout_1720[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1269 (Glob (None, 16)           0           dropout_1721[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1270 (Glob (None, 16)           0           dropout_1722[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1271 (Glob (None, 16)           0           dropout_1723[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1272 (Glob (None, 16)           0           dropout_1724[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1273 (Glob (None, 16)           0           dropout_1725[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1274 (Glob (None, 16)           0           dropout_1726[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 1296)         0           global_max_pooling3d_1194[0][0]  \n",
            "                                                                 global_max_pooling3d_1195[0][0]  \n",
            "                                                                 global_max_pooling3d_1196[0][0]  \n",
            "                                                                 global_max_pooling3d_1197[0][0]  \n",
            "                                                                 global_max_pooling3d_1198[0][0]  \n",
            "                                                                 global_max_pooling3d_1199[0][0]  \n",
            "                                                                 global_max_pooling3d_1200[0][0]  \n",
            "                                                                 global_max_pooling3d_1201[0][0]  \n",
            "                                                                 global_max_pooling3d_1202[0][0]  \n",
            "                                                                 global_max_pooling3d_1203[0][0]  \n",
            "                                                                 global_max_pooling3d_1204[0][0]  \n",
            "                                                                 global_max_pooling3d_1205[0][0]  \n",
            "                                                                 global_max_pooling3d_1206[0][0]  \n",
            "                                                                 global_max_pooling3d_1207[0][0]  \n",
            "                                                                 global_max_pooling3d_1208[0][0]  \n",
            "                                                                 global_max_pooling3d_1209[0][0]  \n",
            "                                                                 global_max_pooling3d_1210[0][0]  \n",
            "                                                                 global_max_pooling3d_1211[0][0]  \n",
            "                                                                 global_max_pooling3d_1212[0][0]  \n",
            "                                                                 global_max_pooling3d_1213[0][0]  \n",
            "                                                                 global_max_pooling3d_1214[0][0]  \n",
            "                                                                 global_max_pooling3d_1215[0][0]  \n",
            "                                                                 global_max_pooling3d_1216[0][0]  \n",
            "                                                                 global_max_pooling3d_1217[0][0]  \n",
            "                                                                 global_max_pooling3d_1218[0][0]  \n",
            "                                                                 global_max_pooling3d_1219[0][0]  \n",
            "                                                                 global_max_pooling3d_1220[0][0]  \n",
            "                                                                 global_max_pooling3d_1221[0][0]  \n",
            "                                                                 global_max_pooling3d_1222[0][0]  \n",
            "                                                                 global_max_pooling3d_1223[0][0]  \n",
            "                                                                 global_max_pooling3d_1224[0][0]  \n",
            "                                                                 global_max_pooling3d_1225[0][0]  \n",
            "                                                                 global_max_pooling3d_1226[0][0]  \n",
            "                                                                 global_max_pooling3d_1227[0][0]  \n",
            "                                                                 global_max_pooling3d_1228[0][0]  \n",
            "                                                                 global_max_pooling3d_1229[0][0]  \n",
            "                                                                 global_max_pooling3d_1230[0][0]  \n",
            "                                                                 global_max_pooling3d_1231[0][0]  \n",
            "                                                                 global_max_pooling3d_1232[0][0]  \n",
            "                                                                 global_max_pooling3d_1233[0][0]  \n",
            "                                                                 global_max_pooling3d_1234[0][0]  \n",
            "                                                                 global_max_pooling3d_1235[0][0]  \n",
            "                                                                 global_max_pooling3d_1236[0][0]  \n",
            "                                                                 global_max_pooling3d_1237[0][0]  \n",
            "                                                                 global_max_pooling3d_1238[0][0]  \n",
            "                                                                 global_max_pooling3d_1239[0][0]  \n",
            "                                                                 global_max_pooling3d_1240[0][0]  \n",
            "                                                                 global_max_pooling3d_1241[0][0]  \n",
            "                                                                 global_max_pooling3d_1242[0][0]  \n",
            "                                                                 global_max_pooling3d_1243[0][0]  \n",
            "                                                                 global_max_pooling3d_1244[0][0]  \n",
            "                                                                 global_max_pooling3d_1245[0][0]  \n",
            "                                                                 global_max_pooling3d_1246[0][0]  \n",
            "                                                                 global_max_pooling3d_1247[0][0]  \n",
            "                                                                 global_max_pooling3d_1248[0][0]  \n",
            "                                                                 global_max_pooling3d_1249[0][0]  \n",
            "                                                                 global_max_pooling3d_1250[0][0]  \n",
            "                                                                 global_max_pooling3d_1251[0][0]  \n",
            "                                                                 global_max_pooling3d_1252[0][0]  \n",
            "                                                                 global_max_pooling3d_1253[0][0]  \n",
            "                                                                 global_max_pooling3d_1254[0][0]  \n",
            "                                                                 global_max_pooling3d_1255[0][0]  \n",
            "                                                                 global_max_pooling3d_1256[0][0]  \n",
            "                                                                 global_max_pooling3d_1257[0][0]  \n",
            "                                                                 global_max_pooling3d_1258[0][0]  \n",
            "                                                                 global_max_pooling3d_1259[0][0]  \n",
            "                                                                 global_max_pooling3d_1260[0][0]  \n",
            "                                                                 global_max_pooling3d_1261[0][0]  \n",
            "                                                                 global_max_pooling3d_1262[0][0]  \n",
            "                                                                 global_max_pooling3d_1263[0][0]  \n",
            "                                                                 global_max_pooling3d_1264[0][0]  \n",
            "                                                                 global_max_pooling3d_1265[0][0]  \n",
            "                                                                 global_max_pooling3d_1266[0][0]  \n",
            "                                                                 global_max_pooling3d_1267[0][0]  \n",
            "                                                                 global_max_pooling3d_1268[0][0]  \n",
            "                                                                 global_max_pooling3d_1269[0][0]  \n",
            "                                                                 global_max_pooling3d_1270[0][0]  \n",
            "                                                                 global_max_pooling3d_1271[0][0]  \n",
            "                                                                 global_max_pooling3d_1272[0][0]  \n",
            "                                                                 global_max_pooling3d_1273[0][0]  \n",
            "                                                                 global_max_pooling3d_1274[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_88 (Dense)                (None, 512)          664064      concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_89 (Dense)                (None, 512)          262656      dense_88[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_90 (Dense)                (None, 512)          262656      dense_89[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_91 (Dense)                (None, 1)            513         dense_90[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,226,177\n",
            "Trainable params: 1,226,177\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 14s 1s/step - loss: 99.4946 - accuracy: 0.4146 - val_loss: 93.5342 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 93.53418, saving model to ./mod2.h5\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 91.8985 - accuracy: 0.5122 - val_loss: 86.3095 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00002: val_loss improved from 93.53418 to 86.30950, saving model to ./mod2.h5\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 84.7606 - accuracy: 0.4878 - val_loss: 79.4862 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00003: val_loss improved from 86.30950 to 79.48620, saving model to ./mod2.h5\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 77.9907 - accuracy: 0.5122 - val_loss: 72.9247 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00004: val_loss improved from 79.48620 to 72.92470, saving model to ./mod2.h5\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 71.4985 - accuracy: 0.4878 - val_loss: 66.6727 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00005: val_loss improved from 72.92470 to 66.67267, saving model to ./mod2.h5\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 65.3454 - accuracy: 0.4878 - val_loss: 60.7305 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00006: val_loss improved from 66.67267 to 60.73050, saving model to ./mod2.h5\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 59.4197 - accuracy: 0.5122 - val_loss: 55.0815 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00007: val_loss improved from 60.73050 to 55.08147, saving model to ./mod2.h5\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 53.8263 - accuracy: 0.5122 - val_loss: 49.6787 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00008: val_loss improved from 55.08147 to 49.67869, saving model to ./mod2.h5\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 48.4799 - accuracy: 0.5610 - val_loss: 44.5683 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00009: val_loss improved from 49.67869 to 44.56832, saving model to ./mod2.h5\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 43.4671 - accuracy: 0.4878 - val_loss: 39.7442 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00010: val_loss improved from 44.56832 to 39.74419, saving model to ./mod2.h5\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 38.7160 - accuracy: 0.4878 - val_loss: 35.2108 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00011: val_loss improved from 39.74419 to 35.21082, saving model to ./mod2.h5\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 34.2307 - accuracy: 0.4878 - val_loss: 30.9740 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00012: val_loss improved from 35.21082 to 30.97396, saving model to ./mod2.h5\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 30.0496 - accuracy: 0.5976 - val_loss: 27.0219 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00013: val_loss improved from 30.97396 to 27.02193, saving model to ./mod2.h5\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 26.1624 - accuracy: 0.5976 - val_loss: 23.3629 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00014: val_loss improved from 27.02193 to 23.36292, saving model to ./mod2.h5\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 22.5717 - accuracy: 0.5488 - val_loss: 19.9887 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00015: val_loss improved from 23.36292 to 19.98868, saving model to ./mod2.h5\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 19.2597 - accuracy: 0.7073 - val_loss: 16.8943 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00016: val_loss improved from 19.98868 to 16.89433, saving model to ./mod2.h5\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 16.2257 - accuracy: 0.7927 - val_loss: 14.1275 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00017: val_loss improved from 16.89433 to 14.12747, saving model to ./mod2.h5\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 13.5273 - accuracy: 0.5122 - val_loss: 11.6468 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00018: val_loss improved from 14.12747 to 11.64680, saving model to ./mod2.h5\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 11.0944 - accuracy: 0.5610 - val_loss: 9.4385 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00019: val_loss improved from 11.64680 to 9.43846, saving model to ./mod2.h5\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 8.9799 - accuracy: 0.5000 - val_loss: 7.5617 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00020: val_loss improved from 9.43846 to 7.56173, saving model to ./mod2.h5\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 7.1686 - accuracy: 0.5366 - val_loss: 5.9933 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00021: val_loss improved from 7.56173 to 5.99331, saving model to ./mod2.h5\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 5.6477 - accuracy: 0.6707 - val_loss: 4.7015 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00022: val_loss improved from 5.99331 to 4.70150, saving model to ./mod2.h5\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 4.4352 - accuracy: 0.6585 - val_loss: 3.7228 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00023: val_loss improved from 4.70150 to 3.72278, saving model to ./mod2.h5\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 3.5102 - accuracy: 0.8659 - val_loss: 3.0425 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00024: val_loss improved from 3.72278 to 3.04248, saving model to ./mod2.h5\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 2.8850 - accuracy: 0.8659 - val_loss: 2.6826 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00025: val_loss improved from 3.04248 to 2.68265, saving model to ./mod2.h5\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 2.5925 - accuracy: 0.5122 - val_loss: 2.5149 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00026: val_loss improved from 2.68265 to 2.51494, saving model to ./mod2.h5\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 2.4580 - accuracy: 0.5244 - val_loss: 2.2960 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00027: val_loss improved from 2.51494 to 2.29599, saving model to ./mod2.h5\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 2.1756 - accuracy: 0.8293 - val_loss: 2.0782 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00028: val_loss improved from 2.29599 to 2.07816, saving model to ./mod2.h5\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.9257 - accuracy: 0.5366 - val_loss: 1.7747 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00029: val_loss improved from 2.07816 to 1.77474, saving model to ./mod2.h5\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 1.6323 - accuracy: 0.8171 - val_loss: 1.6037 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.77474 to 1.60374, saving model to ./mod2.h5\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 1.4631 - accuracy: 0.8415 - val_loss: 1.5397 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.60374 to 1.53970, saving model to ./mod2.h5\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 1.3888 - accuracy: 0.8415 - val_loss: 1.4463 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.53970 to 1.44634, saving model to ./mod2.h5\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.2476 - accuracy: 0.8537 - val_loss: 1.4356 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.44634 to 1.43561, saving model to ./mod2.h5\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 1.1254 - accuracy: 0.8171 - val_loss: 1.3601 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.43561 to 1.36009, saving model to ./mod2.h5\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 1.0252 - accuracy: 0.8659 - val_loss: 1.2187 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.36009 to 1.21874, saving model to ./mod2.h5\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 1.0509 - accuracy: 0.8049 - val_loss: 1.3630 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.21874\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.9529 - accuracy: 0.8293 - val_loss: 1.4460 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.21874\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.9774 - accuracy: 0.8171 - val_loss: 1.2783 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.21874\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.8054 - accuracy: 0.8780 - val_loss: 1.0694 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.21874 to 1.06941, saving model to ./mod2.h5\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.8081 - accuracy: 0.8780 - val_loss: 1.0716 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.06941\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.7614 - accuracy: 0.9268 - val_loss: 1.4016 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.06941\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.8061 - accuracy: 0.8415 - val_loss: 1.1159 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.06941\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 1.0042 - accuracy: 0.7317 - val_loss: 1.3667 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.06941\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.7756 - accuracy: 0.8537 - val_loss: 0.9919 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00044: val_loss improved from 1.06941 to 0.99191, saving model to ./mod2.h5\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.6628 - accuracy: 0.9634 - val_loss: 1.4856 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.99191\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.8777 - accuracy: 0.7805 - val_loss: 0.9894 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.99191 to 0.98940, saving model to ./mod2.h5\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.8054 - accuracy: 0.8537 - val_loss: 1.2203 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.98940\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.7505 - accuracy: 0.8780 - val_loss: 0.9628 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.98940 to 0.96285, saving model to ./mod2.h5\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.8334 - accuracy: 0.8049 - val_loss: 1.1792 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.96285\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.8675 - accuracy: 0.7561 - val_loss: 0.9718 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.96285\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.9339 - accuracy: 0.7561 - val_loss: 0.9815 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.96285\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.7969 - accuracy: 0.8171 - val_loss: 1.3650 - val_accuracy: 0.4286\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.96285\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.8853 - accuracy: 0.6829 - val_loss: 0.9803 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.96285\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.7660 - accuracy: 0.8780 - val_loss: 0.9657 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.96285\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.7354 - accuracy: 0.8659 - val_loss: 1.1415 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.96285\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.6973 - accuracy: 0.9390 - val_loss: 1.0412 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.96285\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.6069 - accuracy: 0.9634 - val_loss: 0.9524 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.96285 to 0.95242, saving model to ./mod2.h5\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.6013 - accuracy: 0.9390 - val_loss: 1.0582 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.95242\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.5782 - accuracy: 0.9390 - val_loss: 0.9530 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.95242\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.5576 - accuracy: 0.9634 - val_loss: 1.0245 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.95242\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.5442 - accuracy: 0.9756 - val_loss: 0.9363 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.95242 to 0.93629, saving model to ./mod2.h5\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.5361 - accuracy: 0.9512 - val_loss: 1.0118 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.93629\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.5670 - accuracy: 0.9146 - val_loss: 0.8817 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.93629 to 0.88166, saving model to ./mod2.h5\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.6531 - accuracy: 0.9146 - val_loss: 1.0892 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.88166\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.5484 - accuracy: 0.9390 - val_loss: 0.8948 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.88166\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.4974 - accuracy: 1.0000 - val_loss: 0.9262 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.88166\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.4942 - accuracy: 0.9878 - val_loss: 0.9363 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.88166\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.4699 - accuracy: 1.0000 - val_loss: 0.9519 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.88166\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.4856 - accuracy: 0.9878 - val_loss: 0.8834 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.88166\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.4813 - accuracy: 0.9878 - val_loss: 0.8373 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.88166 to 0.83728, saving model to ./mod2.h5\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.4824 - accuracy: 0.9878 - val_loss: 0.8868 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.83728\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4829 - accuracy: 0.9878 - val_loss: 0.8225 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.83728 to 0.82251, saving model to ./mod2.h5\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.5417 - accuracy: 0.9390 - val_loss: 1.1433 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.82251\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.5155 - accuracy: 0.9756 - val_loss: 0.8285 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.82251\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.4997 - accuracy: 0.9390 - val_loss: 1.0546 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.82251\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4701 - accuracy: 0.9878 - val_loss: 0.8273 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.82251\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4563 - accuracy: 0.9878 - val_loss: 0.8876 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.82251\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4363 - accuracy: 1.0000 - val_loss: 0.9036 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.82251\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.4308 - accuracy: 1.0000 - val_loss: 0.9704 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.82251\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.4388 - accuracy: 1.0000 - val_loss: 0.7987 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.82251 to 0.79874, saving model to ./mod2.h5\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.4460 - accuracy: 0.9878 - val_loss: 1.0204 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.79874\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.4684 - accuracy: 0.9878 - val_loss: 0.8108 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.79874\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.5335 - accuracy: 0.9268 - val_loss: 1.1725 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.79874\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.4825 - accuracy: 0.9756 - val_loss: 0.8069 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.79874\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.4575 - accuracy: 0.9878 - val_loss: 0.9123 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.79874\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.4315 - accuracy: 1.0000 - val_loss: 0.8170 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.79874\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.4276 - accuracy: 1.0000 - val_loss: 0.8094 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.79874\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.4300 - accuracy: 1.0000 - val_loss: 0.9608 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.79874\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.4147 - accuracy: 1.0000 - val_loss: 0.7896 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00089: val_loss improved from 0.79874 to 0.78958, saving model to ./mod2.h5\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.4197 - accuracy: 1.0000 - val_loss: 0.8440 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.78958\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4096 - accuracy: 1.0000 - val_loss: 0.8326 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.78958\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4020 - accuracy: 1.0000 - val_loss: 0.8240 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.78958\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.4048 - accuracy: 1.0000 - val_loss: 0.8607 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.78958\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.4065 - accuracy: 1.0000 - val_loss: 0.7904 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.78958\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.4082 - accuracy: 1.0000 - val_loss: 0.7879 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.78958 to 0.78786, saving model to ./mod2.h5\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3998 - accuracy: 1.0000 - val_loss: 0.9068 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.78786\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.4106 - accuracy: 1.0000 - val_loss: 0.7898 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.78786\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.4073 - accuracy: 1.0000 - val_loss: 0.9087 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.78786\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.4294 - accuracy: 0.9878 - val_loss: 0.7668 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00099: val_loss improved from 0.78786 to 0.76680, saving model to ./mod2.h5\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.4461 - accuracy: 0.9634 - val_loss: 0.9158 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.76680\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.4148 - accuracy: 1.0000 - val_loss: 0.8136 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.76680\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3976 - accuracy: 1.0000 - val_loss: 0.7475 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00102: val_loss improved from 0.76680 to 0.74747, saving model to ./mod2.h5\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3986 - accuracy: 1.0000 - val_loss: 0.7839 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.74747\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3963 - accuracy: 1.0000 - val_loss: 0.7924 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.74747\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3946 - accuracy: 1.0000 - val_loss: 0.7845 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.74747\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3922 - accuracy: 1.0000 - val_loss: 0.7654 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.74747\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3904 - accuracy: 1.0000 - val_loss: 0.8386 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.74747\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3946 - accuracy: 1.0000 - val_loss: 0.7488 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.74747\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3956 - accuracy: 1.0000 - val_loss: 0.7663 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.74747\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3896 - accuracy: 1.0000 - val_loss: 0.9155 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.74747\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3967 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.74747\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.4073 - accuracy: 0.9878 - val_loss: 0.9169 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.74747\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.4110 - accuracy: 1.0000 - val_loss: 0.7464 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00113: val_loss improved from 0.74747 to 0.74643, saving model to ./mod2.h5\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3992 - accuracy: 1.0000 - val_loss: 0.7869 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.74643\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3943 - accuracy: 1.0000 - val_loss: 0.9842 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.74643\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.3911 - accuracy: 1.0000 - val_loss: 0.7619 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.74643\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4006 - accuracy: 1.0000 - val_loss: 0.8691 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.74643\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3894 - accuracy: 1.0000 - val_loss: 0.7661 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.74643\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3893 - accuracy: 1.0000 - val_loss: 0.7507 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.74643\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3798 - accuracy: 1.0000 - val_loss: 0.9182 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.74643\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.3855 - accuracy: 1.0000 - val_loss: 0.7598 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.74643\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3860 - accuracy: 1.0000 - val_loss: 0.8247 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.74643\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3844 - accuracy: 1.0000 - val_loss: 0.8909 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.74643\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3796 - accuracy: 1.0000 - val_loss: 0.7497 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.74643\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3815 - accuracy: 1.0000 - val_loss: 0.7614 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.74643\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3764 - accuracy: 1.0000 - val_loss: 0.8565 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.74643\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3779 - accuracy: 1.0000 - val_loss: 0.7638 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.74643\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3726 - accuracy: 1.0000 - val_loss: 0.7414 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00128: val_loss improved from 0.74643 to 0.74138, saving model to ./mod2.h5\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3742 - accuracy: 1.0000 - val_loss: 0.8028 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.74138\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3747 - accuracy: 1.0000 - val_loss: 0.8841 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.74138\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3757 - accuracy: 1.0000 - val_loss: 0.7456 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.74138\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3751 - accuracy: 1.0000 - val_loss: 0.7749 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.74138\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3737 - accuracy: 1.0000 - val_loss: 0.8008 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.74138\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.3690 - accuracy: 1.0000 - val_loss: 0.7306 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00134: val_loss improved from 0.74138 to 0.73063, saving model to ./mod2.h5\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3689 - accuracy: 1.0000 - val_loss: 0.7847 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.73063\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.3714 - accuracy: 1.0000 - val_loss: 0.7963 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.73063\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3668 - accuracy: 1.0000 - val_loss: 0.7253 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00137: val_loss improved from 0.73063 to 0.72531, saving model to ./mod2.h5\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3708 - accuracy: 1.0000 - val_loss: 0.7506 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.72531\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3734 - accuracy: 1.0000 - val_loss: 0.7821 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.72531\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3647 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.72531\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3683 - accuracy: 1.0000 - val_loss: 0.7412 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.72531\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3687 - accuracy: 1.0000 - val_loss: 0.7470 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.72531\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.3685 - accuracy: 1.0000 - val_loss: 0.8858 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.72531\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3706 - accuracy: 1.0000 - val_loss: 0.7420 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.72531\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3648 - accuracy: 1.0000 - val_loss: 0.7389 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.72531\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3641 - accuracy: 1.0000 - val_loss: 0.7930 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.72531\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.3650 - accuracy: 1.0000 - val_loss: 0.7403 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.72531\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3620 - accuracy: 1.0000 - val_loss: 0.7384 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.72531\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3627 - accuracy: 1.0000 - val_loss: 0.7936 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.72531\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3654 - accuracy: 1.0000 - val_loss: 0.7496 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.72531\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3637 - accuracy: 1.0000 - val_loss: 0.7201 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00151: val_loss improved from 0.72531 to 0.72013, saving model to ./mod2.h5\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3640 - accuracy: 1.0000 - val_loss: 0.7907 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.72013\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3624 - accuracy: 1.0000 - val_loss: 0.8070 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.72013\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3597 - accuracy: 1.0000 - val_loss: 0.7277 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.72013\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3633 - accuracy: 1.0000 - val_loss: 0.7425 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.72013\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3602 - accuracy: 1.0000 - val_loss: 0.8140 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.72013\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3595 - accuracy: 1.0000 - val_loss: 0.7647 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.72013\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3610 - accuracy: 1.0000 - val_loss: 0.7295 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.72013\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3622 - accuracy: 1.0000 - val_loss: 0.7850 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.72013\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.3651 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00160: val_loss improved from 0.72013 to 0.71395, saving model to ./mod2.h5\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3587 - accuracy: 1.0000 - val_loss: 0.7791 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.71395\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3593 - accuracy: 1.0000 - val_loss: 0.7649 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.71395\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3594 - accuracy: 1.0000 - val_loss: 0.7225 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.71395\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3568 - accuracy: 1.0000 - val_loss: 0.8296 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.71395\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3593 - accuracy: 1.0000 - val_loss: 0.7644 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.71395\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3564 - accuracy: 1.0000 - val_loss: 0.7333 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.71395\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3581 - accuracy: 1.0000 - val_loss: 0.7411 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.71395\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3564 - accuracy: 1.0000 - val_loss: 0.7583 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.71395\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3572 - accuracy: 1.0000 - val_loss: 0.7250 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.71395\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3599 - accuracy: 1.0000 - val_loss: 0.7678 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.71395\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3564 - accuracy: 1.0000 - val_loss: 0.7707 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.71395\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3546 - accuracy: 1.0000 - val_loss: 0.7243 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.71395\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3552 - accuracy: 1.0000 - val_loss: 0.8219 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.71395\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3560 - accuracy: 1.0000 - val_loss: 0.7217 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.71395\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3564 - accuracy: 1.0000 - val_loss: 0.7151 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.71395\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3555 - accuracy: 1.0000 - val_loss: 0.8184 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.71395\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3572 - accuracy: 1.0000 - val_loss: 0.7564 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.71395\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3545 - accuracy: 1.0000 - val_loss: 0.7189 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.71395\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3552 - accuracy: 1.0000 - val_loss: 0.7517 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.71395\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3559 - accuracy: 1.0000 - val_loss: 0.7769 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.71395\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3546 - accuracy: 1.0000 - val_loss: 0.7141 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.71395\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3556 - accuracy: 1.0000 - val_loss: 0.7966 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.71395\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3551 - accuracy: 1.0000 - val_loss: 0.7342 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.71395\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3525 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.71395\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3520 - accuracy: 1.0000 - val_loss: 0.7453 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.71395\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3527 - accuracy: 1.0000 - val_loss: 0.7370 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.71395\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3524 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.71395\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3499 - accuracy: 1.0000 - val_loss: 0.7373 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.71395\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3522 - accuracy: 1.0000 - val_loss: 0.8204 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.71395\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3544 - accuracy: 1.0000 - val_loss: 0.7572 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.71395\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3500 - accuracy: 1.0000 - val_loss: 0.7115 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00191: val_loss improved from 0.71395 to 0.71149, saving model to ./mod2.h5\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.3559 - accuracy: 1.0000 - val_loss: 0.8012 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.71149\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3539 - accuracy: 1.0000 - val_loss: 0.7868 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.71149\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3510 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.71149\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3563 - accuracy: 1.0000 - val_loss: 0.7170 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.71149\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3488 - accuracy: 1.0000 - val_loss: 0.8404 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.71149\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3540 - accuracy: 1.0000 - val_loss: 0.7129 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.71149\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3549 - accuracy: 1.0000 - val_loss: 0.7406 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.71149\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3545 - accuracy: 1.0000 - val_loss: 0.7892 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.71149\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3508 - accuracy: 1.0000 - val_loss: 0.7113 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00200: val_loss improved from 0.71149 to 0.71134, saving model to ./mod2.h5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 26ms/step - loss: 0.3604 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6248 - accuracy: 0.8800\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7113 - accuracy: 0.7857\n",
            "(None, 19, 19, 19, 1)\n",
            "Model: \"model_23\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_25 (InputLayer)           [(None, 19, 19, 19,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3455 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3457 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3459 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3461 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3463 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3465 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3467 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3469 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3471 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3473 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3475 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3477 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3479 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3481 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3483 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3485 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3487 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3489 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3491 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3493 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3495 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3497 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3499 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3501 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3503 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3505 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3507 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3509 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3511 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3513 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3515 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3517 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3519 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3521 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3523 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3525 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3527 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3529 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3531 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3533 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3535 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3537 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3539 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3541 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3543 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3545 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3547 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3549 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3551 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3553 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3555 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3557 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3559 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3561 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3563 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3565 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3567 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3569 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3571 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3573 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3575 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3577 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3579 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3581 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3583 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3585 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3587 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3589 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3591 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3593 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3595 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3597 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3599 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3601 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3603 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3605 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3607 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3609 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3611 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3613 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3615 (Lambda)            (None, 19, 3, 19, 1) 0           input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3454 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3455[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3456 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3457[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3458 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3459[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3460 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3461[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3462 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3463[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3464 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3465[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3466 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3467[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3468 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3469[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3470 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3471[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3472 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3473[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3474 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3475[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3476 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3477[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3478 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3479[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3480 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3481[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3482 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3483[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3484 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3485[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3486 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3487[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3488 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3489[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3490 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3491[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3492 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3493[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3494 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3495[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3496 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3497[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3498 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3499[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3500 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3501[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3502 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3503[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3504 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3505[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3506 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3507[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3508 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3509[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3510 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3511[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3512 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3513[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3514 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3515[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3516 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3517[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3518 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3519[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3520 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3521[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3522 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3523[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3524 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3525[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3526 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3527[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3528 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3529[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3530 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3531[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3532 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3533[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3534 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3535[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3536 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3537[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3538 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3539[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3540 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3541[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3542 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3543[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3544 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3545[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3546 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3547[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3548 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3549[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3550 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3551[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3552 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3553[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3554 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3555[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3556 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3557[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3558 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3559[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3560 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3561[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3562 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3563[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3564 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3565[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3566 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3567[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3568 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3569[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3570 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3571[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3572 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3573[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3574 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3575[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3576 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3577[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3578 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3579[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3580 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3581[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3582 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3583[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3584 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3585[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3586 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3587[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3588 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3589[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3590 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3591[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3592 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3593[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3594 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3595[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3596 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3597[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3598 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3599[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3600 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3601[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3602 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3603[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3604 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3605[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3606 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3607[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3608 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3609[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3610 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3611[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3612 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3613[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3614 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3615[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1727 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3454[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1728 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3456[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1729 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3458[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1730 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3460[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1731 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3462[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1732 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3464[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1733 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3466[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1734 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3468[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1735 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3470[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1736 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3472[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1737 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3474[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1738 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3476[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1739 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3478[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1740 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3480[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1741 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3482[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1742 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3484[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1743 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3486[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1744 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3488[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1745 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3490[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1746 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3492[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1747 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3494[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1748 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3496[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1749 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3498[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1750 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3500[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1751 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3502[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1752 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3504[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1753 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3506[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1754 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3508[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1755 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3510[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1756 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3512[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1757 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3514[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1758 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3516[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1759 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3518[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1760 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3520[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1761 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3522[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1762 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3524[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1763 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3526[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1764 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3528[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1765 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3530[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1766 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3532[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1767 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3534[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1768 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3536[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1769 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3538[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1770 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3540[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1771 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3542[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1772 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3544[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1773 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3546[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1774 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3548[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1775 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3550[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1776 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3552[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1777 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3554[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1778 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3556[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1779 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3558[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1780 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3560[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1781 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3562[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1782 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3564[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1783 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3566[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1784 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3568[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1785 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3570[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1786 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3572[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1787 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3574[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1788 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3576[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1789 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3578[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1790 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3580[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1791 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3582[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1792 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3584[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1793 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3586[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1794 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3588[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1795 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3590[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1796 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3592[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1797 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3594[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1798 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3596[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1799 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3598[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1800 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3600[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1801 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3602[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1802 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3604[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1803 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3606[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1804 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3608[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1805 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3610[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1806 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3612[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1807 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3614[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1727 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1727[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1728 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1728[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1729 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1729[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1730 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1730[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1731 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1731[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1732 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1732[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1733 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1733[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1734 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1734[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1735 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1735[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1736 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1736[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1737 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1737[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1738 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1738[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1739 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1739[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1740 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1740[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1741 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1741[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1742 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1742[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1743 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1743[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1744 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1744[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1745 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1745[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1746 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1746[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1747 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1747[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1748 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1748[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1749 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1749[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1750 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1750[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1751 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1751[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1752 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1752[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1753 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1753[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1754 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1754[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1755 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1755[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1756 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1756[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1757 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1757[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1758 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1758[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1759 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1759[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1760 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1760[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1761 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1761[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1762 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1762[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1763 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1763[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1764 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1764[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1765 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1765[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1766 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1766[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1767 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1767[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1768 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1768[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1769 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1769[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1770 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1770[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1771 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1771[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1772 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1772[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1773 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1773[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1774 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1774[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1775 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1775[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1776 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1776[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1777 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1777[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1778 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1778[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1779 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1779[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1780 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1780[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1781 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1781[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1782 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1782[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1783 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1783[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1784 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1784[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1785 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1785[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1786 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1786[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1787 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1787[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1788 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1788[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1789 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1789[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1790 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1790[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1791 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1791[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1792 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1792[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1793 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1793[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1794 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1794[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1795 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1795[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1796 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1796[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1797 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1797[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1798 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1798[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1799 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1799[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1800 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1800[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1801 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1801[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1802 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1802[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1803 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1803[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1804 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1804[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1805 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1805[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1806 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1806[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1807 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1807[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1275 (Glob (None, 16)           0           dropout_1727[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1276 (Glob (None, 16)           0           dropout_1728[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1277 (Glob (None, 16)           0           dropout_1729[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1278 (Glob (None, 16)           0           dropout_1730[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1279 (Glob (None, 16)           0           dropout_1731[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1280 (Glob (None, 16)           0           dropout_1732[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1281 (Glob (None, 16)           0           dropout_1733[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1282 (Glob (None, 16)           0           dropout_1734[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1283 (Glob (None, 16)           0           dropout_1735[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1284 (Glob (None, 16)           0           dropout_1736[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1285 (Glob (None, 16)           0           dropout_1737[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1286 (Glob (None, 16)           0           dropout_1738[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1287 (Glob (None, 16)           0           dropout_1739[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1288 (Glob (None, 16)           0           dropout_1740[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1289 (Glob (None, 16)           0           dropout_1741[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1290 (Glob (None, 16)           0           dropout_1742[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1291 (Glob (None, 16)           0           dropout_1743[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1292 (Glob (None, 16)           0           dropout_1744[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1293 (Glob (None, 16)           0           dropout_1745[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1294 (Glob (None, 16)           0           dropout_1746[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1295 (Glob (None, 16)           0           dropout_1747[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1296 (Glob (None, 16)           0           dropout_1748[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1297 (Glob (None, 16)           0           dropout_1749[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1298 (Glob (None, 16)           0           dropout_1750[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1299 (Glob (None, 16)           0           dropout_1751[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1300 (Glob (None, 16)           0           dropout_1752[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1301 (Glob (None, 16)           0           dropout_1753[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1302 (Glob (None, 16)           0           dropout_1754[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1303 (Glob (None, 16)           0           dropout_1755[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1304 (Glob (None, 16)           0           dropout_1756[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1305 (Glob (None, 16)           0           dropout_1757[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1306 (Glob (None, 16)           0           dropout_1758[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1307 (Glob (None, 16)           0           dropout_1759[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1308 (Glob (None, 16)           0           dropout_1760[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1309 (Glob (None, 16)           0           dropout_1761[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1310 (Glob (None, 16)           0           dropout_1762[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1311 (Glob (None, 16)           0           dropout_1763[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1312 (Glob (None, 16)           0           dropout_1764[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1313 (Glob (None, 16)           0           dropout_1765[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1314 (Glob (None, 16)           0           dropout_1766[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1315 (Glob (None, 16)           0           dropout_1767[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1316 (Glob (None, 16)           0           dropout_1768[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1317 (Glob (None, 16)           0           dropout_1769[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1318 (Glob (None, 16)           0           dropout_1770[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1319 (Glob (None, 16)           0           dropout_1771[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1320 (Glob (None, 16)           0           dropout_1772[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1321 (Glob (None, 16)           0           dropout_1773[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1322 (Glob (None, 16)           0           dropout_1774[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1323 (Glob (None, 16)           0           dropout_1775[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1324 (Glob (None, 16)           0           dropout_1776[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1325 (Glob (None, 16)           0           dropout_1777[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1326 (Glob (None, 16)           0           dropout_1778[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1327 (Glob (None, 16)           0           dropout_1779[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1328 (Glob (None, 16)           0           dropout_1780[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1329 (Glob (None, 16)           0           dropout_1781[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1330 (Glob (None, 16)           0           dropout_1782[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1331 (Glob (None, 16)           0           dropout_1783[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1332 (Glob (None, 16)           0           dropout_1784[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1333 (Glob (None, 16)           0           dropout_1785[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1334 (Glob (None, 16)           0           dropout_1786[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1335 (Glob (None, 16)           0           dropout_1787[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1336 (Glob (None, 16)           0           dropout_1788[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1337 (Glob (None, 16)           0           dropout_1789[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1338 (Glob (None, 16)           0           dropout_1790[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1339 (Glob (None, 16)           0           dropout_1791[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1340 (Glob (None, 16)           0           dropout_1792[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1341 (Glob (None, 16)           0           dropout_1793[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1342 (Glob (None, 16)           0           dropout_1794[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1343 (Glob (None, 16)           0           dropout_1795[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1344 (Glob (None, 16)           0           dropout_1796[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1345 (Glob (None, 16)           0           dropout_1797[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1346 (Glob (None, 16)           0           dropout_1798[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1347 (Glob (None, 16)           0           dropout_1799[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1348 (Glob (None, 16)           0           dropout_1800[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1349 (Glob (None, 16)           0           dropout_1801[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1350 (Glob (None, 16)           0           dropout_1802[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1351 (Glob (None, 16)           0           dropout_1803[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1352 (Glob (None, 16)           0           dropout_1804[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1353 (Glob (None, 16)           0           dropout_1805[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1354 (Glob (None, 16)           0           dropout_1806[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1355 (Glob (None, 16)           0           dropout_1807[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 1296)         0           global_max_pooling3d_1275[0][0]  \n",
            "                                                                 global_max_pooling3d_1276[0][0]  \n",
            "                                                                 global_max_pooling3d_1277[0][0]  \n",
            "                                                                 global_max_pooling3d_1278[0][0]  \n",
            "                                                                 global_max_pooling3d_1279[0][0]  \n",
            "                                                                 global_max_pooling3d_1280[0][0]  \n",
            "                                                                 global_max_pooling3d_1281[0][0]  \n",
            "                                                                 global_max_pooling3d_1282[0][0]  \n",
            "                                                                 global_max_pooling3d_1283[0][0]  \n",
            "                                                                 global_max_pooling3d_1284[0][0]  \n",
            "                                                                 global_max_pooling3d_1285[0][0]  \n",
            "                                                                 global_max_pooling3d_1286[0][0]  \n",
            "                                                                 global_max_pooling3d_1287[0][0]  \n",
            "                                                                 global_max_pooling3d_1288[0][0]  \n",
            "                                                                 global_max_pooling3d_1289[0][0]  \n",
            "                                                                 global_max_pooling3d_1290[0][0]  \n",
            "                                                                 global_max_pooling3d_1291[0][0]  \n",
            "                                                                 global_max_pooling3d_1292[0][0]  \n",
            "                                                                 global_max_pooling3d_1293[0][0]  \n",
            "                                                                 global_max_pooling3d_1294[0][0]  \n",
            "                                                                 global_max_pooling3d_1295[0][0]  \n",
            "                                                                 global_max_pooling3d_1296[0][0]  \n",
            "                                                                 global_max_pooling3d_1297[0][0]  \n",
            "                                                                 global_max_pooling3d_1298[0][0]  \n",
            "                                                                 global_max_pooling3d_1299[0][0]  \n",
            "                                                                 global_max_pooling3d_1300[0][0]  \n",
            "                                                                 global_max_pooling3d_1301[0][0]  \n",
            "                                                                 global_max_pooling3d_1302[0][0]  \n",
            "                                                                 global_max_pooling3d_1303[0][0]  \n",
            "                                                                 global_max_pooling3d_1304[0][0]  \n",
            "                                                                 global_max_pooling3d_1305[0][0]  \n",
            "                                                                 global_max_pooling3d_1306[0][0]  \n",
            "                                                                 global_max_pooling3d_1307[0][0]  \n",
            "                                                                 global_max_pooling3d_1308[0][0]  \n",
            "                                                                 global_max_pooling3d_1309[0][0]  \n",
            "                                                                 global_max_pooling3d_1310[0][0]  \n",
            "                                                                 global_max_pooling3d_1311[0][0]  \n",
            "                                                                 global_max_pooling3d_1312[0][0]  \n",
            "                                                                 global_max_pooling3d_1313[0][0]  \n",
            "                                                                 global_max_pooling3d_1314[0][0]  \n",
            "                                                                 global_max_pooling3d_1315[0][0]  \n",
            "                                                                 global_max_pooling3d_1316[0][0]  \n",
            "                                                                 global_max_pooling3d_1317[0][0]  \n",
            "                                                                 global_max_pooling3d_1318[0][0]  \n",
            "                                                                 global_max_pooling3d_1319[0][0]  \n",
            "                                                                 global_max_pooling3d_1320[0][0]  \n",
            "                                                                 global_max_pooling3d_1321[0][0]  \n",
            "                                                                 global_max_pooling3d_1322[0][0]  \n",
            "                                                                 global_max_pooling3d_1323[0][0]  \n",
            "                                                                 global_max_pooling3d_1324[0][0]  \n",
            "                                                                 global_max_pooling3d_1325[0][0]  \n",
            "                                                                 global_max_pooling3d_1326[0][0]  \n",
            "                                                                 global_max_pooling3d_1327[0][0]  \n",
            "                                                                 global_max_pooling3d_1328[0][0]  \n",
            "                                                                 global_max_pooling3d_1329[0][0]  \n",
            "                                                                 global_max_pooling3d_1330[0][0]  \n",
            "                                                                 global_max_pooling3d_1331[0][0]  \n",
            "                                                                 global_max_pooling3d_1332[0][0]  \n",
            "                                                                 global_max_pooling3d_1333[0][0]  \n",
            "                                                                 global_max_pooling3d_1334[0][0]  \n",
            "                                                                 global_max_pooling3d_1335[0][0]  \n",
            "                                                                 global_max_pooling3d_1336[0][0]  \n",
            "                                                                 global_max_pooling3d_1337[0][0]  \n",
            "                                                                 global_max_pooling3d_1338[0][0]  \n",
            "                                                                 global_max_pooling3d_1339[0][0]  \n",
            "                                                                 global_max_pooling3d_1340[0][0]  \n",
            "                                                                 global_max_pooling3d_1341[0][0]  \n",
            "                                                                 global_max_pooling3d_1342[0][0]  \n",
            "                                                                 global_max_pooling3d_1343[0][0]  \n",
            "                                                                 global_max_pooling3d_1344[0][0]  \n",
            "                                                                 global_max_pooling3d_1345[0][0]  \n",
            "                                                                 global_max_pooling3d_1346[0][0]  \n",
            "                                                                 global_max_pooling3d_1347[0][0]  \n",
            "                                                                 global_max_pooling3d_1348[0][0]  \n",
            "                                                                 global_max_pooling3d_1349[0][0]  \n",
            "                                                                 global_max_pooling3d_1350[0][0]  \n",
            "                                                                 global_max_pooling3d_1351[0][0]  \n",
            "                                                                 global_max_pooling3d_1352[0][0]  \n",
            "                                                                 global_max_pooling3d_1353[0][0]  \n",
            "                                                                 global_max_pooling3d_1354[0][0]  \n",
            "                                                                 global_max_pooling3d_1355[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_92 (Dense)                (None, 512)          664064      concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_93 (Dense)                (None, 512)          262656      dense_92[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_94 (Dense)                (None, 512)          262656      dense_93[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_95 (Dense)                (None, 1)            513         dense_94[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,226,177\n",
            "Trainable params: 1,226,177\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 14s 1s/step - loss: 99.5151 - accuracy: 0.5000 - val_loss: 93.4777 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 93.47767, saving model to ./mod3.h5\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 91.8976 - accuracy: 0.5000 - val_loss: 86.3395 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00002: val_loss improved from 93.47767 to 86.33952, saving model to ./mod3.h5\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 84.8218 - accuracy: 0.5000 - val_loss: 79.5178 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00003: val_loss improved from 86.33952 to 79.51781, saving model to ./mod3.h5\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 78.0460 - accuracy: 0.4512 - val_loss: 73.0079 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00004: val_loss improved from 79.51781 to 73.00786, saving model to ./mod3.h5\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 71.6084 - accuracy: 0.5000 - val_loss: 66.7671 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00005: val_loss improved from 73.00786 to 66.76710, saving model to ./mod3.h5\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 65.3957 - accuracy: 0.5000 - val_loss: 60.8105 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00006: val_loss improved from 66.76710 to 60.81048, saving model to ./mod3.h5\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 59.5027 - accuracy: 0.5000 - val_loss: 55.1458 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00007: val_loss improved from 60.81048 to 55.14579, saving model to ./mod3.h5\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 53.8955 - accuracy: 0.6341 - val_loss: 49.7572 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00008: val_loss improved from 55.14579 to 49.75723, saving model to ./mod3.h5\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 48.5821 - accuracy: 0.5000 - val_loss: 44.6515 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00009: val_loss improved from 49.75723 to 44.65148, saving model to ./mod3.h5\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 43.5307 - accuracy: 0.5000 - val_loss: 39.8315 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00010: val_loss improved from 44.65148 to 39.83150, saving model to ./mod3.h5\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 38.7825 - accuracy: 0.5000 - val_loss: 35.2990 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00011: val_loss improved from 39.83150 to 35.29895, saving model to ./mod3.h5\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 34.3165 - accuracy: 0.5000 - val_loss: 31.0477 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00012: val_loss improved from 35.29895 to 31.04771, saving model to ./mod3.h5\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 30.1225 - accuracy: 0.5122 - val_loss: 27.0830 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00013: val_loss improved from 31.04771 to 27.08301, saving model to ./mod3.h5\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 26.2309 - accuracy: 0.5000 - val_loss: 23.4252 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00014: val_loss improved from 27.08301 to 23.42516, saving model to ./mod3.h5\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 22.6364 - accuracy: 0.5000 - val_loss: 20.0441 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00015: val_loss improved from 23.42516 to 20.04412, saving model to ./mod3.h5\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 19.3223 - accuracy: 0.6098 - val_loss: 16.9543 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00016: val_loss improved from 20.04412 to 16.95431, saving model to ./mod3.h5\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 16.2960 - accuracy: 0.5000 - val_loss: 14.1814 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00017: val_loss improved from 16.95431 to 14.18140, saving model to ./mod3.h5\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 13.5903 - accuracy: 0.6341 - val_loss: 11.6947 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00018: val_loss improved from 14.18140 to 11.69466, saving model to ./mod3.h5\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 11.1719 - accuracy: 0.5000 - val_loss: 9.5004 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00019: val_loss improved from 11.69466 to 9.50044, saving model to ./mod3.h5\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 9.0473 - accuracy: 0.5366 - val_loss: 7.6098 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00020: val_loss improved from 9.50044 to 7.60981, saving model to ./mod3.h5\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 7.2251 - accuracy: 0.5366 - val_loss: 6.0094 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00021: val_loss improved from 7.60981 to 6.00944, saving model to ./mod3.h5\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 5.6905 - accuracy: 0.5732 - val_loss: 4.7207 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00022: val_loss improved from 6.00944 to 4.72069, saving model to ./mod3.h5\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 4.4676 - accuracy: 0.6829 - val_loss: 3.7350 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00023: val_loss improved from 4.72069 to 3.73499, saving model to ./mod3.h5\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 3.5536 - accuracy: 0.5122 - val_loss: 3.0460 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00024: val_loss improved from 3.73499 to 3.04602, saving model to ./mod3.h5\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 2.9306 - accuracy: 0.5000 - val_loss: 2.6529 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00025: val_loss improved from 3.04602 to 2.65286, saving model to ./mod3.h5\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 2.6290 - accuracy: 0.5000 - val_loss: 2.5123 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00026: val_loss improved from 2.65286 to 2.51229, saving model to ./mod3.h5\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 2.4611 - accuracy: 0.5000 - val_loss: 2.2821 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00027: val_loss improved from 2.51229 to 2.28212, saving model to ./mod3.h5\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 2.2142 - accuracy: 0.5976 - val_loss: 2.0080 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00028: val_loss improved from 2.28212 to 2.00798, saving model to ./mod3.h5\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 1.9411 - accuracy: 0.5000 - val_loss: 1.7436 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00029: val_loss improved from 2.00798 to 1.74357, saving model to ./mod3.h5\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 1.6924 - accuracy: 0.5000 - val_loss: 1.5680 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.74357 to 1.56795, saving model to ./mod3.h5\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.5412 - accuracy: 0.5000 - val_loss: 1.4968 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.56795 to 1.49676, saving model to ./mod3.h5\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 1.4733 - accuracy: 0.5000 - val_loss: 1.3986 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.49676 to 1.39856, saving model to ./mod3.h5\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 1.3630 - accuracy: 0.7073 - val_loss: 1.2986 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.39856 to 1.29863, saving model to ./mod3.h5\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 1.2752 - accuracy: 0.5366 - val_loss: 1.2500 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.29863 to 1.25000, saving model to ./mod3.h5\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 1.2282 - accuracy: 0.6585 - val_loss: 1.2035 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.25000 to 1.20353, saving model to ./mod3.h5\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 1.1747 - accuracy: 0.7195 - val_loss: 1.1643 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00036: val_loss improved from 1.20353 to 1.16435, saving model to ./mod3.h5\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 1.1444 - accuracy: 0.5732 - val_loss: 1.1391 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00037: val_loss improved from 1.16435 to 1.13910, saving model to ./mod3.h5\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 1.1078 - accuracy: 0.5366 - val_loss: 1.1173 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00038: val_loss improved from 1.13910 to 1.11729, saving model to ./mod3.h5\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.1138 - accuracy: 0.5976 - val_loss: 1.0953 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.11729 to 1.09530, saving model to ./mod3.h5\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 1s 227ms/step - loss: 1.0526 - accuracy: 0.6707 - val_loss: 1.0778 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00040: val_loss improved from 1.09530 to 1.07775, saving model to ./mod3.h5\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 1.0313 - accuracy: 0.6585 - val_loss: 1.0630 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00041: val_loss improved from 1.07775 to 1.06298, saving model to ./mod3.h5\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.9884 - accuracy: 0.7317 - val_loss: 1.0482 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00042: val_loss improved from 1.06298 to 1.04821, saving model to ./mod3.h5\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.9911 - accuracy: 0.6585 - val_loss: 1.0403 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00043: val_loss improved from 1.04821 to 1.04027, saving model to ./mod3.h5\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 1.0176 - accuracy: 0.5732 - val_loss: 1.0254 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00044: val_loss improved from 1.04027 to 1.02542, saving model to ./mod3.h5\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.9234 - accuracy: 0.8171 - val_loss: 1.0512 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 1.02542\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.9343 - accuracy: 0.7561 - val_loss: 1.0080 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00046: val_loss improved from 1.02542 to 1.00800, saving model to ./mod3.h5\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.8873 - accuracy: 0.8415 - val_loss: 1.0012 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00047: val_loss improved from 1.00800 to 1.00119, saving model to ./mod3.h5\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.8778 - accuracy: 0.8049 - val_loss: 1.0893 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 1.00119\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 1.1498 - accuracy: 0.5366 - val_loss: 0.9875 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00049: val_loss improved from 1.00119 to 0.98751, saving model to ./mod3.h5\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 1.0051 - accuracy: 0.6951 - val_loss: 1.0605 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.98751\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.9779 - accuracy: 0.6463 - val_loss: 1.0779 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.98751\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 1.0265 - accuracy: 0.5244 - val_loss: 1.0618 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.98751\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 1s 226ms/step - loss: 0.9590 - accuracy: 0.6585 - val_loss: 1.0147 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.98751\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.9372 - accuracy: 0.8049 - val_loss: 1.0144 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.98751\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.9424 - accuracy: 0.6829 - val_loss: 0.9938 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.98751\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.8664 - accuracy: 0.8293 - val_loss: 1.0086 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.98751\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.8225 - accuracy: 0.8659 - val_loss: 0.9778 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.98751 to 0.97775, saving model to ./mod3.h5\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.8840 - accuracy: 0.7683 - val_loss: 0.9668 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.97775 to 0.96679, saving model to ./mod3.h5\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.8133 - accuracy: 0.7805 - val_loss: 0.9436 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.96679 to 0.94359, saving model to ./mod3.h5\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.7348 - accuracy: 0.8902 - val_loss: 0.9236 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.94359 to 0.92360, saving model to ./mod3.h5\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.7103 - accuracy: 0.9024 - val_loss: 0.9724 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.92360\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.6898 - accuracy: 0.8780 - val_loss: 0.8940 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.92360 to 0.89399, saving model to ./mod3.h5\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.6723 - accuracy: 0.8780 - val_loss: 1.0314 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.89399\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.7225 - accuracy: 0.8659 - val_loss: 0.8828 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.89399 to 0.88276, saving model to ./mod3.h5\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.6062 - accuracy: 0.9146 - val_loss: 0.9166 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.88276\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.6131 - accuracy: 0.9024 - val_loss: 0.8360 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.88276 to 0.83596, saving model to ./mod3.h5\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.6248 - accuracy: 0.9146 - val_loss: 0.8981 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.83596\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.5616 - accuracy: 0.9146 - val_loss: 0.8037 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.83596 to 0.80365, saving model to ./mod3.h5\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.5698 - accuracy: 0.9390 - val_loss: 0.8941 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.80365\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.5935 - accuracy: 0.8659 - val_loss: 0.9310 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.80365\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.5959 - accuracy: 0.9268 - val_loss: 0.7690 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.80365 to 0.76895, saving model to ./mod3.h5\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.5171 - accuracy: 0.9756 - val_loss: 0.9044 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.76895\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.5704 - accuracy: 0.9024 - val_loss: 0.7828 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.76895\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.5418 - accuracy: 0.9512 - val_loss: 0.9145 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.76895\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.6888 - accuracy: 0.8415 - val_loss: 1.0366 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.76895\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.7765 - accuracy: 0.8171 - val_loss: 0.8489 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.76895\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.7649 - accuracy: 0.7927 - val_loss: 0.7948 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.76895\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.6746 - accuracy: 0.8659 - val_loss: 0.7896 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.76895\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.6208 - accuracy: 0.8780 - val_loss: 0.7415 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00079: val_loss improved from 0.76895 to 0.74149, saving model to ./mod3.h5\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.5173 - accuracy: 0.9512 - val_loss: 0.7401 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.74149 to 0.74013, saving model to ./mod3.h5\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.4679 - accuracy: 0.9878 - val_loss: 0.7688 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.74013\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.4789 - accuracy: 1.0000 - val_loss: 0.7369 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00082: val_loss improved from 0.74013 to 0.73687, saving model to ./mod3.h5\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.4794 - accuracy: 0.9756 - val_loss: 0.7442 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.73687\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4494 - accuracy: 1.0000 - val_loss: 0.7613 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.73687\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.4696 - accuracy: 0.9878 - val_loss: 0.7320 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.73687 to 0.73197, saving model to ./mod3.h5\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.4577 - accuracy: 1.0000 - val_loss: 0.7942 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.73197\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.4687 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.73197 to 0.71217, saving model to ./mod3.h5\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.4402 - accuracy: 0.9878 - val_loss: 0.6999 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.71217 to 0.69990, saving model to ./mod3.h5\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4477 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.69990\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4603 - accuracy: 0.9634 - val_loss: 0.7383 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.69990\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.4439 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00091: val_loss improved from 0.69990 to 0.69015, saving model to ./mod3.h5\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.4378 - accuracy: 0.9756 - val_loss: 0.6834 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00092: val_loss improved from 0.69015 to 0.68339, saving model to ./mod3.h5\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.4149 - accuracy: 1.0000 - val_loss: 0.6949 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.68339\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.4141 - accuracy: 1.0000 - val_loss: 0.6823 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.68339 to 0.68233, saving model to ./mod3.h5\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.4170 - accuracy: 1.0000 - val_loss: 0.6852 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.68233\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.4213 - accuracy: 1.0000 - val_loss: 0.6846 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.68233\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.4146 - accuracy: 1.0000 - val_loss: 0.7148 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.68233\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.4186 - accuracy: 1.0000 - val_loss: 0.7241 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.68233\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.4599 - accuracy: 0.9756 - val_loss: 0.9249 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.68233\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.4605 - accuracy: 0.9756 - val_loss: 0.7071 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.68233\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.4564 - accuracy: 0.9756 - val_loss: 0.7891 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.68233\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.4783 - accuracy: 0.9634 - val_loss: 0.7043 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.68233\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.4645 - accuracy: 0.9756 - val_loss: 0.7416 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.68233\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.4279 - accuracy: 1.0000 - val_loss: 0.6430 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00104: val_loss improved from 0.68233 to 0.64298, saving model to ./mod3.h5\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.4146 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.64298\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 1s 227ms/step - loss: 0.4388 - accuracy: 0.9634 - val_loss: 0.6507 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.64298\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.4243 - accuracy: 0.9878 - val_loss: 0.6371 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00107: val_loss improved from 0.64298 to 0.63713, saving model to ./mod3.h5\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.3984 - accuracy: 1.0000 - val_loss: 0.7762 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.63713\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.4150 - accuracy: 1.0000 - val_loss: 0.6506 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.63713\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.4142 - accuracy: 1.0000 - val_loss: 0.6565 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.63713\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3923 - accuracy: 1.0000 - val_loss: 0.6396 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.63713\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3940 - accuracy: 1.0000 - val_loss: 0.6338 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00112: val_loss improved from 0.63713 to 0.63381, saving model to ./mod3.h5\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3927 - accuracy: 1.0000 - val_loss: 0.6308 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00113: val_loss improved from 0.63381 to 0.63076, saving model to ./mod3.h5\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3932 - accuracy: 1.0000 - val_loss: 0.6396 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.63076\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3900 - accuracy: 1.0000 - val_loss: 0.6215 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00115: val_loss improved from 0.63076 to 0.62147, saving model to ./mod3.h5\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.3896 - accuracy: 1.0000 - val_loss: 0.6274 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.62147\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3995 - accuracy: 1.0000 - val_loss: 0.6165 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00117: val_loss improved from 0.62147 to 0.61652, saving model to ./mod3.h5\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3961 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.61652\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3906 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00119: val_loss improved from 0.61652 to 0.61017, saving model to ./mod3.h5\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3905 - accuracy: 1.0000 - val_loss: 0.6107 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.61017\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3858 - accuracy: 1.0000 - val_loss: 0.6206 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.61017\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3847 - accuracy: 1.0000 - val_loss: 0.6325 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.61017\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3886 - accuracy: 1.0000 - val_loss: 0.6236 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.61017\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.3846 - accuracy: 1.0000 - val_loss: 0.6618 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.61017\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3863 - accuracy: 1.0000 - val_loss: 0.6193 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.61017\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3876 - accuracy: 1.0000 - val_loss: 0.6401 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.61017\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3841 - accuracy: 1.0000 - val_loss: 0.6218 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.61017\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3823 - accuracy: 1.0000 - val_loss: 0.6313 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.61017\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3813 - accuracy: 1.0000 - val_loss: 0.6718 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.61017\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3841 - accuracy: 1.0000 - val_loss: 0.6169 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.61017\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3851 - accuracy: 1.0000 - val_loss: 0.6352 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.61017\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3815 - accuracy: 1.0000 - val_loss: 0.6341 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.61017\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3789 - accuracy: 1.0000 - val_loss: 0.6130 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.61017\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3831 - accuracy: 1.0000 - val_loss: 0.6129 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.61017\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3807 - accuracy: 1.0000 - val_loss: 0.6400 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.61017\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3769 - accuracy: 1.0000 - val_loss: 0.6111 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.61017\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3767 - accuracy: 1.0000 - val_loss: 0.6110 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.61017\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3797 - accuracy: 1.0000 - val_loss: 0.6780 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.61017\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.3781 - accuracy: 1.0000 - val_loss: 0.6131 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.61017\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3760 - accuracy: 1.0000 - val_loss: 0.6123 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.61017\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3746 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.61017\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3806 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.61017\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3834 - accuracy: 1.0000 - val_loss: 0.6137 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.61017\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3821 - accuracy: 1.0000 - val_loss: 0.6233 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.61017\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3737 - accuracy: 1.0000 - val_loss: 0.6622 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.61017\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.3746 - accuracy: 1.0000 - val_loss: 0.6109 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.61017\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3751 - accuracy: 1.0000 - val_loss: 0.6053 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00147: val_loss improved from 0.61017 to 0.60532, saving model to ./mod3.h5\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3715 - accuracy: 1.0000 - val_loss: 0.6579 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.60532\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3776 - accuracy: 1.0000 - val_loss: 0.6096 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.60532\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3784 - accuracy: 1.0000 - val_loss: 0.6348 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.60532\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3753 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.60532\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3763 - accuracy: 1.0000 - val_loss: 0.6082 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.60532\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3816 - accuracy: 1.0000 - val_loss: 0.6041 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00153: val_loss improved from 0.60532 to 0.60410, saving model to ./mod3.h5\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3696 - accuracy: 1.0000 - val_loss: 0.6264 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.60410\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3721 - accuracy: 1.0000 - val_loss: 0.5899 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00155: val_loss improved from 0.60410 to 0.58993, saving model to ./mod3.h5\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3752 - accuracy: 1.0000 - val_loss: 0.6014 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.58993\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3796 - accuracy: 1.0000 - val_loss: 0.6128 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.58993\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3735 - accuracy: 1.0000 - val_loss: 0.6514 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.58993\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3801 - accuracy: 1.0000 - val_loss: 0.6969 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.58993\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3822 - accuracy: 1.0000 - val_loss: 0.5916 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.58993\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3800 - accuracy: 1.0000 - val_loss: 0.6082 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.58993\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3710 - accuracy: 1.0000 - val_loss: 0.6464 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.58993\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3696 - accuracy: 1.0000 - val_loss: 0.6265 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.58993\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3819 - accuracy: 1.0000 - val_loss: 0.6633 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.58993\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3782 - accuracy: 1.0000 - val_loss: 0.5930 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.58993\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3728 - accuracy: 1.0000 - val_loss: 0.6008 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.58993\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3752 - accuracy: 1.0000 - val_loss: 0.8298 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.58993\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 0.3772 - accuracy: 1.0000 - val_loss: 0.6086 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.58993\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3792 - accuracy: 1.0000 - val_loss: 0.6426 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.58993\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3750 - accuracy: 1.0000 - val_loss: 0.6206 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.58993\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3775 - accuracy: 1.0000 - val_loss: 0.6011 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.58993\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3710 - accuracy: 1.0000 - val_loss: 0.7210 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.58993\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3667 - accuracy: 1.0000 - val_loss: 0.6165 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.58993\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3635 - accuracy: 1.0000 - val_loss: 0.5929 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.58993\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3758 - accuracy: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.58993\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3707 - accuracy: 1.0000 - val_loss: 0.5962 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.58993\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3667 - accuracy: 1.0000 - val_loss: 0.5932 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.58993\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 1s 268ms/step - loss: 0.3667 - accuracy: 1.0000 - val_loss: 0.6398 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.58993\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3670 - accuracy: 1.0000 - val_loss: 0.6224 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.58993\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3616 - accuracy: 1.0000 - val_loss: 0.5884 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00180: val_loss improved from 0.58993 to 0.58842, saving model to ./mod3.h5\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3640 - accuracy: 1.0000 - val_loss: 0.5994 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.58842\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 1s 271ms/step - loss: 0.3628 - accuracy: 1.0000 - val_loss: 0.7068 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.58842\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3675 - accuracy: 1.0000 - val_loss: 0.5863 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00183: val_loss improved from 0.58842 to 0.58630, saving model to ./mod3.h5\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3629 - accuracy: 1.0000 - val_loss: 0.5820 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00184: val_loss improved from 0.58630 to 0.58202, saving model to ./mod3.h5\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3624 - accuracy: 1.0000 - val_loss: 0.6284 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.58202\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3615 - accuracy: 1.0000 - val_loss: 0.6060 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.58202\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3629 - accuracy: 1.0000 - val_loss: 0.6004 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.58202\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3601 - accuracy: 1.0000 - val_loss: 0.6442 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.58202\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3623 - accuracy: 1.0000 - val_loss: 0.6089 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.58202\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3613 - accuracy: 1.0000 - val_loss: 0.5930 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.58202\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3590 - accuracy: 1.0000 - val_loss: 0.6068 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.58202\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3587 - accuracy: 1.0000 - val_loss: 0.5925 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.58202\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3584 - accuracy: 1.0000 - val_loss: 0.5974 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.58202\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3584 - accuracy: 1.0000 - val_loss: 0.6461 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.58202\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3618 - accuracy: 1.0000 - val_loss: 0.6096 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.58202\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3571 - accuracy: 1.0000 - val_loss: 0.5917 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.58202\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3628 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.58202\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3609 - accuracy: 1.0000 - val_loss: 0.6502 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.58202\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3606 - accuracy: 1.0000 - val_loss: 0.5891 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.58202\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3583 - accuracy: 1.0000 - val_loss: 0.5925 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.58202\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 28ms/step - loss: 0.3739 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5426 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5820 - accuracy: 0.9286\n",
            "(None, 19, 19, 19, 1)\n",
            "Model: \"model_24\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_26 (InputLayer)           [(None, 19, 19, 19,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3617 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3619 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3621 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3623 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3625 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3627 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3629 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3631 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3633 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3635 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3637 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3639 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3641 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3643 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3645 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3647 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3649 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3651 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3653 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3655 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3657 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3659 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3661 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3663 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3665 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3667 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3669 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3671 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3673 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3675 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3677 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3679 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3681 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3683 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3685 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3687 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3689 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3691 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3693 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3695 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3697 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3699 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3701 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3703 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3705 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3707 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3709 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3711 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3713 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3715 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3717 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3719 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3721 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3723 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3725 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3727 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3729 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3731 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3733 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3735 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3737 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3739 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3741 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3743 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3745 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3747 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3749 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3751 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3753 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3755 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3757 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3759 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3761 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3763 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3765 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3767 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3769 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3771 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3773 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3775 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3777 (Lambda)            (None, 19, 3, 19, 1) 0           input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3616 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3617[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3618 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3619[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3620 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3621[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3622 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3623[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3624 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3625[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3626 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3627[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3628 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3629[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3630 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3631[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3632 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3633[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3634 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3635[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3636 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3637[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3638 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3639[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3640 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3641[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3642 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3643[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3644 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3645[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3646 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3647[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3648 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3649[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3650 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3651[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3652 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3653[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3654 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3655[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3656 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3657[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3658 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3659[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3660 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3661[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3662 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3663[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3664 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3665[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3666 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3667[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3668 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3669[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3670 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3671[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3672 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3673[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3674 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3675[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3676 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3677[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3678 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3679[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3680 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3681[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3682 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3683[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3684 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3685[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3686 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3687[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3688 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3689[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3690 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3691[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3692 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3693[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3694 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3695[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3696 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3697[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3698 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3699[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3700 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3701[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3702 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3703[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3704 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3705[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3706 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3707[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3708 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3709[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3710 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3711[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3712 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3713[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3714 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3715[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3716 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3717[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3718 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3719[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3720 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3721[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3722 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3723[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3724 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3725[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3726 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3727[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3728 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3729[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3730 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3731[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3732 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3733[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3734 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3735[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3736 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3737[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3738 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3739[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3740 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3741[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3742 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3743[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3744 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3745[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3746 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3747[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3748 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3749[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3750 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3751[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3752 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3753[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3754 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3755[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3756 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3757[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3758 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3759[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3760 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3761[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3762 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3763[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3764 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3765[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3766 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3767[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3768 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3769[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3770 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3771[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3772 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3773[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3774 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3775[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3776 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3777[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1808 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3616[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1809 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3618[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1810 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3620[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1811 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3622[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1812 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3624[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1813 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3626[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1814 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3628[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1815 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3630[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1816 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3632[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1817 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3634[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1818 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3636[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1819 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3638[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1820 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3640[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1821 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3642[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1822 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3644[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1823 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3646[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1824 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3648[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1825 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3650[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1826 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3652[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1827 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3654[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1828 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3656[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1829 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3658[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1830 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3660[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1831 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3662[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1832 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3664[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1833 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3666[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1834 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3668[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1835 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3670[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1836 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3672[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1837 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3674[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1838 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3676[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1839 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3678[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1840 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3680[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1841 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3682[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1842 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3684[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1843 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3686[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1844 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3688[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1845 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3690[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1846 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3692[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1847 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3694[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1848 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3696[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1849 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3698[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1850 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3700[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1851 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3702[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1852 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3704[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1853 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3706[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1854 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3708[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1855 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3710[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1856 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3712[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1857 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3714[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1858 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3716[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1859 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3718[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1860 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3720[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1861 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3722[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1862 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3724[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1863 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3726[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1864 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3728[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1865 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3730[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1866 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3732[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1867 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3734[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1868 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3736[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1869 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3738[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1870 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3740[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1871 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3742[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1872 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3744[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1873 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3746[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1874 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3748[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1875 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3750[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1876 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3752[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1877 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3754[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1878 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3756[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1879 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3758[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1880 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3760[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1881 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3762[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1882 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3764[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1883 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3766[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1884 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3768[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1885 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3770[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1886 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3772[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1887 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3774[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1888 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3776[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1808 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1808[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1809 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1809[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1810 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1810[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1811 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1811[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1812 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1812[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1813 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1813[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1814 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1814[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1815 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1815[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1816 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1816[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1817 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1817[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1818 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1818[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1819 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1819[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1820 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1820[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1821 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1821[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1822 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1822[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1823 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1823[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1824 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1824[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1825 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1825[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1826 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1826[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1827 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1827[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1828 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1828[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1829 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1829[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1830 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1830[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1831 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1831[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1832 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1832[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1833 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1833[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1834 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1834[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1835 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1835[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1836 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1836[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1837 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1837[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1838 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1838[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1839 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1839[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1840 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1840[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1841 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1841[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1842 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1842[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1843 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1843[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1844 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1844[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1845 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1845[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1846 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1846[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1847 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1847[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1848 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1848[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1849 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1849[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1850 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1850[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1851 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1851[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1852 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1852[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1853 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1853[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1854 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1854[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1855 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1855[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1856 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1856[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1857 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1857[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1858 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1858[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1859 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1859[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1860 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1860[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1861 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1861[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1862 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1862[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1863 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1863[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1864 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1864[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1865 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1865[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1866 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1866[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1867 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1867[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1868 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1868[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1869 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1869[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1870 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1870[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1871 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1871[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1872 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1872[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1873 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1873[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1874 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1874[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1875 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1875[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1876 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1876[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1877 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1877[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1878 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1878[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1879 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1879[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1880 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1880[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1881 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1881[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1882 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1882[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1883 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1883[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1884 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1884[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1885 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1885[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1886 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1886[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1887 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1887[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1888 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1888[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1356 (Glob (None, 16)           0           dropout_1808[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1357 (Glob (None, 16)           0           dropout_1809[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1358 (Glob (None, 16)           0           dropout_1810[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1359 (Glob (None, 16)           0           dropout_1811[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1360 (Glob (None, 16)           0           dropout_1812[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1361 (Glob (None, 16)           0           dropout_1813[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1362 (Glob (None, 16)           0           dropout_1814[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1363 (Glob (None, 16)           0           dropout_1815[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1364 (Glob (None, 16)           0           dropout_1816[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1365 (Glob (None, 16)           0           dropout_1817[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1366 (Glob (None, 16)           0           dropout_1818[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1367 (Glob (None, 16)           0           dropout_1819[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1368 (Glob (None, 16)           0           dropout_1820[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1369 (Glob (None, 16)           0           dropout_1821[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1370 (Glob (None, 16)           0           dropout_1822[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1371 (Glob (None, 16)           0           dropout_1823[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1372 (Glob (None, 16)           0           dropout_1824[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1373 (Glob (None, 16)           0           dropout_1825[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1374 (Glob (None, 16)           0           dropout_1826[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1375 (Glob (None, 16)           0           dropout_1827[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1376 (Glob (None, 16)           0           dropout_1828[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1377 (Glob (None, 16)           0           dropout_1829[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1378 (Glob (None, 16)           0           dropout_1830[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1379 (Glob (None, 16)           0           dropout_1831[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1380 (Glob (None, 16)           0           dropout_1832[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1381 (Glob (None, 16)           0           dropout_1833[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1382 (Glob (None, 16)           0           dropout_1834[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1383 (Glob (None, 16)           0           dropout_1835[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1384 (Glob (None, 16)           0           dropout_1836[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1385 (Glob (None, 16)           0           dropout_1837[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1386 (Glob (None, 16)           0           dropout_1838[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1387 (Glob (None, 16)           0           dropout_1839[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1388 (Glob (None, 16)           0           dropout_1840[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1389 (Glob (None, 16)           0           dropout_1841[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1390 (Glob (None, 16)           0           dropout_1842[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1391 (Glob (None, 16)           0           dropout_1843[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1392 (Glob (None, 16)           0           dropout_1844[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1393 (Glob (None, 16)           0           dropout_1845[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1394 (Glob (None, 16)           0           dropout_1846[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1395 (Glob (None, 16)           0           dropout_1847[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1396 (Glob (None, 16)           0           dropout_1848[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1397 (Glob (None, 16)           0           dropout_1849[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1398 (Glob (None, 16)           0           dropout_1850[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1399 (Glob (None, 16)           0           dropout_1851[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1400 (Glob (None, 16)           0           dropout_1852[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1401 (Glob (None, 16)           0           dropout_1853[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1402 (Glob (None, 16)           0           dropout_1854[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1403 (Glob (None, 16)           0           dropout_1855[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1404 (Glob (None, 16)           0           dropout_1856[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1405 (Glob (None, 16)           0           dropout_1857[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1406 (Glob (None, 16)           0           dropout_1858[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1407 (Glob (None, 16)           0           dropout_1859[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1408 (Glob (None, 16)           0           dropout_1860[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1409 (Glob (None, 16)           0           dropout_1861[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1410 (Glob (None, 16)           0           dropout_1862[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1411 (Glob (None, 16)           0           dropout_1863[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1412 (Glob (None, 16)           0           dropout_1864[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1413 (Glob (None, 16)           0           dropout_1865[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1414 (Glob (None, 16)           0           dropout_1866[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1415 (Glob (None, 16)           0           dropout_1867[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1416 (Glob (None, 16)           0           dropout_1868[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1417 (Glob (None, 16)           0           dropout_1869[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1418 (Glob (None, 16)           0           dropout_1870[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1419 (Glob (None, 16)           0           dropout_1871[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1420 (Glob (None, 16)           0           dropout_1872[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1421 (Glob (None, 16)           0           dropout_1873[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1422 (Glob (None, 16)           0           dropout_1874[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1423 (Glob (None, 16)           0           dropout_1875[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1424 (Glob (None, 16)           0           dropout_1876[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1425 (Glob (None, 16)           0           dropout_1877[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1426 (Glob (None, 16)           0           dropout_1878[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1427 (Glob (None, 16)           0           dropout_1879[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1428 (Glob (None, 16)           0           dropout_1880[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1429 (Glob (None, 16)           0           dropout_1881[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1430 (Glob (None, 16)           0           dropout_1882[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1431 (Glob (None, 16)           0           dropout_1883[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1432 (Glob (None, 16)           0           dropout_1884[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1433 (Glob (None, 16)           0           dropout_1885[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1434 (Glob (None, 16)           0           dropout_1886[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1435 (Glob (None, 16)           0           dropout_1887[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1436 (Glob (None, 16)           0           dropout_1888[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 1296)         0           global_max_pooling3d_1356[0][0]  \n",
            "                                                                 global_max_pooling3d_1357[0][0]  \n",
            "                                                                 global_max_pooling3d_1358[0][0]  \n",
            "                                                                 global_max_pooling3d_1359[0][0]  \n",
            "                                                                 global_max_pooling3d_1360[0][0]  \n",
            "                                                                 global_max_pooling3d_1361[0][0]  \n",
            "                                                                 global_max_pooling3d_1362[0][0]  \n",
            "                                                                 global_max_pooling3d_1363[0][0]  \n",
            "                                                                 global_max_pooling3d_1364[0][0]  \n",
            "                                                                 global_max_pooling3d_1365[0][0]  \n",
            "                                                                 global_max_pooling3d_1366[0][0]  \n",
            "                                                                 global_max_pooling3d_1367[0][0]  \n",
            "                                                                 global_max_pooling3d_1368[0][0]  \n",
            "                                                                 global_max_pooling3d_1369[0][0]  \n",
            "                                                                 global_max_pooling3d_1370[0][0]  \n",
            "                                                                 global_max_pooling3d_1371[0][0]  \n",
            "                                                                 global_max_pooling3d_1372[0][0]  \n",
            "                                                                 global_max_pooling3d_1373[0][0]  \n",
            "                                                                 global_max_pooling3d_1374[0][0]  \n",
            "                                                                 global_max_pooling3d_1375[0][0]  \n",
            "                                                                 global_max_pooling3d_1376[0][0]  \n",
            "                                                                 global_max_pooling3d_1377[0][0]  \n",
            "                                                                 global_max_pooling3d_1378[0][0]  \n",
            "                                                                 global_max_pooling3d_1379[0][0]  \n",
            "                                                                 global_max_pooling3d_1380[0][0]  \n",
            "                                                                 global_max_pooling3d_1381[0][0]  \n",
            "                                                                 global_max_pooling3d_1382[0][0]  \n",
            "                                                                 global_max_pooling3d_1383[0][0]  \n",
            "                                                                 global_max_pooling3d_1384[0][0]  \n",
            "                                                                 global_max_pooling3d_1385[0][0]  \n",
            "                                                                 global_max_pooling3d_1386[0][0]  \n",
            "                                                                 global_max_pooling3d_1387[0][0]  \n",
            "                                                                 global_max_pooling3d_1388[0][0]  \n",
            "                                                                 global_max_pooling3d_1389[0][0]  \n",
            "                                                                 global_max_pooling3d_1390[0][0]  \n",
            "                                                                 global_max_pooling3d_1391[0][0]  \n",
            "                                                                 global_max_pooling3d_1392[0][0]  \n",
            "                                                                 global_max_pooling3d_1393[0][0]  \n",
            "                                                                 global_max_pooling3d_1394[0][0]  \n",
            "                                                                 global_max_pooling3d_1395[0][0]  \n",
            "                                                                 global_max_pooling3d_1396[0][0]  \n",
            "                                                                 global_max_pooling3d_1397[0][0]  \n",
            "                                                                 global_max_pooling3d_1398[0][0]  \n",
            "                                                                 global_max_pooling3d_1399[0][0]  \n",
            "                                                                 global_max_pooling3d_1400[0][0]  \n",
            "                                                                 global_max_pooling3d_1401[0][0]  \n",
            "                                                                 global_max_pooling3d_1402[0][0]  \n",
            "                                                                 global_max_pooling3d_1403[0][0]  \n",
            "                                                                 global_max_pooling3d_1404[0][0]  \n",
            "                                                                 global_max_pooling3d_1405[0][0]  \n",
            "                                                                 global_max_pooling3d_1406[0][0]  \n",
            "                                                                 global_max_pooling3d_1407[0][0]  \n",
            "                                                                 global_max_pooling3d_1408[0][0]  \n",
            "                                                                 global_max_pooling3d_1409[0][0]  \n",
            "                                                                 global_max_pooling3d_1410[0][0]  \n",
            "                                                                 global_max_pooling3d_1411[0][0]  \n",
            "                                                                 global_max_pooling3d_1412[0][0]  \n",
            "                                                                 global_max_pooling3d_1413[0][0]  \n",
            "                                                                 global_max_pooling3d_1414[0][0]  \n",
            "                                                                 global_max_pooling3d_1415[0][0]  \n",
            "                                                                 global_max_pooling3d_1416[0][0]  \n",
            "                                                                 global_max_pooling3d_1417[0][0]  \n",
            "                                                                 global_max_pooling3d_1418[0][0]  \n",
            "                                                                 global_max_pooling3d_1419[0][0]  \n",
            "                                                                 global_max_pooling3d_1420[0][0]  \n",
            "                                                                 global_max_pooling3d_1421[0][0]  \n",
            "                                                                 global_max_pooling3d_1422[0][0]  \n",
            "                                                                 global_max_pooling3d_1423[0][0]  \n",
            "                                                                 global_max_pooling3d_1424[0][0]  \n",
            "                                                                 global_max_pooling3d_1425[0][0]  \n",
            "                                                                 global_max_pooling3d_1426[0][0]  \n",
            "                                                                 global_max_pooling3d_1427[0][0]  \n",
            "                                                                 global_max_pooling3d_1428[0][0]  \n",
            "                                                                 global_max_pooling3d_1429[0][0]  \n",
            "                                                                 global_max_pooling3d_1430[0][0]  \n",
            "                                                                 global_max_pooling3d_1431[0][0]  \n",
            "                                                                 global_max_pooling3d_1432[0][0]  \n",
            "                                                                 global_max_pooling3d_1433[0][0]  \n",
            "                                                                 global_max_pooling3d_1434[0][0]  \n",
            "                                                                 global_max_pooling3d_1435[0][0]  \n",
            "                                                                 global_max_pooling3d_1436[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_96 (Dense)                (None, 512)          664064      concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_97 (Dense)                (None, 512)          262656      dense_96[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_98 (Dense)                (None, 512)          262656      dense_97[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_99 (Dense)                (None, 1)            513         dense_98[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,226,177\n",
            "Trainable params: 1,226,177\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 14s 1s/step - loss: 99.6712 - accuracy: 0.3780 - val_loss: 93.6531 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 93.65312, saving model to ./mod4.h5\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 92.1062 - accuracy: 0.5000 - val_loss: 86.5334 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00002: val_loss improved from 93.65312 to 86.53345, saving model to ./mod4.h5\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 84.9838 - accuracy: 0.5000 - val_loss: 79.7148 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00003: val_loss improved from 86.53345 to 79.71484, saving model to ./mod4.h5\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 78.2038 - accuracy: 0.6220 - val_loss: 73.1799 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00004: val_loss improved from 79.71484 to 73.17992, saving model to ./mod4.h5\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 71.7466 - accuracy: 0.5000 - val_loss: 66.9292 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00005: val_loss improved from 73.17992 to 66.92918, saving model to ./mod4.h5\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 65.5584 - accuracy: 0.5000 - val_loss: 60.9641 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00006: val_loss improved from 66.92918 to 60.96415, saving model to ./mod4.h5\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 59.6439 - accuracy: 0.5244 - val_loss: 55.2835 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00007: val_loss improved from 60.96415 to 55.28352, saving model to ./mod4.h5\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 54.0652 - accuracy: 0.5000 - val_loss: 49.8774 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00008: val_loss improved from 55.28352 to 49.87741, saving model to ./mod4.h5\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 48.6865 - accuracy: 0.5366 - val_loss: 44.7745 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00009: val_loss improved from 49.87741 to 44.77453, saving model to ./mod4.h5\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 43.6698 - accuracy: 0.5000 - val_loss: 39.9435 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00010: val_loss improved from 44.77453 to 39.94348, saving model to ./mod4.h5\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 38.8845 - accuracy: 0.5366 - val_loss: 35.3902 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00011: val_loss improved from 39.94348 to 35.39023, saving model to ./mod4.h5\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 34.4056 - accuracy: 0.5000 - val_loss: 31.1390 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00012: val_loss improved from 35.39023 to 31.13901, saving model to ./mod4.h5\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 30.2287 - accuracy: 0.5000 - val_loss: 27.1667 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00013: val_loss improved from 31.13901 to 27.16672, saving model to ./mod4.h5\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 26.3099 - accuracy: 0.5000 - val_loss: 23.4967 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00014: val_loss improved from 27.16672 to 23.49669, saving model to ./mod4.h5\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 22.7027 - accuracy: 0.5854 - val_loss: 20.1104 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00015: val_loss improved from 23.49669 to 20.11038, saving model to ./mod4.h5\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 19.3832 - accuracy: 0.8171 - val_loss: 17.0118 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00016: val_loss improved from 20.11038 to 17.01176, saving model to ./mod4.h5\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 16.3543 - accuracy: 0.6951 - val_loss: 14.2418 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00017: val_loss improved from 17.01176 to 14.24184, saving model to ./mod4.h5\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 13.6563 - accuracy: 0.5244 - val_loss: 11.7557 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00018: val_loss improved from 14.24184 to 11.75571, saving model to ./mod4.h5\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 11.2284 - accuracy: 0.5122 - val_loss: 9.5594 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00019: val_loss improved from 11.75571 to 9.55942, saving model to ./mod4.h5\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 9.1193 - accuracy: 0.5366 - val_loss: 7.6745 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00020: val_loss improved from 9.55942 to 7.67451, saving model to ./mod4.h5\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 7.2895 - accuracy: 0.4634 - val_loss: 6.0749 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00021: val_loss improved from 7.67451 to 6.07489, saving model to ./mod4.h5\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 5.7535 - accuracy: 0.6585 - val_loss: 4.7817 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00022: val_loss improved from 6.07489 to 4.78166, saving model to ./mod4.h5\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 4.5279 - accuracy: 0.5976 - val_loss: 3.7895 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00023: val_loss improved from 4.78166 to 3.78949, saving model to ./mod4.h5\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 3.6002 - accuracy: 0.7195 - val_loss: 3.1024 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00024: val_loss improved from 3.78949 to 3.10242, saving model to ./mod4.h5\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 3.0004 - accuracy: 0.5000 - val_loss: 2.7130 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00025: val_loss improved from 3.10242 to 2.71303, saving model to ./mod4.h5\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 1s 228ms/step - loss: 2.6731 - accuracy: 0.5488 - val_loss: 2.5724 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00026: val_loss improved from 2.71303 to 2.57244, saving model to ./mod4.h5\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 2.5223 - accuracy: 0.5000 - val_loss: 2.3365 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00027: val_loss improved from 2.57244 to 2.33650, saving model to ./mod4.h5\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 2.2780 - accuracy: 0.4390 - val_loss: 2.0505 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00028: val_loss improved from 2.33650 to 2.05049, saving model to ./mod4.h5\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 1.9795 - accuracy: 0.6707 - val_loss: 1.7788 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00029: val_loss improved from 2.05049 to 1.77876, saving model to ./mod4.h5\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 1.7202 - accuracy: 0.6707 - val_loss: 1.5974 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.77876 to 1.59735, saving model to ./mod4.h5\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 1.5661 - accuracy: 0.8780 - val_loss: 1.5191 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.59735 to 1.51911, saving model to ./mod4.h5\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 1.4898 - accuracy: 0.7683 - val_loss: 1.4187 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.51911 to 1.41868, saving model to ./mod4.h5\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 1.3759 - accuracy: 0.9024 - val_loss: 1.3121 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.41868 to 1.31214, saving model to ./mod4.h5\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.2740 - accuracy: 0.9146 - val_loss: 1.2514 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.31214 to 1.25136, saving model to ./mod4.h5\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 1.2182 - accuracy: 0.8293 - val_loss: 1.1984 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.25136 to 1.19838, saving model to ./mod4.h5\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 1.1767 - accuracy: 0.6220 - val_loss: 1.1821 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00036: val_loss improved from 1.19838 to 1.18208, saving model to ./mod4.h5\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 1.1704 - accuracy: 0.5244 - val_loss: 1.1229 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00037: val_loss improved from 1.18208 to 1.12287, saving model to ./mod4.h5\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 1.1178 - accuracy: 0.5732 - val_loss: 1.0909 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00038: val_loss improved from 1.12287 to 1.09092, saving model to ./mod4.h5\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 1.0743 - accuracy: 0.6341 - val_loss: 1.0565 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.09092 to 1.05646, saving model to ./mod4.h5\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 1.0047 - accuracy: 0.7927 - val_loss: 1.0473 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00040: val_loss improved from 1.05646 to 1.04726, saving model to ./mod4.h5\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.9711 - accuracy: 0.8171 - val_loss: 1.0271 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00041: val_loss improved from 1.04726 to 1.02709, saving model to ./mod4.h5\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.9230 - accuracy: 0.8415 - val_loss: 0.9532 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00042: val_loss improved from 1.02709 to 0.95318, saving model to ./mod4.h5\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.8630 - accuracy: 0.8780 - val_loss: 0.9263 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.95318 to 0.92635, saving model to ./mod4.h5\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.9803 - accuracy: 0.6585 - val_loss: 0.9170 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.92635 to 0.91695, saving model to ./mod4.h5\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.9531 - accuracy: 0.7561 - val_loss: 0.9121 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.91695 to 0.91211, saving model to ./mod4.h5\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.8176 - accuracy: 0.8171 - val_loss: 0.9197 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.91211\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.7600 - accuracy: 0.9024 - val_loss: 0.8380 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.91211 to 0.83804, saving model to ./mod4.h5\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.7468 - accuracy: 0.8537 - val_loss: 0.8100 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.83804 to 0.80999, saving model to ./mod4.h5\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.7467 - accuracy: 0.8415 - val_loss: 0.9584 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.80999\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.7554 - accuracy: 0.8537 - val_loss: 0.8088 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.80999 to 0.80879, saving model to ./mod4.h5\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.8067 - accuracy: 0.8171 - val_loss: 0.9367 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.80879\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.7634 - accuracy: 0.8171 - val_loss: 0.7981 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.80879 to 0.79808, saving model to ./mod4.h5\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.8214 - accuracy: 0.7927 - val_loss: 0.8115 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.79808\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 1.1765 - accuracy: 0.6463 - val_loss: 0.8744 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.79808\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.9677 - accuracy: 0.7317 - val_loss: 1.0601 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.79808\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.8608 - accuracy: 0.7317 - val_loss: 0.9834 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.79808\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 1.0589 - accuracy: 0.5366 - val_loss: 0.9681 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.79808\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.9054 - accuracy: 0.7683 - val_loss: 0.9945 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.79808\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.9102 - accuracy: 0.7683 - val_loss: 1.0129 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.79808\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.8485 - accuracy: 0.8780 - val_loss: 0.8850 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.79808\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.8252 - accuracy: 0.8171 - val_loss: 0.8617 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.79808\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.7654 - accuracy: 0.8659 - val_loss: 0.9551 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.79808\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.7610 - accuracy: 0.8902 - val_loss: 0.8286 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.79808\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.7064 - accuracy: 0.9024 - val_loss: 0.7966 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.79808 to 0.79665, saving model to ./mod4.h5\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.7025 - accuracy: 0.9146 - val_loss: 0.8316 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.79665\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.6307 - accuracy: 0.9756 - val_loss: 0.7728 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.79665 to 0.77276, saving model to ./mod4.h5\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.6067 - accuracy: 0.9390 - val_loss: 0.8735 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.77276\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.6251 - accuracy: 0.9390 - val_loss: 0.7041 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.77276 to 0.70410, saving model to ./mod4.h5\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.7147 - accuracy: 0.8537 - val_loss: 1.1139 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.70410\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.7706 - accuracy: 0.8537 - val_loss: 0.6852 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.70410 to 0.68517, saving model to ./mod4.h5\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.6641 - accuracy: 0.8659 - val_loss: 1.0156 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.68517\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 1s 230ms/step - loss: 0.6657 - accuracy: 0.8902 - val_loss: 0.6857 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.68517\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.6809 - accuracy: 0.8659 - val_loss: 0.9138 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.68517\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.5876 - accuracy: 0.9268 - val_loss: 0.6676 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.68517 to 0.66758, saving model to ./mod4.h5\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 1s 229ms/step - loss: 0.5981 - accuracy: 0.8659 - val_loss: 0.8289 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.66758\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.5374 - accuracy: 0.9756 - val_loss: 0.6625 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.66758 to 0.66246, saving model to ./mod4.h5\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.5384 - accuracy: 0.9512 - val_loss: 0.6946 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.66246\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.5019 - accuracy: 0.9756 - val_loss: 0.7098 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.66246\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.5003 - accuracy: 0.9756 - val_loss: 0.6746 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.66246\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4983 - accuracy: 0.9756 - val_loss: 0.7216 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.66246\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.4784 - accuracy: 0.9878 - val_loss: 0.6709 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.66246\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.4699 - accuracy: 0.9878 - val_loss: 0.7257 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.66246\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.4656 - accuracy: 0.9878 - val_loss: 0.6355 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.66246 to 0.63553, saving model to ./mod4.h5\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.4618 - accuracy: 0.9878 - val_loss: 0.7849 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.63553\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.4654 - accuracy: 1.0000 - val_loss: 0.6602 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.63553\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.4507 - accuracy: 1.0000 - val_loss: 0.6468 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.63553\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.4601 - accuracy: 0.9878 - val_loss: 0.7275 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.63553\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.4548 - accuracy: 1.0000 - val_loss: 0.5894 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.63553 to 0.58937, saving model to ./mod4.h5\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.4797 - accuracy: 0.9756 - val_loss: 0.8402 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.58937\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4796 - accuracy: 0.9756 - val_loss: 0.5991 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.58937\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.4338 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.58937\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.4363 - accuracy: 1.0000 - val_loss: 0.6005 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.58937\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4727 - accuracy: 0.9756 - val_loss: 1.0386 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.58937\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.5346 - accuracy: 0.9268 - val_loss: 0.5831 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.58937 to 0.58313, saving model to ./mod4.h5\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.4390 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.58313\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.4229 - accuracy: 1.0000 - val_loss: 0.5680 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00096: val_loss improved from 0.58313 to 0.56798, saving model to ./mod4.h5\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4489 - accuracy: 0.9878 - val_loss: 0.8974 - val_accuracy: 0.7143\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.56798\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.4708 - accuracy: 0.9634 - val_loss: 0.5508 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.56798 to 0.55079, saving model to ./mod4.h5\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.4431 - accuracy: 1.0000 - val_loss: 1.0110 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.55079\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.4741 - accuracy: 0.9756 - val_loss: 0.5435 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00100: val_loss improved from 0.55079 to 0.54354, saving model to ./mod4.h5\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4455 - accuracy: 0.9878 - val_loss: 0.8245 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.54354\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.4440 - accuracy: 0.9878 - val_loss: 0.5529 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.54354\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.4331 - accuracy: 1.0000 - val_loss: 0.7590 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.54354\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.4327 - accuracy: 1.0000 - val_loss: 0.5640 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.54354\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4606 - accuracy: 0.9634 - val_loss: 0.8090 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.54354\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4797 - accuracy: 0.9634 - val_loss: 0.5706 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.54354\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.5100 - accuracy: 0.9268 - val_loss: 1.0845 - val_accuracy: 0.5714\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.54354\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.4856 - accuracy: 0.9634 - val_loss: 0.5600 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.54354\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.5401 - accuracy: 0.9024 - val_loss: 1.3770 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.54354\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.7626 - accuracy: 0.7927 - val_loss: 0.5984 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.54354\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.5175 - accuracy: 0.9512 - val_loss: 1.2130 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.54354\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.5700 - accuracy: 0.9390 - val_loss: 0.6385 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.54354\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.5472 - accuracy: 0.9268 - val_loss: 1.0159 - val_accuracy: 0.6429\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.54354\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.5046 - accuracy: 0.9756 - val_loss: 0.5472 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.54354\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.4883 - accuracy: 0.9878 - val_loss: 0.5806 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.54354\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.4140 - accuracy: 1.0000 - val_loss: 0.7857 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.54354\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.4396 - accuracy: 0.9756 - val_loss: 0.5422 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00117: val_loss improved from 0.54354 to 0.54216, saving model to ./mod4.h5\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.4441 - accuracy: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.54216\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.4461 - accuracy: 0.9878 - val_loss: 0.6834 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.54216\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.4005 - accuracy: 1.0000 - val_loss: 0.5411 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00120: val_loss improved from 0.54216 to 0.54106, saving model to ./mod4.h5\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.4303 - accuracy: 0.9878 - val_loss: 0.5892 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.54106\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.4102 - accuracy: 1.0000 - val_loss: 0.7166 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.54106\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.4131 - accuracy: 1.0000 - val_loss: 0.5927 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.54106\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3992 - accuracy: 1.0000 - val_loss: 0.5405 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00124: val_loss improved from 0.54106 to 0.54052, saving model to ./mod4.h5\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.4101 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.54052\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3941 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.54052\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.4059 - accuracy: 1.0000 - val_loss: 0.5855 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.54052\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3980 - accuracy: 1.0000 - val_loss: 0.5387 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00128: val_loss improved from 0.54052 to 0.53868, saving model to ./mod4.h5\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3993 - accuracy: 1.0000 - val_loss: 0.6696 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.53868\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.4046 - accuracy: 1.0000 - val_loss: 0.6799 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.53868\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3955 - accuracy: 1.0000 - val_loss: 0.5749 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.53868\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3887 - accuracy: 1.0000 - val_loss: 0.5643 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.53868\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3929 - accuracy: 1.0000 - val_loss: 0.6042 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.53868\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3892 - accuracy: 1.0000 - val_loss: 0.6017 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.53868\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3865 - accuracy: 1.0000 - val_loss: 0.5795 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.53868\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3855 - accuracy: 1.0000 - val_loss: 0.5673 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.53868\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3871 - accuracy: 1.0000 - val_loss: 0.6010 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.53868\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3846 - accuracy: 1.0000 - val_loss: 0.5951 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.53868\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3859 - accuracy: 1.0000 - val_loss: 0.5635 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.53868\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3826 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.53868\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3850 - accuracy: 1.0000 - val_loss: 0.6072 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.53868\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3861 - accuracy: 1.0000 - val_loss: 0.5912 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.53868\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3831 - accuracy: 1.0000 - val_loss: 0.5919 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.53868\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.3814 - accuracy: 1.0000 - val_loss: 0.5625 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.53868\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3848 - accuracy: 1.0000 - val_loss: 0.6167 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.53868\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3866 - accuracy: 1.0000 - val_loss: 0.6234 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.53868\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3808 - accuracy: 1.0000 - val_loss: 0.5709 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.53868\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3832 - accuracy: 1.0000 - val_loss: 0.5303 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00148: val_loss improved from 0.53868 to 0.53033, saving model to ./mod4.h5\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3810 - accuracy: 1.0000 - val_loss: 0.5857 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.53033\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 1s 232ms/step - loss: 0.3789 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.53033\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3863 - accuracy: 1.0000 - val_loss: 0.5930 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.53033\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3786 - accuracy: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.53033\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3824 - accuracy: 1.0000 - val_loss: 0.6008 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.53033\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3787 - accuracy: 1.0000 - val_loss: 0.6237 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.53033\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3799 - accuracy: 1.0000 - val_loss: 0.5338 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.53033\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3790 - accuracy: 1.0000 - val_loss: 0.5482 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.53033\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3803 - accuracy: 1.0000 - val_loss: 0.6715 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.53033\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3822 - accuracy: 1.0000 - val_loss: 0.5851 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.53033\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3764 - accuracy: 1.0000 - val_loss: 0.5310 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.53033\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3772 - accuracy: 1.0000 - val_loss: 0.6182 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.53033\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3754 - accuracy: 1.0000 - val_loss: 0.6553 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.53033\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.3755 - accuracy: 1.0000 - val_loss: 0.5608 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.53033\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3713 - accuracy: 1.0000 - val_loss: 0.5306 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.53033\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 1s 233ms/step - loss: 0.3722 - accuracy: 1.0000 - val_loss: 0.6133 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.53033\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3788 - accuracy: 1.0000 - val_loss: 0.6997 - val_accuracy: 0.8571\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.53033\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 1s 231ms/step - loss: 0.3764 - accuracy: 1.0000 - val_loss: 0.6064 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.53033\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3734 - accuracy: 1.0000 - val_loss: 0.5279 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00167: val_loss improved from 0.53033 to 0.52792, saving model to ./mod4.h5\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3746 - accuracy: 1.0000 - val_loss: 0.5554 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.52792\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3765 - accuracy: 1.0000 - val_loss: 0.6170 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.52792\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3715 - accuracy: 1.0000 - val_loss: 0.5711 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.52792\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3713 - accuracy: 1.0000 - val_loss: 0.5367 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.52792\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3718 - accuracy: 1.0000 - val_loss: 0.5775 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.52792\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3695 - accuracy: 1.0000 - val_loss: 0.6504 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.52792\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3704 - accuracy: 1.0000 - val_loss: 0.5504 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.52792\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3738 - accuracy: 1.0000 - val_loss: 0.5235 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00175: val_loss improved from 0.52792 to 0.52354, saving model to ./mod4.h5\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3700 - accuracy: 1.0000 - val_loss: 0.5748 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.52354\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3695 - accuracy: 1.0000 - val_loss: 0.5993 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.52354\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 0.3699 - accuracy: 1.0000 - val_loss: 0.5565 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.52354\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3725 - accuracy: 1.0000 - val_loss: 0.5811 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.52354\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3650 - accuracy: 1.0000 - val_loss: 0.6132 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.52354\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3692 - accuracy: 1.0000 - val_loss: 0.5850 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.52354\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3653 - accuracy: 1.0000 - val_loss: 0.5939 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.52354\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 1s 234ms/step - loss: 0.3691 - accuracy: 1.0000 - val_loss: 0.5705 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.52354\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3668 - accuracy: 1.0000 - val_loss: 0.5661 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.52354\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3678 - accuracy: 1.0000 - val_loss: 0.6069 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.52354\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3659 - accuracy: 1.0000 - val_loss: 0.5812 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.52354\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3669 - accuracy: 1.0000 - val_loss: 0.5572 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.52354\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3634 - accuracy: 1.0000 - val_loss: 0.5823 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.52354\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3679 - accuracy: 1.0000 - val_loss: 0.5889 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.52354\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3653 - accuracy: 1.0000 - val_loss: 0.5635 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.52354\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.3663 - accuracy: 1.0000 - val_loss: 0.5799 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.52354\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3641 - accuracy: 1.0000 - val_loss: 0.5575 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.52354\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3613 - accuracy: 1.0000 - val_loss: 0.5667 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.52354\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3618 - accuracy: 1.0000 - val_loss: 0.5627 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.52354\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3646 - accuracy: 1.0000 - val_loss: 0.5542 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.52354\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3611 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.52354\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3689 - accuracy: 1.0000 - val_loss: 0.5600 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.52354\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3640 - accuracy: 1.0000 - val_loss: 0.5444 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.52354\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3639 - accuracy: 1.0000 - val_loss: 0.5639 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.52354\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3626 - accuracy: 1.0000 - val_loss: 0.5947 - val_accuracy: 0.9286\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.52354\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 27ms/step - loss: 0.3883 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6270 - accuracy: 0.8800\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5235 - accuracy: 0.9286\n",
            "(None, 19, 19, 19, 1)\n",
            "Model: \"model_25\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_27 (InputLayer)           [(None, 19, 19, 19,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3779 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3781 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3783 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3785 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3787 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3789 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3791 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3793 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3795 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3797 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3799 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3801 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3803 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3805 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3807 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3809 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3811 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3813 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3815 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3817 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3819 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3821 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3823 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3825 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3827 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3829 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3831 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3833 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3835 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3837 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3839 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3841 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3843 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3845 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3847 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3849 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3851 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3853 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3855 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3857 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3859 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3861 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3863 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3865 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3867 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3869 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3871 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3873 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3875 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3877 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3879 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3881 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3883 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3885 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3887 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3889 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3891 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3893 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3895 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3897 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3899 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3901 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3903 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3905 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3907 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3909 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3911 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3913 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3915 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3917 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3919 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3921 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3923 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3925 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3927 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3929 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3931 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3933 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3935 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3937 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3939 (Lambda)            (None, 19, 3, 19, 1) 0           input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3778 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3779[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3780 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3781[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3782 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3783[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3784 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3785[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3786 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3787[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3788 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3789[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3790 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3791[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3792 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3793[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3794 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3795[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3796 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3797[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3798 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3799[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3800 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3801[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3802 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3803[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3804 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3805[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3806 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3807[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3808 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3809[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3810 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3811[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3812 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3813[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3814 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3815[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3816 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3817[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3818 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3819[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3820 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3821[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3822 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3823[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3824 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3825[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3826 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3827[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3828 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3829[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3830 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3831[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3832 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3833[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3834 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3835[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3836 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3837[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3838 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3839[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3840 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3841[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3842 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3843[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3844 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3845[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3846 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3847[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3848 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3849[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3850 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3851[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3852 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3853[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3854 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3855[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3856 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3857[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3858 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3859[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3860 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3861[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3862 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3863[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3864 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3865[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3866 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3867[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3868 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3869[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3870 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3871[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3872 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3873[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3874 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3875[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3876 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3877[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3878 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3879[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3880 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3881[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3882 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3883[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3884 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3885[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3886 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3887[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3888 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3889[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3890 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3891[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3892 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3893[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3894 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3895[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3896 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3897[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3898 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3899[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3900 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3901[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3902 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3903[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3904 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3905[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3906 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3907[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3908 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3909[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3910 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3911[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3912 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3913[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3914 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3915[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3916 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3917[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3918 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3919[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3920 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3921[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3922 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3923[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3924 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3925[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3926 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3927[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3928 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3929[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3930 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3931[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3932 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3933[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3934 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3935[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3936 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3937[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3938 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3939[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1889 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3778[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1890 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3780[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1891 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3782[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1892 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3784[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1893 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3786[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1894 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3788[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1895 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3790[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1896 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3792[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1897 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3794[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1898 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3796[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1899 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3798[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1900 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3800[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1901 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3802[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1902 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3804[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1903 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3806[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1904 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3808[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1905 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3810[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1906 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3812[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1907 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3814[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1908 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3816[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1909 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3818[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1910 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3820[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1911 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3822[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1912 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3824[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1913 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3826[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1914 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3828[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1915 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3830[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1916 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3832[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1917 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3834[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1918 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3836[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1919 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3838[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1920 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3840[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1921 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3842[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1922 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3844[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1923 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3846[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1924 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3848[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1925 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3850[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1926 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3852[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1927 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3854[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1928 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3856[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1929 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3858[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1930 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3860[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1931 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3862[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1932 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3864[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1933 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3866[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1934 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3868[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1935 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3870[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1936 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3872[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1937 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3874[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1938 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3876[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1939 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3878[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1940 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3880[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1941 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3882[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1942 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3884[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1943 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3886[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1944 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3888[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1945 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3890[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1946 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3892[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1947 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3894[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1948 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3896[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1949 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3898[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1950 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3900[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1951 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3902[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1952 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3904[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1953 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3906[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1954 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3908[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1955 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3910[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1956 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3912[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1957 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3914[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1958 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3916[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1959 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3918[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1960 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3920[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1961 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3922[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1962 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3924[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1963 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3926[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1964 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3928[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1965 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3930[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1966 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3932[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1967 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3934[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1968 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3936[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1969 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3938[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1889 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1889[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1890 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1890[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1891 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1891[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1892 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1892[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1893 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1893[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1894 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1894[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1895 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1895[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1896 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1896[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1897 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1897[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1898 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1898[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1899 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1899[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1900 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1900[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1901 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1901[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1902 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1902[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1903 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1903[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1904 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1904[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1905 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1905[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1906 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1906[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1907 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1907[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1908 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1908[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1909 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1909[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1910 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1910[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1911 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1911[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1912 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1912[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1913 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1913[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1914 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1914[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1915 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1915[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1916 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1916[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1917 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1917[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1918 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1918[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1919 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1919[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1920 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1920[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1921 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1921[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1922 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1922[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1923 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1923[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1924 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1924[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1925 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1925[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1926 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1926[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1927 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1927[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1928 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1928[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1929 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1929[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1930 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1930[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1931 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1931[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1932 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1932[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1933 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1933[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1934 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1934[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1935 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1935[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1936 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1936[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1937 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1937[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1938 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1938[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1939 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1939[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1940 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1940[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1941 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1941[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1942 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1942[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1943 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1943[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1944 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1944[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1945 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1945[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1946 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1946[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1947 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1947[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1948 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1948[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1949 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1949[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1950 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1950[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1951 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1951[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1952 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1952[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1953 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1953[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1954 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1954[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1955 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1955[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1956 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1956[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1957 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1957[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1958 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1958[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1959 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1959[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1960 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1960[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1961 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1961[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1962 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1962[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1963 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1963[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1964 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1964[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1965 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1965[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1966 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1966[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1967 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1967[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1968 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1968[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1969 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1969[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1437 (Glob (None, 16)           0           dropout_1889[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1438 (Glob (None, 16)           0           dropout_1890[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1439 (Glob (None, 16)           0           dropout_1891[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1440 (Glob (None, 16)           0           dropout_1892[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1441 (Glob (None, 16)           0           dropout_1893[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1442 (Glob (None, 16)           0           dropout_1894[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1443 (Glob (None, 16)           0           dropout_1895[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1444 (Glob (None, 16)           0           dropout_1896[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1445 (Glob (None, 16)           0           dropout_1897[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1446 (Glob (None, 16)           0           dropout_1898[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1447 (Glob (None, 16)           0           dropout_1899[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1448 (Glob (None, 16)           0           dropout_1900[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1449 (Glob (None, 16)           0           dropout_1901[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1450 (Glob (None, 16)           0           dropout_1902[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1451 (Glob (None, 16)           0           dropout_1903[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1452 (Glob (None, 16)           0           dropout_1904[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1453 (Glob (None, 16)           0           dropout_1905[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1454 (Glob (None, 16)           0           dropout_1906[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1455 (Glob (None, 16)           0           dropout_1907[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1456 (Glob (None, 16)           0           dropout_1908[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1457 (Glob (None, 16)           0           dropout_1909[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1458 (Glob (None, 16)           0           dropout_1910[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1459 (Glob (None, 16)           0           dropout_1911[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1460 (Glob (None, 16)           0           dropout_1912[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1461 (Glob (None, 16)           0           dropout_1913[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1462 (Glob (None, 16)           0           dropout_1914[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1463 (Glob (None, 16)           0           dropout_1915[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1464 (Glob (None, 16)           0           dropout_1916[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1465 (Glob (None, 16)           0           dropout_1917[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1466 (Glob (None, 16)           0           dropout_1918[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1467 (Glob (None, 16)           0           dropout_1919[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1468 (Glob (None, 16)           0           dropout_1920[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1469 (Glob (None, 16)           0           dropout_1921[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1470 (Glob (None, 16)           0           dropout_1922[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1471 (Glob (None, 16)           0           dropout_1923[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1472 (Glob (None, 16)           0           dropout_1924[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1473 (Glob (None, 16)           0           dropout_1925[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1474 (Glob (None, 16)           0           dropout_1926[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1475 (Glob (None, 16)           0           dropout_1927[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1476 (Glob (None, 16)           0           dropout_1928[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1477 (Glob (None, 16)           0           dropout_1929[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1478 (Glob (None, 16)           0           dropout_1930[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1479 (Glob (None, 16)           0           dropout_1931[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1480 (Glob (None, 16)           0           dropout_1932[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1481 (Glob (None, 16)           0           dropout_1933[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1482 (Glob (None, 16)           0           dropout_1934[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1483 (Glob (None, 16)           0           dropout_1935[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1484 (Glob (None, 16)           0           dropout_1936[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1485 (Glob (None, 16)           0           dropout_1937[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1486 (Glob (None, 16)           0           dropout_1938[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1487 (Glob (None, 16)           0           dropout_1939[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1488 (Glob (None, 16)           0           dropout_1940[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1489 (Glob (None, 16)           0           dropout_1941[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1490 (Glob (None, 16)           0           dropout_1942[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1491 (Glob (None, 16)           0           dropout_1943[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1492 (Glob (None, 16)           0           dropout_1944[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1493 (Glob (None, 16)           0           dropout_1945[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1494 (Glob (None, 16)           0           dropout_1946[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1495 (Glob (None, 16)           0           dropout_1947[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1496 (Glob (None, 16)           0           dropout_1948[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1497 (Glob (None, 16)           0           dropout_1949[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1498 (Glob (None, 16)           0           dropout_1950[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1499 (Glob (None, 16)           0           dropout_1951[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1500 (Glob (None, 16)           0           dropout_1952[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1501 (Glob (None, 16)           0           dropout_1953[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1502 (Glob (None, 16)           0           dropout_1954[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1503 (Glob (None, 16)           0           dropout_1955[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1504 (Glob (None, 16)           0           dropout_1956[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1505 (Glob (None, 16)           0           dropout_1957[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1506 (Glob (None, 16)           0           dropout_1958[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1507 (Glob (None, 16)           0           dropout_1959[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1508 (Glob (None, 16)           0           dropout_1960[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1509 (Glob (None, 16)           0           dropout_1961[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1510 (Glob (None, 16)           0           dropout_1962[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1511 (Glob (None, 16)           0           dropout_1963[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1512 (Glob (None, 16)           0           dropout_1964[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1513 (Glob (None, 16)           0           dropout_1965[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1514 (Glob (None, 16)           0           dropout_1966[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1515 (Glob (None, 16)           0           dropout_1967[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1516 (Glob (None, 16)           0           dropout_1968[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1517 (Glob (None, 16)           0           dropout_1969[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 1296)         0           global_max_pooling3d_1437[0][0]  \n",
            "                                                                 global_max_pooling3d_1438[0][0]  \n",
            "                                                                 global_max_pooling3d_1439[0][0]  \n",
            "                                                                 global_max_pooling3d_1440[0][0]  \n",
            "                                                                 global_max_pooling3d_1441[0][0]  \n",
            "                                                                 global_max_pooling3d_1442[0][0]  \n",
            "                                                                 global_max_pooling3d_1443[0][0]  \n",
            "                                                                 global_max_pooling3d_1444[0][0]  \n",
            "                                                                 global_max_pooling3d_1445[0][0]  \n",
            "                                                                 global_max_pooling3d_1446[0][0]  \n",
            "                                                                 global_max_pooling3d_1447[0][0]  \n",
            "                                                                 global_max_pooling3d_1448[0][0]  \n",
            "                                                                 global_max_pooling3d_1449[0][0]  \n",
            "                                                                 global_max_pooling3d_1450[0][0]  \n",
            "                                                                 global_max_pooling3d_1451[0][0]  \n",
            "                                                                 global_max_pooling3d_1452[0][0]  \n",
            "                                                                 global_max_pooling3d_1453[0][0]  \n",
            "                                                                 global_max_pooling3d_1454[0][0]  \n",
            "                                                                 global_max_pooling3d_1455[0][0]  \n",
            "                                                                 global_max_pooling3d_1456[0][0]  \n",
            "                                                                 global_max_pooling3d_1457[0][0]  \n",
            "                                                                 global_max_pooling3d_1458[0][0]  \n",
            "                                                                 global_max_pooling3d_1459[0][0]  \n",
            "                                                                 global_max_pooling3d_1460[0][0]  \n",
            "                                                                 global_max_pooling3d_1461[0][0]  \n",
            "                                                                 global_max_pooling3d_1462[0][0]  \n",
            "                                                                 global_max_pooling3d_1463[0][0]  \n",
            "                                                                 global_max_pooling3d_1464[0][0]  \n",
            "                                                                 global_max_pooling3d_1465[0][0]  \n",
            "                                                                 global_max_pooling3d_1466[0][0]  \n",
            "                                                                 global_max_pooling3d_1467[0][0]  \n",
            "                                                                 global_max_pooling3d_1468[0][0]  \n",
            "                                                                 global_max_pooling3d_1469[0][0]  \n",
            "                                                                 global_max_pooling3d_1470[0][0]  \n",
            "                                                                 global_max_pooling3d_1471[0][0]  \n",
            "                                                                 global_max_pooling3d_1472[0][0]  \n",
            "                                                                 global_max_pooling3d_1473[0][0]  \n",
            "                                                                 global_max_pooling3d_1474[0][0]  \n",
            "                                                                 global_max_pooling3d_1475[0][0]  \n",
            "                                                                 global_max_pooling3d_1476[0][0]  \n",
            "                                                                 global_max_pooling3d_1477[0][0]  \n",
            "                                                                 global_max_pooling3d_1478[0][0]  \n",
            "                                                                 global_max_pooling3d_1479[0][0]  \n",
            "                                                                 global_max_pooling3d_1480[0][0]  \n",
            "                                                                 global_max_pooling3d_1481[0][0]  \n",
            "                                                                 global_max_pooling3d_1482[0][0]  \n",
            "                                                                 global_max_pooling3d_1483[0][0]  \n",
            "                                                                 global_max_pooling3d_1484[0][0]  \n",
            "                                                                 global_max_pooling3d_1485[0][0]  \n",
            "                                                                 global_max_pooling3d_1486[0][0]  \n",
            "                                                                 global_max_pooling3d_1487[0][0]  \n",
            "                                                                 global_max_pooling3d_1488[0][0]  \n",
            "                                                                 global_max_pooling3d_1489[0][0]  \n",
            "                                                                 global_max_pooling3d_1490[0][0]  \n",
            "                                                                 global_max_pooling3d_1491[0][0]  \n",
            "                                                                 global_max_pooling3d_1492[0][0]  \n",
            "                                                                 global_max_pooling3d_1493[0][0]  \n",
            "                                                                 global_max_pooling3d_1494[0][0]  \n",
            "                                                                 global_max_pooling3d_1495[0][0]  \n",
            "                                                                 global_max_pooling3d_1496[0][0]  \n",
            "                                                                 global_max_pooling3d_1497[0][0]  \n",
            "                                                                 global_max_pooling3d_1498[0][0]  \n",
            "                                                                 global_max_pooling3d_1499[0][0]  \n",
            "                                                                 global_max_pooling3d_1500[0][0]  \n",
            "                                                                 global_max_pooling3d_1501[0][0]  \n",
            "                                                                 global_max_pooling3d_1502[0][0]  \n",
            "                                                                 global_max_pooling3d_1503[0][0]  \n",
            "                                                                 global_max_pooling3d_1504[0][0]  \n",
            "                                                                 global_max_pooling3d_1505[0][0]  \n",
            "                                                                 global_max_pooling3d_1506[0][0]  \n",
            "                                                                 global_max_pooling3d_1507[0][0]  \n",
            "                                                                 global_max_pooling3d_1508[0][0]  \n",
            "                                                                 global_max_pooling3d_1509[0][0]  \n",
            "                                                                 global_max_pooling3d_1510[0][0]  \n",
            "                                                                 global_max_pooling3d_1511[0][0]  \n",
            "                                                                 global_max_pooling3d_1512[0][0]  \n",
            "                                                                 global_max_pooling3d_1513[0][0]  \n",
            "                                                                 global_max_pooling3d_1514[0][0]  \n",
            "                                                                 global_max_pooling3d_1515[0][0]  \n",
            "                                                                 global_max_pooling3d_1516[0][0]  \n",
            "                                                                 global_max_pooling3d_1517[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_100 (Dense)               (None, 512)          664064      concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_101 (Dense)               (None, 512)          262656      dense_100[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_102 (Dense)               (None, 512)          262656      dense_101[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_103 (Dense)               (None, 1)            513         dense_102[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,226,177\n",
            "Trainable params: 1,226,177\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 14s 1s/step - loss: 99.5077 - accuracy: 0.5060 - val_loss: 93.6439 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 93.64391, saving model to ./mod5.h5\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 91.9997 - accuracy: 0.4699 - val_loss: 86.4760 - val_accuracy: 0.3846\n",
            "\n",
            "Epoch 00002: val_loss improved from 93.64391 to 86.47601, saving model to ./mod5.h5\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 84.8394 - accuracy: 0.4819 - val_loss: 79.5631 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00003: val_loss improved from 86.47601 to 79.56306, saving model to ./mod5.h5\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 78.0319 - accuracy: 0.5181 - val_loss: 73.0108 - val_accuracy: 0.3846\n",
            "\n",
            "Epoch 00004: val_loss improved from 79.56306 to 73.01080, saving model to ./mod5.h5\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 71.5082 - accuracy: 0.5181 - val_loss: 66.7030 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00005: val_loss improved from 73.01080 to 66.70300, saving model to ./mod5.h5\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 65.2916 - accuracy: 0.6145 - val_loss: 60.7092 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00006: val_loss improved from 66.70300 to 60.70925, saving model to ./mod5.h5\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 59.4019 - accuracy: 0.3735 - val_loss: 55.0263 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00007: val_loss improved from 60.70925 to 55.02627, saving model to ./mod5.h5\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 53.7759 - accuracy: 0.4819 - val_loss: 49.6402 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00008: val_loss improved from 55.02627 to 49.64016, saving model to ./mod5.h5\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 48.4149 - accuracy: 0.6627 - val_loss: 44.5933 - val_accuracy: 0.3846\n",
            "\n",
            "Epoch 00009: val_loss improved from 49.64016 to 44.59335, saving model to ./mod5.h5\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 43.4117 - accuracy: 0.5181 - val_loss: 39.7335 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00010: val_loss improved from 44.59335 to 39.73351, saving model to ./mod5.h5\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 38.6551 - accuracy: 0.4940 - val_loss: 35.2010 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00011: val_loss improved from 39.73351 to 35.20102, saving model to ./mod5.h5\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 34.2001 - accuracy: 0.5181 - val_loss: 30.9877 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00012: val_loss improved from 35.20102 to 30.98771, saving model to ./mod5.h5\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 30.0195 - accuracy: 0.5181 - val_loss: 27.0245 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00013: val_loss improved from 30.98771 to 27.02448, saving model to ./mod5.h5\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 26.1135 - accuracy: 0.6265 - val_loss: 23.3558 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00014: val_loss improved from 27.02448 to 23.35576, saving model to ./mod5.h5\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 22.5373 - accuracy: 0.6386 - val_loss: 20.0283 - val_accuracy: 0.4615\n",
            "\n",
            "Epoch 00015: val_loss improved from 23.35576 to 20.02826, saving model to ./mod5.h5\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 19.2642 - accuracy: 0.5301 - val_loss: 16.9064 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00016: val_loss improved from 20.02826 to 16.90645, saving model to ./mod5.h5\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 16.2650 - accuracy: 0.5181 - val_loss: 14.1381 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00017: val_loss improved from 16.90645 to 14.13811, saving model to ./mod5.h5\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 1s 235ms/step - loss: 13.4998 - accuracy: 0.7590 - val_loss: 11.6673 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00018: val_loss improved from 14.13811 to 11.66726, saving model to ./mod5.h5\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 11.0601 - accuracy: 0.8916 - val_loss: 9.4742 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00019: val_loss improved from 11.66726 to 9.47423, saving model to ./mod5.h5\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 8.9686 - accuracy: 0.7711 - val_loss: 7.6478 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00020: val_loss improved from 9.47423 to 7.64781, saving model to ./mod5.h5\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 7.1693 - accuracy: 0.6867 - val_loss: 6.0386 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00021: val_loss improved from 7.64781 to 6.03861, saving model to ./mod5.h5\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 5.6399 - accuracy: 0.7590 - val_loss: 4.7629 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00022: val_loss improved from 6.03861 to 4.76287, saving model to ./mod5.h5\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 4.4004 - accuracy: 0.8193 - val_loss: 3.7855 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00023: val_loss improved from 4.76287 to 3.78546, saving model to ./mod5.h5\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 3.5016 - accuracy: 0.7590 - val_loss: 3.0911 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00024: val_loss improved from 3.78546 to 3.09115, saving model to ./mod5.h5\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 2.8278 - accuracy: 0.8795 - val_loss: 2.7218 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00025: val_loss improved from 3.09115 to 2.72179, saving model to ./mod5.h5\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 2.5433 - accuracy: 0.8072 - val_loss: 2.6673 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00026: val_loss improved from 2.72179 to 2.66730, saving model to ./mod5.h5\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 2.5364 - accuracy: 0.7229 - val_loss: 2.4874 - val_accuracy: 0.4615\n",
            "\n",
            "Epoch 00027: val_loss improved from 2.66730 to 2.48744, saving model to ./mod5.h5\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 2.3726 - accuracy: 0.5422 - val_loss: 2.1119 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00028: val_loss improved from 2.48744 to 2.11189, saving model to ./mod5.h5\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 1.9495 - accuracy: 0.6988 - val_loss: 1.8145 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00029: val_loss improved from 2.11189 to 1.81452, saving model to ./mod5.h5\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 1.6136 - accuracy: 0.8795 - val_loss: 1.6621 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.81452 to 1.66209, saving model to ./mod5.h5\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 1.4986 - accuracy: 0.7831 - val_loss: 1.5644 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.66209 to 1.56439, saving model to ./mod5.h5\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 1.4201 - accuracy: 0.7952 - val_loss: 1.4969 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.56439 to 1.49693, saving model to ./mod5.h5\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.3316 - accuracy: 0.7108 - val_loss: 1.3373 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.49693 to 1.33734, saving model to ./mod5.h5\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.1537 - accuracy: 0.8434 - val_loss: 1.3194 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.33734 to 1.31940, saving model to ./mod5.h5\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.1026 - accuracy: 0.8313 - val_loss: 1.2194 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00035: val_loss improved from 1.31940 to 1.21942, saving model to ./mod5.h5\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 1.0195 - accuracy: 0.8554 - val_loss: 1.2203 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.21942\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.9371 - accuracy: 0.8916 - val_loss: 1.1466 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00037: val_loss improved from 1.21942 to 1.14655, saving model to ./mod5.h5\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.9075 - accuracy: 0.8916 - val_loss: 1.2187 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.14655\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.9261 - accuracy: 0.8193 - val_loss: 1.0565 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.14655 to 1.05652, saving model to ./mod5.h5\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.8178 - accuracy: 0.9157 - val_loss: 1.0630 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.05652\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.7475 - accuracy: 0.9277 - val_loss: 1.0293 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00041: val_loss improved from 1.05652 to 1.02930, saving model to ./mod5.h5\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.7118 - accuracy: 0.9398 - val_loss: 1.0479 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.02930\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.9521 - accuracy: 0.7590 - val_loss: 1.0814 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 1.02930\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.7057 - accuracy: 0.9398 - val_loss: 0.9661 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00044: val_loss improved from 1.02930 to 0.96612, saving model to ./mod5.h5\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.6537 - accuracy: 0.9518 - val_loss: 0.9979 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.96612\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.6479 - accuracy: 0.9398 - val_loss: 1.0041 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.96612\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.6200 - accuracy: 0.9880 - val_loss: 0.9277 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.96612 to 0.92773, saving model to ./mod5.h5\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.6125 - accuracy: 0.9398 - val_loss: 0.9719 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.92773\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.5773 - accuracy: 0.9880 - val_loss: 0.8914 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.92773 to 0.89136, saving model to ./mod5.h5\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.5609 - accuracy: 0.9639 - val_loss: 0.9808 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.89136\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.5871 - accuracy: 0.9518 - val_loss: 0.8989 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.89136\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.6027 - accuracy: 0.9639 - val_loss: 0.9256 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.89136\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.5948 - accuracy: 0.9277 - val_loss: 0.9747 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.89136\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.5336 - accuracy: 0.9639 - val_loss: 0.8534 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.89136 to 0.85335, saving model to ./mod5.h5\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.5669 - accuracy: 0.9639 - val_loss: 0.8452 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.85335 to 0.84520, saving model to ./mod5.h5\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.6002 - accuracy: 0.9157 - val_loss: 0.9287 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.84520\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.5170 - accuracy: 1.0000 - val_loss: 0.8435 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.84520 to 0.84354, saving model to ./mod5.h5\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.5400 - accuracy: 0.9639 - val_loss: 1.0416 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.84354\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.5598 - accuracy: 0.9639 - val_loss: 0.8304 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.84354 to 0.83037, saving model to ./mod5.h5\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.4756 - accuracy: 1.0000 - val_loss: 0.9215 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.83037\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.5212 - accuracy: 0.9759 - val_loss: 0.8302 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.83037 to 0.83024, saving model to ./mod5.h5\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.4916 - accuracy: 1.0000 - val_loss: 0.8180 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.83024 to 0.81799, saving model to ./mod5.h5\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.5345 - accuracy: 0.9398 - val_loss: 0.9769 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.81799\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.5086 - accuracy: 0.9880 - val_loss: 0.8251 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.81799\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.4842 - accuracy: 0.9759 - val_loss: 0.8924 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.81799\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.4601 - accuracy: 1.0000 - val_loss: 0.8140 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.81799 to 0.81404, saving model to ./mod5.h5\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.4522 - accuracy: 1.0000 - val_loss: 0.8831 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.81404\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.4571 - accuracy: 1.0000 - val_loss: 0.8108 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.81404 to 0.81078, saving model to ./mod5.h5\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.4556 - accuracy: 0.9880 - val_loss: 0.8696 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.81078\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.4475 - accuracy: 1.0000 - val_loss: 0.8114 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.81078\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.4790 - accuracy: 0.9639 - val_loss: 1.0055 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.81078\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.4890 - accuracy: 0.9880 - val_loss: 0.8805 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.81078\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.4666 - accuracy: 0.9880 - val_loss: 1.0517 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.81078\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.4866 - accuracy: 0.9880 - val_loss: 0.8582 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.81078\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.4751 - accuracy: 0.9759 - val_loss: 1.0185 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.81078\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.4611 - accuracy: 1.0000 - val_loss: 0.8137 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.81078\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.4515 - accuracy: 0.9880 - val_loss: 0.9106 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.81078\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.4519 - accuracy: 0.9880 - val_loss: 0.8003 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.81078 to 0.80029, saving model to ./mod5.h5\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.4270 - accuracy: 1.0000 - val_loss: 0.7944 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00079: val_loss improved from 0.80029 to 0.79439, saving model to ./mod5.h5\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.4217 - accuracy: 1.0000 - val_loss: 0.9784 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.79439\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.4357 - accuracy: 1.0000 - val_loss: 0.8098 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.79439\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.4479 - accuracy: 0.9880 - val_loss: 0.9678 - val_accuracy: 0.6923\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.79439\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.4366 - accuracy: 1.0000 - val_loss: 0.7779 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.79439 to 0.77788, saving model to ./mod5.h5\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.4212 - accuracy: 1.0000 - val_loss: 0.9013 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.77788\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.4237 - accuracy: 1.0000 - val_loss: 0.7710 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.77788 to 0.77104, saving model to ./mod5.h5\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.4178 - accuracy: 1.0000 - val_loss: 0.7639 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00086: val_loss improved from 0.77104 to 0.76391, saving model to ./mod5.h5\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.4118 - accuracy: 1.0000 - val_loss: 0.8357 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.76391\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.4084 - accuracy: 1.0000 - val_loss: 0.7589 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.76391 to 0.75894, saving model to ./mod5.h5\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.4083 - accuracy: 1.0000 - val_loss: 0.7801 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.75894\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.4017 - accuracy: 1.0000 - val_loss: 0.7577 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00090: val_loss improved from 0.75894 to 0.75768, saving model to ./mod5.h5\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.4054 - accuracy: 1.0000 - val_loss: 0.8295 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.75768\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.4348 - accuracy: 1.0000 - val_loss: 0.7646 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.75768\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.4433 - accuracy: 0.9880 - val_loss: 0.9336 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.75768\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.4227 - accuracy: 1.0000 - val_loss: 0.7605 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.75768\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.4050 - accuracy: 1.0000 - val_loss: 0.7638 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.75768\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3986 - accuracy: 1.0000 - val_loss: 0.7912 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.75768\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.3985 - accuracy: 1.0000 - val_loss: 0.7598 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.75768\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3932 - accuracy: 1.0000 - val_loss: 0.8244 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.75768\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3921 - accuracy: 1.0000 - val_loss: 0.7524 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00099: val_loss improved from 0.75768 to 0.75235, saving model to ./mod5.h5\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3872 - accuracy: 1.0000 - val_loss: 0.7482 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00100: val_loss improved from 0.75235 to 0.74819, saving model to ./mod5.h5\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3817 - accuracy: 1.0000 - val_loss: 0.8595 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.74819\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3917 - accuracy: 1.0000 - val_loss: 0.7494 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.74819\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.3973 - accuracy: 1.0000 - val_loss: 0.7560 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.74819\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3831 - accuracy: 1.0000 - val_loss: 0.7900 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.74819\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3819 - accuracy: 1.0000 - val_loss: 0.7418 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00105: val_loss improved from 0.74819 to 0.74183, saving model to ./mod5.h5\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.3840 - accuracy: 1.0000 - val_loss: 0.7648 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.74183\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3805 - accuracy: 1.0000 - val_loss: 0.7541 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.74183\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3778 - accuracy: 1.0000 - val_loss: 0.7416 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00108: val_loss improved from 0.74183 to 0.74157, saving model to ./mod5.h5\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3798 - accuracy: 1.0000 - val_loss: 0.7592 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.74157\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 1s 237ms/step - loss: 0.3791 - accuracy: 1.0000 - val_loss: 0.7353 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00110: val_loss improved from 0.74157 to 0.73533, saving model to ./mod5.h5\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3760 - accuracy: 1.0000 - val_loss: 0.7431 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.73533\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3850 - accuracy: 1.0000 - val_loss: 0.7355 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.73533\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3753 - accuracy: 1.0000 - val_loss: 0.7346 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00113: val_loss improved from 0.73533 to 0.73458, saving model to ./mod5.h5\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3755 - accuracy: 1.0000 - val_loss: 0.7747 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.73458\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.3766 - accuracy: 1.0000 - val_loss: 0.7280 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00115: val_loss improved from 0.73458 to 0.72796, saving model to ./mod5.h5\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3733 - accuracy: 1.0000 - val_loss: 0.7323 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.72796\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3710 - accuracy: 1.0000 - val_loss: 0.7323 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.72796\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3726 - accuracy: 1.0000 - val_loss: 0.7850 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.72796\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3704 - accuracy: 1.0000 - val_loss: 0.7343 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.72796\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3732 - accuracy: 1.0000 - val_loss: 0.7381 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.72796\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3692 - accuracy: 1.0000 - val_loss: 0.7429 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.72796\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3688 - accuracy: 1.0000 - val_loss: 0.7226 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00122: val_loss improved from 0.72796 to 0.72257, saving model to ./mod5.h5\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.3703 - accuracy: 1.0000 - val_loss: 0.7306 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.72257\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3658 - accuracy: 1.0000 - val_loss: 0.7197 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00124: val_loss improved from 0.72257 to 0.71975, saving model to ./mod5.h5\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3669 - accuracy: 1.0000 - val_loss: 0.7511 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.71975\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3662 - accuracy: 1.0000 - val_loss: 0.7201 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.71975\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.3661 - accuracy: 1.0000 - val_loss: 0.7124 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00127: val_loss improved from 0.71975 to 0.71236, saving model to ./mod5.h5\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.3663 - accuracy: 1.0000 - val_loss: 0.7335 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.71236\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3641 - accuracy: 1.0000 - val_loss: 0.7204 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.71236\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.3663 - accuracy: 1.0000 - val_loss: 0.7274 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.71236\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3626 - accuracy: 1.0000 - val_loss: 0.7195 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.71236\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3645 - accuracy: 1.0000 - val_loss: 0.7180 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.71236\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3639 - accuracy: 1.0000 - val_loss: 0.7185 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.71236\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3618 - accuracy: 1.0000 - val_loss: 0.7564 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.71236\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3605 - accuracy: 1.0000 - val_loss: 0.7120 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00135: val_loss improved from 0.71236 to 0.71196, saving model to ./mod5.h5\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3603 - accuracy: 1.0000 - val_loss: 0.7160 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.71196\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3592 - accuracy: 1.0000 - val_loss: 0.7601 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.71196\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3646 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.71196\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.3657 - accuracy: 1.0000 - val_loss: 0.7559 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.71196\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.3593 - accuracy: 1.0000 - val_loss: 0.7131 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.71196\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3604 - accuracy: 1.0000 - val_loss: 0.7388 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.71196\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3634 - accuracy: 1.0000 - val_loss: 0.7222 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.71196\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3615 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00143: val_loss improved from 0.71196 to 0.70742, saving model to ./mod5.h5\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3611 - accuracy: 1.0000 - val_loss: 0.7746 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.70742\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3606 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00145: val_loss improved from 0.70742 to 0.70544, saving model to ./mod5.h5\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3597 - accuracy: 1.0000 - val_loss: 0.7473 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.70544\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3615 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.70544\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3543 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.70544\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3539 - accuracy: 1.0000 - val_loss: 0.7085 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.70544\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3551 - accuracy: 1.0000 - val_loss: 0.7711 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.70544\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3600 - accuracy: 1.0000 - val_loss: 0.7251 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.70544\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3571 - accuracy: 1.0000 - val_loss: 0.7130 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.70544\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.3578 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.70544\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3524 - accuracy: 1.0000 - val_loss: 0.7465 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.70544\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.3556 - accuracy: 1.0000 - val_loss: 0.7018 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00155: val_loss improved from 0.70544 to 0.70182, saving model to ./mod5.h5\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3538 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.70182\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.3558 - accuracy: 1.0000 - val_loss: 0.7449 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.70182\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.3547 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.70182\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 1s 238ms/step - loss: 0.3574 - accuracy: 1.0000 - val_loss: 0.7143 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.70182\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3527 - accuracy: 1.0000 - val_loss: 0.7372 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.70182\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3517 - accuracy: 1.0000 - val_loss: 0.7063 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.70182\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 0.3550 - accuracy: 1.0000 - val_loss: 0.7576 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.70182\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.3566 - accuracy: 1.0000 - val_loss: 0.7152 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.70182\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3506 - accuracy: 1.0000 - val_loss: 0.7270 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.70182\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3594 - accuracy: 1.0000 - val_loss: 0.7787 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.70182\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3545 - accuracy: 1.0000 - val_loss: 0.7152 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.70182\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3530 - accuracy: 1.0000 - val_loss: 0.7224 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.70182\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3529 - accuracy: 1.0000 - val_loss: 0.7474 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.70182\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3527 - accuracy: 1.0000 - val_loss: 0.7086 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.70182\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.3540 - accuracy: 1.0000 - val_loss: 0.7182 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.70182\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3504 - accuracy: 1.0000 - val_loss: 0.7175 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.70182\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.3484 - accuracy: 1.0000 - val_loss: 0.7616 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.70182\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.3488 - accuracy: 1.0000 - val_loss: 0.7023 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.70182\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3514 - accuracy: 1.0000 - val_loss: 0.7431 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.70182\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3494 - accuracy: 1.0000 - val_loss: 0.7216 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.70182\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3491 - accuracy: 1.0000 - val_loss: 0.7100 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.70182\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.3489 - accuracy: 1.0000 - val_loss: 0.7188 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.70182\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3482 - accuracy: 1.0000 - val_loss: 0.7199 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.70182\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3476 - accuracy: 1.0000 - val_loss: 0.7276 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.70182\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.3451 - accuracy: 1.0000 - val_loss: 0.7044 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.70182\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3498 - accuracy: 1.0000 - val_loss: 0.7337 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.70182\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.3482 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.70182\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3503 - accuracy: 1.0000 - val_loss: 0.7193 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.70182\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3462 - accuracy: 1.0000 - val_loss: 0.7321 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.70182\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3481 - accuracy: 1.0000 - val_loss: 0.7260 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.70182\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3460 - accuracy: 1.0000 - val_loss: 0.7181 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.70182\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.3451 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.70182\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.3440 - accuracy: 1.0000 - val_loss: 0.7139 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.70182\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3453 - accuracy: 1.0000 - val_loss: 0.7067 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.70182\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3445 - accuracy: 1.0000 - val_loss: 0.7006 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00190: val_loss improved from 0.70182 to 0.70058, saving model to ./mod5.h5\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3438 - accuracy: 1.0000 - val_loss: 0.7219 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.70058\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3439 - accuracy: 1.0000 - val_loss: 0.7303 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.70058\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3428 - accuracy: 1.0000 - val_loss: 0.7087 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.70058\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.3425 - accuracy: 1.0000 - val_loss: 0.7259 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.70058\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.3458 - accuracy: 1.0000 - val_loss: 0.7110 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.70058\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.3415 - accuracy: 1.0000 - val_loss: 0.7190 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.70058\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3443 - accuracy: 1.0000 - val_loss: 0.7078 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.70058\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.3447 - accuracy: 1.0000 - val_loss: 0.7209 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.70058\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3468 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.70058\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3434 - accuracy: 1.0000 - val_loss: 0.7324 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.70058\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfXRc9X3n8fd3HqSRZMuSZVmyLcsytvFTAAOGmhBSGtKEEJ5awkOWbGmbwm6bbB7atHW2p0l6TnaXdNvm4ZyklDRsaZeQZCE0bA40CRSHTQsEG5zYYIMfsLBsyZJl68HWw2hmvvvHXBnZSLakkWakO5/XOXN05947M1/dGX3mp9/93XvN3RERkXCJFLoAERGZegp3EZEQUriLiISQwl1EJIQU7iIiIaRwFxEJIYW7FA0z+wcz21roOkTyQeEuIhJCCncRkRBSuEvRMrMNZva0mfWZ2XEze8jM6s5Y57NmttfMBszsiJn9i5nVB8viZvZXZvammQ2a2WEze8zMSgrzG4m8JVboAkQKwcxqgS3ALuA/AHOAe4GfmNlGd0+a2W8B/xX4U+AVoAZ4D1ARPM1ngTuBzcAbQD1wHRDN328iMjqFuxSrPwp+vt/dewDMbA/wPHAL8DBwOfBjd//GiMd9f8T05cC33f3BEfO+N30li4yfumWkWA0Hd8/wDHd/ATgAvCuYtR24zsz+wswuN7MzW+Tbgd82sz8xswvNzPJRuMh4KNylWC0Cjowy/wgwP5h+gGy3zG3AC8ARM/viiJD/IvB14A+AXwAHzeyT01q1yDgp3KVYtQILR5lfBxwDcPeMu3/Z3dcCjcBfke1nvztYPuDun3P3JuB84LvAV8zs2jzUL3JWCncpVi8A7zezucMzzOwyoAn42Zkru/tBd78X2AusG2X5HuAzwOBoy0XyTTtUpVj9DfD7wI/M7Eu8NVpmB/AogJn9HdlW/PNAN/BrwCqyo2cws8eAbcDLQD/wIbJ/U8/m8xcRGY3CXYqSu3eY2a8Bf012ZEwSeAL4tLsng9WeI9sF85+ABNlW+93u/s/B8n8Hbgf+mOx/wa8Ct7i7TnEgBWe6zJ6ISPioz11EJIQU7iIiIaRwFxEJIYW7iEgIzYjRMgsWLPCmpqZClyEiMqts27btqLvXjrZsRoR7U1MTW7dq9JiIyESYWfNYy9QtIyISQgp3EZEQUriLiITQjOhzFxGZjKGhIVpaWhgYGCh0KdMqkUjQ0NBAPB4f92POGe5m9gBwPdDu7u8I5s0ne3rTJrIXN7jN3Y8HFyv4KtlLjfUBv+3uL03w9xARGZeWlhbmzp1LU1MTYb1WirvT2dlJS0sLy5cvH/fjxtMt8w/Ameen3gw87e6rgKeD+wAfIHvWvFXAPcDfjrsSEZEJGhgYoKamJrTBDmBm1NTUTPi/k3OGu7s/S3DxghFuAoavG/kgcPOI+f/oWc8DVWa2aEIViYhMQJiDfdhkfsfJ7lCtc/fWYLqN7NVrAJYAB0es1xLMexszu8fMtprZ1o6OjkkV8eKBY9z75G50ZksRkdPlPFrGs8k64XR19/vdfaO7b6ytHfUAq3P6ZUs39/10H119Q5N6vIhILrq6uvjGN74x4cddd911dHV1TUNFb5lsuB8Z7m4JfrYH8w8BS0es1xDMmxb1lQkA2nrCvadcRGamscI9lUqd9XFPPPEEVVVV01UWMPlwfxy4K5i+C/jBiPm/ZVmbgO4R3TdTrq6yFIAjCncRKYDNmzezb98+NmzYwGWXXcZVV13FjTfeyLp12cvo3nzzzVx66aWsX7+e+++//9TjmpqaOHr0KAcOHGDt2rXcfffdrF+/nve973309/dPSW3jGQr5MHA1sMDMWoDPk73W5PfM7KNAM3BbsPoTZIdB7iU7FPJ3pqTKMdQFLXeFu4j8xf99hVcP90zpc65bXMnnb1g/5vJ7772XnTt3sn37drZs2cIHP/hBdu7ceWrI4gMPPMD8+fPp7+/nsssu45ZbbqGmpua059izZw8PP/ww3/zmN7ntttt49NFH+chHPpJz7ecMd3f/8BiLrhllXQc+lmtR4zUc7m3dg/l6SRGRMV1++eWnjUX/2te+xmOPPQbAwYMH2bNnz9vCffny5WzYsAGASy+9lAMHDkxJLbP6CNWSWISaihL1uYvIWVvY+VJRUXFqesuWLTz11FM899xzlJeXc/XVV486Vr20tPTUdDQanbJumVl/bpm6yoS6ZUSkIObOnUtvb++oy7q7u6murqa8vJzdu3fz/PPP57W2Wd1yh+xOVYW7iBRCTU0NV155Je94xzsoKyujrq7u1LJrr72W++67j7Vr17J69Wo2bdqU19pmfbjXz0uw41B3ocsQkSL17W9/e9T5paWlPPnkk6MuG+5XX7BgATt37jw1/zOf+cyU1RWKbpmjJ5IkU5lClyIiMmPM+nAfPpCpvVddMyIiw2Z3uL/0T9zws5uIkuZIj4ZDiogMm93hnhmiomc/C+jWTlURkRFmd7hXZk84uciO0datcBcRGTbLw30xAA2x42q5i4iMMLvDfW423FclunWUqojMeHPmzMnba83ucC+fD9FSmuLqcxcRGWl2H8RkBpWLWZI6rtEyIpJ3mzdvZunSpXzsY9nzJX7hC18gFovxzDPPcPz4cYaGhvjiF7/ITTfdlPfaZne4A1QuYWFnJ23dA7h7UVxPUURG8eRmaNsxtc9ZfwF84N4xF99+++186lOfOhXu3/ve9/jRj37EJz7xCSorKzl69CibNm3ixhtvzHs2hSDcF1N95Gf0D6XpGUgxryxe6IpEpEhcfPHFtLe3c/jwYTo6Oqiurqa+vp5Pf/rTPPvss0QiEQ4dOsSRI0eor6/Pa22hCPeKwXaMDO09Awp3kWJ1lhb2dLr11lt55JFHaGtr4/bbb+ehhx6io6ODbdu2EY/HaWpqGvVUv9Ntdu9QBahcQsRT1NCrETMikne333473/nOd3jkkUe49dZb6e7uZuHChcTjcZ555hmam5sLUlcoWu4A9dapA5lEJO/Wr19Pb28vS5YsYdGiRdx5553ccMMNXHDBBWzcuJE1a9YUpK4QhbsOZBKRwtix460duQsWLOC5554bdb0TJ07kq6RwdMsALC/RgUwiIsNmf7hX1EIkxorSbo11FxEJzP5wj0Rg7iIaouqWESlG7l7oEqbdZH7H2R/uAJWLtUNVpAglEgk6OztDHfDuTmdnJ4lEYkKPm/07VAEqF1PTsZWjJwZJpTPEouH4zhKRs2toaKClpYWOjo5ClzKtEokEDQ0NE3pMSMJ9CXOTT5Jxp+PEIIvmlRW6IhHJg3g8zvLlywtdxowUjiZu5WJimQHmcZLDXeqaEREJTbhD9opMh7v6C1yMiEjhhSTcs2Pd662T1m6Fu4hISMI923JvinerW0ZEhLCE+5w6sAgrEj3qlhERISyjZaJxqFhIo3dxWN0yIiK5tdzN7NNm9oqZ7TSzh80sYWbLzewFM9trZt81s5KpKvasKhezyI7Rqm4ZEZHJh7uZLQE+AWx093cAUeAO4EvAl919JXAc+OhUFHpOlYupyRyl82SSgaF0Xl5SRGSmyrXPPQaUmVkMKAdagfcAjwTLHwRuzvE1xqdyCZXJdgBadRoCESlykw53dz8E/BXwJtlQ7wa2AV3ungpWawGWjPZ4M7vHzLaa2dYpOXS4cjHx1Anm0EerdqqKSJHLpVumGrgJWA4sBiqAa8f7eHe/3903uvvG2trayZbxlnnZ8y4ssmMcUriLSJHLpVvmvcAb7t7h7kPA94ErgaqgmwagATiUY43jE4T7EjuqbhkRKXq5hPubwCYzKzczA64BXgWeAT4UrHMX8IPcShyneUsBWJ3o0lh3ESl6ufS5v0B2x+lLwI7gue4H/hT4QzPbC9QA35qCOs9tbj1EYqws7eKwWu4iUuRyOojJ3T8PfP6M2fuBy3N53kmJRKFyMctSnWq5i0jRC8fpB4bNa6SOo7R29Yf6yiwiIucSsnBvoGboCCeTaXr6U+deX0QkpMIV7lVLqRhsJ0ZK55gRkaIWrnCf14CRoY7j6ncXkaIWsnDPDodcYkc1YkZEilq4wr2qEYClUY2YEZHiFq5wDy63tzrRpfPLiEhRC1e4l5RD+QKWlxzX5fZEpKiFK9wB5jXQYEc1WkZEilr4wr1qKbWZDtq6B0hndCCTiBSn8IX7vEaqkm2kMhk6egcLXY2ISEGEMNwbiKUHqKZX53UXkaIVvnCvyo51X2ydtBzvK3AxIiKFEb5wDy7a0WBHaTmulruIFKcQhnv2QKZViS613EWkaIUv3MvnQ6yMVaXHOXhMLXcRKU7hC3czqFpKY/SYWu4iUrTCF+4A85ZS7x0c6urXWHcRKUohDfcGqoaOMJR22nt1GgIRKT7hDPeqpZQlj1FKUv3uIlKUwhnuI87rrn53ESlG4Qz3qmUALLUOtdxFpCiFM9yrmwBYV6YRMyJSnMIZ7nPqIJZgTekxDircRaQIhTPcIxGoaqQp0qFTEIhIUQpnuANUN1HvR2jtHiCVzhS6GhGRvApvuFcto3rwEOlMhtZujXUXkeIS3nCvbqIkdYJ5nFTXjIgUnVCHO8BSa9dOVREpOiEO9+xY92WRdrXcRaTohDfcgwOZ1iWO03JMLXcRKS45hbuZVZnZI2a228x2mdkVZjbfzH5iZnuCn9VTVeyEJCqhvIbzSzrVcheRopNry/2rwL+4+xrgImAXsBl42t1XAU8H9wujahmNEfW5i0jxmXS4m9k84N3AtwDcPenuXcBNwIPBag8CN+da5KRVN7EwfYS2ngGSKY11F5HikUvLfTnQAfwvM3vZzP7ezCqAOndvDdZpA+pGe7CZ3WNmW81sa0dHRw5lnEX1MuYNtmKe4XCXumZEpHjkEu4x4BLgb939YuAkZ3TBuLsDo14Kyd3vd/eN7r6xtrY2hzLOorqJiKeo5xhvaqeqiBSRXMK9BWhx9xeC+4+QDfsjZrYIIPjZnluJOQjGujdG2mlWuItIEZl0uLt7G3DQzFYHs64BXgUeB+4K5t0F/CCnCnMRDIc8L9pB89GTBStDRCTfYjk+/r8AD5lZCbAf+B2yXxjfM7OPAs3AbTm+xuTNawCLsr78OFvUcheRIpJTuLv7dmDjKIuuyeV5p0w0DvOWsDLVyYOdarmLSPEI7xGqw6qbWOJHaO7sI5MZdd+uiEjoFEW41wy1MpjKcKRXp/4VkeIQ/nCvWkZZspMyBmjuVL+7iBSH8If7qVP/dtCsfncRKRLhD/f55wGwInqEA2q5i0iRCH+416wA4KLyTrXcRaRohD/cE/Ogopa1Je3qcxeRohH+cAeoWckyWmnu7CN7uhsRkXArjnCfv4KFyUOcGEzReTJZ6GpERKZdcYR7zQrKkx1U0K+uGREpCkUS7isBaLI27VQVkaJQJOGeHTFzXqRNwyFFpCgUR7gHY90vLDuqlruIFIXiCPd4GcxbquGQIlI0iiPcAeafRyOtarmLSFEonnCvWUld8iDH+5J09w8VuhoRkWlVVOFemuqlml613kUk9Ioo3LMjZpZbG2/oeqoiEnJFFO7Zse7nRdrY136iwMWIiEyv4gn3qkaIxLio/Cj7OtRyF5FwK55wj8ahuok18Xb2dajlLiLhVjzhDjB/BY20sv/oSdK6WLaIhFhxhXvNSmoGW0im0rQc18FMIhJeRRbuK4il+6njuLpmRCTUii7cAc6LtLKvXTtVRSS8iivcF6wGYEOijb0aDikiIVZc4T63HkrncVFCI2ZEJNyKK9zNoPZ8VtkhhbuIhFpxhTtA7WoWDTVzvG+IzhODha5GRGRaFGG4r6E82UkVvTpSVURCqyjDHWClumZEJMRyDnczi5rZy2b2w+D+cjN7wcz2mtl3zawk9zKnUG12xMy6+GGdQExEQmsqWu6fBHaNuP8l4MvuvhI4Dnx0Cl5j6lQ2QLyci8s62KuWu4iEVE7hbmYNwAeBvw/uG/Ae4JFglQeBm3N5jSkXicCC81kTPaxuGREJrVxb7l8B/gTIBPdrgC53TwX3W4Aloz3QzO4xs61mtrWjoyPHMiaodg0NqWZajvczMJTO72uLiOTBpMPdzK4H2t1922Qe7+73u/tGd99YW1s72TImp3Y1c5PtVHgf+zViRkRCKJbDY68EbjSz64AEUAl8Fagys1jQem8ADuVe5hQLdqqutMPs7TjBusWVBS5IRGRqTbrl7u6fdfcGd28C7gD+1d3vBJ4BPhSsdhfwg5yrnGrBcMjzo4d4ra2nwMWIiEy96Rjn/qfAH5rZXrJ98N+ahtfITdUyiJZyWXk7r7X1FroaEZEpl0u3zCnuvgXYEkzvBy6fiuedNtEYLFjF2hOtfKVV4S4i4VN8R6gOq13N0vRBDnX10zMwVOhqRESmVPGG+4LVVA4cpowBXlfXjIiETPGGe+1qDOc8a2W3wl1EQqaIwz07Yuai0sPs1ogZEQmZ4g33mpUQS3BFeatGzIhI6BRvuEdjsHAd6yLN7G7rxd0LXZGIyJQp3nAHqL+AhsG99A4Mcbh7oNDViIhMmaIP99KhbhZxTEeqikioFHm4XwjAusgBdulgJhEJkeIO97p1gLGp/LB2qopIqBR3uJfOhfnncUnJQQ2HFJFQKe5wB6i/gBXpN9jfcZLBlC7cISLhoHCvv4CqwUOUZU6yr10X7hCRcFC4BztV19ib6poRkdBQuNdfAMBF8Td55bDCXUTCQeE+tx7KF7Cp/DA7D3UXuhoRkSmhcDeD+gtYa828eriHTEanIRCR2U/hDlB/AfWD++kfHKD5WF+hqxERyZnCHaD+QqKZIVaaumZEJBwU7vDWTtVoMzsPK9xFZPZTuAMsWAXxCt4156Ba7iISCgp3gEgUFm/gosh+drR069zuIjLrKdyHLbmEJQN76B8Y4I2jOlJVRGY3hfuwJZcSzQyxxt5k+8GuQlcjIpIThfuwxZcAcFn8DYW7iMx6CvdhVY1QvoB3V6jlLiKzn8J9mBksuZT17GVXaw8DQzr9r4jMXgr3kRouY0H/AcrSvTqJmIjMagr3kRo3YTgbI6/z8pvHC12NiMikKdxHatgIkTi/VraPlxTuIjKLKdxHipfB4ou5smQPLx44roOZRGTWmnS4m9lSM3vGzF41s1fM7JPB/Plm9hMz2xP8rJ66cvNg2RUsG9hNT28vb+oMkSIyS+XSck8Bf+Tu64BNwMfMbB2wGXja3VcBTwf3Z4/GdxL1FBtsHy8eUNeMiMxOkw53d29195eC6V5gF7AEuAl4MFjtQeDmXIvMq6WXA3BV6R62HjhW4GJERCZnSvrczawJuBh4Aahz99ZgURtQN8Zj7jGzrWa2taOjYyrKmBrl82HhOq5O7OFFhbuIzFI5h7uZzQEeBT7l7qcNDvfsHslR90q6+/3uvtHdN9bW1uZaxtRqvILzh3ZxoKOH9t6BQlcjIjJhOYW7mcXJBvtD7v79YPYRM1sULF8EtOdWYgEseycl6T7WWjPP71frXURmn1xGyxjwLWCXu//NiEWPA3cF03cBP5h8eQXSeAUA7yrZy3P7OgtcjIjIxOXScr8S+I/Ae8xse3C7DrgX+HUz2wO8N7g/u8xbAlWNvLdiH8/tO1roakREJiw22Qe6+88AG2PxNZN93hmj8Z2s3/VjDvSepLW7n0XzygpdkYjIuOkI1bEsv4qyoWOssYP8+151zYjI7KJwH8uK9wDw/sRO/m2vumZEZHZRuI+lcjEsXMd1Za/y7J6jZDI6z4yIzB4K97NZ8R5WDuzg5IludrXp/O4iMnso3M9m5TVEM0P8SmQXz76urhkRmT0U7mfT+E6IlfGbc17l2ddn0CkSRETOQeF+NvEErLyGX2UrW5s7OTGYKnRFIiLjonA/l9XXMS95hPMzb7Dltdl3JgURKU4K93M5/1rcItyceJkfv3Kk0NWIiIyLwv1cKmqwxiu4vuQlntndTjKVKXRFIiLnpHAfjzUfZNHgfhYkD/LvOteMiMwCCvfxWP8bOMYt8ed4ckdboasRETknhft4VC7Gmt7FrYmf88TOwwwMpQtdkYjIWSncx+uCD1GXfJPGwb08tUs7VkVkZlO4j9faG/FInI+UP8/3XzpU6GpERM5K4T5e5fOxtdfzG2zhhddbaO/RtVVFZOZSuE/EZXeTSPdyvf0bD73wZqGrEREZk8J9Ipa9Exau5w/K/5Vvv9CsMe8iMmMp3CfCDC6/m2VD+1jZ9zJP7mwtdEUiIqNSuE/URR/GKxbymbIfct9P9+siHiIyIyncJyqewN75cS5N/4KStpf48as6qElEZh6F+2Rs/F08UcWfl3+fr/zkdbXeRWTGUbhPRulc7OrPsjG9nWUd/8oj21oKXZGIyGkU7pN12e/hdev5b4mH+OoT2+g8MVjoikRETlG4T1Y0hl3/FWr8GH+e/jqf++eduKt7RkRmBoV7LpZejv36X3Bt5Oes3PV1vvzUnkJXJCICKNxzd8XH8Qtv59PxR6n86ef4xlOvqgUvIgUXK3QBs54ZdvN9pEvn8Xsv3s+h//dzfvLLq2la1oQtuYRE0yYa6mows0JXKiJFROE+FSIRotf9JX7+++CH/52run9I2Y5B2AFdXsHfRT5I9PKPcuc1Gykv0SYXkelnM6ELYePGjb5169ZClzFlkqkMv9jbTEnrVubv+t8sbd/CkEfZZuuJL1rP3KXrmbt4DTX1DZQsWAGxkkKXLCKzkJltc/eNoy6bjnA3s2uBrwJR4O/d/d6zrR+2cH+bjtdp++n9DL6+hYWDzZRZ8tSiQeIciS0hVlpOpmIhPqeOREmceHkViTnVlCaPYRU1UHcBRGPgGXAPfmZIO0SrG6GiFlKDkE5CNA4VC7PTOJRWZpclT0JZdfYcOamB7P3EvOz6Zxrqh869sGD16F8+qSRkhqCkYnzbID0Eva0wdzEM9sDxA7BwLVgEulugugki0dEfl05mXyeTzt6PJ8b3miIhl9dwN7Mo8Drw60AL8CLwYXd/dazHhD7cR2jv6ePQgT30Ht5D37EWyo7tItHTzMBAHws5Tq11YTiV9BG3NAMeJ2FDOb1mOlJKNJMdh5+JxMEzRDx7qcCMxUhWLCJjMaLJbuLJHlKJGmKDx4lkkqRj5aQS1ZT0HyVVVkM6MR/zDPGufVg6SbKykUgmhWWGyJTXEkn1Y6l+vHwBlk5iqQG8tJJI134seRKPxLFM9vfxaCngWDqJJ6rw8hrsZDs+px6vqINMkkjbDkgN4PNXYL2tkB7E6y6A5AlsoBuvWYUnqiAzhJ3sgFgCyudnvwRSg5AeyH4RxUogVoa1/TK7URZf8tYXkxlgb00H+0fMHXoOwUB39sunpCL7xXpKMH1q3ohlFgGLZr+wLJK9MWK/y2m7YM7YH3Pa/hkbY/5kl43ztUYuy6ShL7gwfNn80xsRkShEYtnfdaAbhvogXp79Ao6WjlIX2YZJsg/w7GOj8ew2zKSyt/QQeDr7nMOvMdibraO8Jns/kz7VwMEzwf0R8+IVUDon+zqefus9GH4/3lbTaDk4yrwx83K8644y78I7YPlVYzzv2eU73K8AvuDu7w/ufxbA3f/HWI8ppnAfSzKV4eiJQTpPJDl6YpDjJwfoOXGCzoEI8aFu5vcf4NiJJO0nknSeTHFyyKmuKOUdiyroOvQ6fT2dnExHSXqcUhuihm6SxDGcBdZNr5dzkgS11k0G46SX0UcptdbFEjtKnDQ9Xk4Xc6ili2PMZXemkQ2RvVRaHx1eRY11M4+TAOzzxZz0Ms6PHGSQEpIeo9a66KeUAS9hvvWSJMYAJVTSx2Gv4TVfSoMdpcfLafY6Lozsw4nQ7AvZYPuYE7xOvR2n2npxjF2ZRnqoYK01c9hr6CPBBttLDxX0eDnnRVqpYIA0ETq9klIboooTJIkxSJykx0kSo5QhKmyA3ZlGDGd95ABxUmRjPfs3YCP+8Ian26mmx8tZah2U8PYvWQ8C0TGw7N+zGURwomSInLq9/bmz06cba5mdEQpne45TAWITea0zn/8tGYwuKjGcefQySAlDxIiRIUo6uGU4QTkDlFLCEIlgrdE4xgClOEaMNFFSgJEKnillMdJEiJIh5imiZOizBE6ESu8lQib7yhbBMTJESBPBR2zpBINUeB8DliBF9LT3IUJmtIgdY0uOuXWn7PEtl/wxl9zw+2M+69mcLdynY+/eEuDgiPstwK9Mw+uESkkswuKqMhZXlY2xxrk3obszmMowOJRhMJ0mmcowmMqQDG6pTIZoJEIsYkSD28nBFCcGUyTiUZriUWJRo71nkOpUhrWxCCWxCP3JNEO9g8RLoiQjxmAqzbJ4jNJYhKF0hkjGiaUzdKWdVDrDUMZpTr31B9QZNCCagvvzg9twu+I8oBunO1je7NA8/DsBpcD+YH0DfgF48OxHGbsxNbLhMnIdB9pGnT/2+jtHWXBaG36cz3Ou9ceYPOvvMpEaRvJp+F0Ya/0zapj2bTTm85x7/Xy7Y83SaXnegg3dMLN7gHsAGhsbC1VGqJgZiXiURDwKjNKPPk5r6qeuJhEpjOk4iOkQMPKrqCGYdxp3v9/dN7r7xtra2mkoQ0SkeE1HuL8IrDKz5WZWAtwBPD4NryMiImOY8m4Zd0+Z2ceBH5EdCvmAu78y1a8jIiJjm5Y+d3d/AnhiOp5bRETOTScOExEJIYW7iEgIKdxFREJI4S4iEkIz4qyQZtbBWwclTtQCsgcqzkQztTbVNTGqa+Jmam1hq2uZu496oNCMCPdcmNnWsc6tUGgztTbVNTGqa+Jmam3FVJe6ZUREQkjhLiISQmEI9/sLXcBZzNTaVNfEqK6Jm6m1FU1ds77PXURE3i4MLXcRETmDwl1EJIRmdbib2bVm9pqZ7TWzzQWsY6mZPWNmr5rZK2b2yWD+F8zskJltD27XFaC2A2a2I3j9rcG8+Wb2EzPbE/ysznNNq0dsk+1m1mNmnyrU9jKzB8ys3cx2jpg36jayrK8Fn7lfmtklea7rf5rZ7uC1HzOzqmB+k5n1j9h29+W5rjHfOzP7bLC9XjOz909XXWep7bsj6jpgZtuD+XnZZmfJh+n9jLn7rLyRPZ3wPrJXaSshe/W1dQWqZRFwScxD4M4AAAOUSURBVDA9l+wFwtcBXwA+U+DtdABYcMa8vwQ2B9ObgS8V+H1sA5YVansB7wYuAXaeaxsB1wFPkr3i3ybghTzX9T4gFkx/aURdTSPXK8D2GvW9C/4OfkH2aonLg7/ZaD5rO2P5XwOfy+c2O0s+TOtnbDa33C8H9rr7fndPAt8BbipEIe7e6u4vBdO9wC6y15KdqW4CHgymHwRuLmAt1wD73H2yRyjnzN2fBY6dMXusbXQT8I+e9TxQZWaL8lWXu//Y3VPB3efJXuksr8bYXmO5CfiOuw+6+xvAXrJ/u3mvzcwMuA14eLpef4yaxsqHaf2MzeZwH+1C3AUPVDNrAi4GXghmfTz41+qBfHd/BBz4sZlts+x1awHq3L01mG4D6gpQ17A7OP2PrdDba9hY22gmfe5+l2wLb9hyM3vZzH5qZlcVoJ7R3ruZtL2uAo64+54R8/K6zc7Ih2n9jM3mcJ9xzGwO8CjwKXfvAf4WWAFsAFrJ/kuYb+9y90uADwAfM7N3j1zo2f8DCzIe1rKXYbwR+D/BrJmwvd6mkNtoLGb2Z0AKeCiY1Qo0uvvFwB8C3zazyjyWNCPfuzN8mNMbEnndZqPkwynT8RmbzeE+rgtx54uZxcm+cQ+5+/cB3P2Iu6fdPQN8k2n8d3Qs7n4o+NkOPBbUcGT437zgZ3u+6wp8AHjJ3Y8ENRZ8e40w1jYq+OfOzH4buB64MwgFgm6PzmB6G9m+7fPzVdNZ3ruCby8AM4sBvwl8d3hePrfZaPnANH/GZnO4z5gLcQd9ed8Cdrn734yYP7Kf7DeAnWc+dprrqjCzucPTZHfG7SS7ne4KVrsL+EE+6xrhtJZUobfXGcbaRo8DvxWMaNgEdI/413ramdm1wJ8AN7p734j5tWYWDabPA1YB+/NY11jv3ePAHWZWambLg7p+nq+6RngvsNvdW4Zn5GubjZUPTPdnbLr3FE/njexe5dfJfuP+WQHreBfZf6l+CWwPbtcB/wTsCOY/DizKc13nkR2p8AvgleFtBNQATwN7gKeA+QXYZhVAJzBvxLyCbC+yXzCtwBDZ/s2PjrWNyI5g+HrwmdsBbMxzXXvJ9scOf87uC9a9JXiPtwMvATfkua4x3zvgz4Lt9RrwgXy/l8H8fwD+8xnr5mWbnSUfpvUzptMPiIiE0GzulhERkTEo3EVEQkjhLiISQgp3EZEQUriLiISQwl1EJIQU7iIiIfT/ASuogcF5PwRHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 29ms/step - loss: 0.3663 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6668 - accuracy: 0.8800\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7006 - accuracy: 0.8462\n",
            "(None, 19, 19, 19, 1)\n",
            "Model: \"model_26\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_28 (InputLayer)           [(None, 19, 19, 19,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3941 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3943 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3945 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3947 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3949 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3951 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3953 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3955 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3957 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3959 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3961 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3963 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3965 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3967 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3969 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3971 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3973 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3975 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3977 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3979 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3981 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3983 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3985 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3987 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3989 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3991 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3993 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3995 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3997 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3999 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4001 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4003 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4005 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4007 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4009 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4011 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4013 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4015 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4017 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4019 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4021 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4023 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4025 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4027 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4029 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4031 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4033 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4035 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4037 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4039 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4041 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4043 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4045 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4047 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4049 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4051 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4053 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4055 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4057 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4059 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4061 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4063 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4065 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4067 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4069 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4071 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4073 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4075 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4077 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4079 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4081 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4083 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4085 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4087 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4089 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4091 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4093 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4095 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4097 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4099 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4101 (Lambda)            (None, 19, 3, 19, 1) 0           input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3940 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3941[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3942 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3943[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3944 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3945[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3946 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3947[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3948 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3949[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3950 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3951[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3952 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3953[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3954 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3955[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3956 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3957[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3958 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3959[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3960 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3961[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3962 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3963[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3964 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3965[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3966 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3967[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3968 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3969[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3970 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3971[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3972 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3973[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3974 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3975[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3976 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3977[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3978 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3979[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3980 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3981[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3982 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3983[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3984 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3985[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3986 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3987[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3988 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3989[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3990 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3991[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3992 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3993[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3994 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3995[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3996 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3997[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3998 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_3999[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4000 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4001[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4002 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4003[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4004 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4005[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4006 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4007[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4008 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4009[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4010 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4011[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4012 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4013[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4014 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4015[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4016 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4017[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4018 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4019[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4020 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4021[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4022 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4023[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4024 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4025[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4026 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4027[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4028 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4029[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4030 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4031[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4032 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4033[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4034 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4035[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4036 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4037[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4038 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4039[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4040 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4041[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4042 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4043[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4044 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4045[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4046 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4047[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4048 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4049[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4050 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4051[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4052 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4053[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4054 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4055[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4056 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4057[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4058 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4059[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4060 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4061[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4062 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4063[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4064 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4065[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4066 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4067[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4068 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4069[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4070 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4071[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4072 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4073[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4074 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4075[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4076 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4077[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4078 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4079[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4080 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4081[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4082 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4083[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4084 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4085[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4086 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4087[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4088 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4089[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4090 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4091[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4092 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4093[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4094 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4095[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4096 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4097[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4098 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4099[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4100 (Lambda)            (None, 19, 3, 3, 1)  0           lambda_4101[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1970 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3940[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1971 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3942[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1972 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3944[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1973 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3946[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1974 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3948[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1975 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3950[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1976 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3952[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1977 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3954[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1978 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3956[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1979 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3958[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1980 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3960[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1981 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3962[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1982 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3964[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1983 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3966[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1984 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3968[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1985 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3970[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1986 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3972[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1987 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3974[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1988 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3976[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1989 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3978[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1990 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3980[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1991 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3982[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1992 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3984[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1993 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3986[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1994 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3988[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1995 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3990[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1996 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3992[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1997 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3994[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1998 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3996[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1999 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_3998[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2000 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4000[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2001 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4002[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2002 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4004[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2003 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4006[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2004 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4008[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2005 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4010[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2006 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4012[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2007 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4014[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2008 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4016[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2009 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4018[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2010 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4020[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2011 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4022[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2012 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4024[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2013 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4026[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2014 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4028[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2015 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4030[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2016 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4032[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2017 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4034[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2018 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4036[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2019 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4038[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2020 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4040[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2021 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4042[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2022 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4044[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2023 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4046[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2024 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4048[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2025 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4050[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2026 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4052[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2027 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4054[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2028 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4056[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2029 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4058[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2030 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4060[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2031 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4062[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2032 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4064[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2033 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4066[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2034 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4068[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2035 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4070[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2036 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4072[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2037 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4074[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2038 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4076[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2039 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4078[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2040 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4080[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2041 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4082[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2042 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4084[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2043 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4086[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2044 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4088[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2045 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4090[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2046 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4092[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2047 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4094[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2048 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4096[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2049 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4098[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2050 (Conv3D)            (None, 17, 1, 1, 16) 448         lambda_4100[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1970 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1970[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1971 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1971[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1972 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1972[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1973 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1973[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1974 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1974[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1975 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1975[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1976 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1976[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1977 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1977[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1978 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1978[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1979 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1979[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1980 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1980[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1981 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1981[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1982 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1982[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1983 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1983[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1984 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1984[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1985 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1985[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1986 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1986[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1987 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1987[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1988 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1988[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1989 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1989[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1990 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1990[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1991 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1991[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1992 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1992[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1993 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1993[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1994 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1994[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1995 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1995[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1996 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1996[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1997 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1997[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1998 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1998[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1999 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_1999[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2000 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2000[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2001 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2001[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2002 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2002[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2003 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2003[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2004 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2004[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2005 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2005[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2006 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2006[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2007 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2007[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2008 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2008[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2009 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2009[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2010 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2010[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2011 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2011[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2012 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2012[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2013 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2013[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2014 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2014[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2015 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2015[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2016 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2016[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2017 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2017[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2018 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2018[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2019 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2019[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2020 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2020[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2021 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2021[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2022 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2022[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2023 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2023[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2024 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2024[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2025 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2025[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2026 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2026[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2027 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2027[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2028 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2028[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2029 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2029[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2030 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2030[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2031 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2031[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2032 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2032[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2033 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2033[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2034 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2034[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2035 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2035[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2036 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2036[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2037 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2037[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2038 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2038[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2039 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2039[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2040 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2040[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2041 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2041[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2042 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2042[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2043 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2043[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2044 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2044[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2045 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2045[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2046 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2046[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2047 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2047[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2048 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2048[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2049 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2049[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2050 (Dropout)          (None, 17, 1, 1, 16) 0           conv3d_2050[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1518 (Glob (None, 16)           0           dropout_1970[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1519 (Glob (None, 16)           0           dropout_1971[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1520 (Glob (None, 16)           0           dropout_1972[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1521 (Glob (None, 16)           0           dropout_1973[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1522 (Glob (None, 16)           0           dropout_1974[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1523 (Glob (None, 16)           0           dropout_1975[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1524 (Glob (None, 16)           0           dropout_1976[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1525 (Glob (None, 16)           0           dropout_1977[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1526 (Glob (None, 16)           0           dropout_1978[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1527 (Glob (None, 16)           0           dropout_1979[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1528 (Glob (None, 16)           0           dropout_1980[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1529 (Glob (None, 16)           0           dropout_1981[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1530 (Glob (None, 16)           0           dropout_1982[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1531 (Glob (None, 16)           0           dropout_1983[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1532 (Glob (None, 16)           0           dropout_1984[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1533 (Glob (None, 16)           0           dropout_1985[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1534 (Glob (None, 16)           0           dropout_1986[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1535 (Glob (None, 16)           0           dropout_1987[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1536 (Glob (None, 16)           0           dropout_1988[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1537 (Glob (None, 16)           0           dropout_1989[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1538 (Glob (None, 16)           0           dropout_1990[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1539 (Glob (None, 16)           0           dropout_1991[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1540 (Glob (None, 16)           0           dropout_1992[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1541 (Glob (None, 16)           0           dropout_1993[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1542 (Glob (None, 16)           0           dropout_1994[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1543 (Glob (None, 16)           0           dropout_1995[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1544 (Glob (None, 16)           0           dropout_1996[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1545 (Glob (None, 16)           0           dropout_1997[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1546 (Glob (None, 16)           0           dropout_1998[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1547 (Glob (None, 16)           0           dropout_1999[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1548 (Glob (None, 16)           0           dropout_2000[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1549 (Glob (None, 16)           0           dropout_2001[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1550 (Glob (None, 16)           0           dropout_2002[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1551 (Glob (None, 16)           0           dropout_2003[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1552 (Glob (None, 16)           0           dropout_2004[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1553 (Glob (None, 16)           0           dropout_2005[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1554 (Glob (None, 16)           0           dropout_2006[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1555 (Glob (None, 16)           0           dropout_2007[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1556 (Glob (None, 16)           0           dropout_2008[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1557 (Glob (None, 16)           0           dropout_2009[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1558 (Glob (None, 16)           0           dropout_2010[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1559 (Glob (None, 16)           0           dropout_2011[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1560 (Glob (None, 16)           0           dropout_2012[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1561 (Glob (None, 16)           0           dropout_2013[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1562 (Glob (None, 16)           0           dropout_2014[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1563 (Glob (None, 16)           0           dropout_2015[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1564 (Glob (None, 16)           0           dropout_2016[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1565 (Glob (None, 16)           0           dropout_2017[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1566 (Glob (None, 16)           0           dropout_2018[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1567 (Glob (None, 16)           0           dropout_2019[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1568 (Glob (None, 16)           0           dropout_2020[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1569 (Glob (None, 16)           0           dropout_2021[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1570 (Glob (None, 16)           0           dropout_2022[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1571 (Glob (None, 16)           0           dropout_2023[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1572 (Glob (None, 16)           0           dropout_2024[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1573 (Glob (None, 16)           0           dropout_2025[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1574 (Glob (None, 16)           0           dropout_2026[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1575 (Glob (None, 16)           0           dropout_2027[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1576 (Glob (None, 16)           0           dropout_2028[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1577 (Glob (None, 16)           0           dropout_2029[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1578 (Glob (None, 16)           0           dropout_2030[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1579 (Glob (None, 16)           0           dropout_2031[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1580 (Glob (None, 16)           0           dropout_2032[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1581 (Glob (None, 16)           0           dropout_2033[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1582 (Glob (None, 16)           0           dropout_2034[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1583 (Glob (None, 16)           0           dropout_2035[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1584 (Glob (None, 16)           0           dropout_2036[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1585 (Glob (None, 16)           0           dropout_2037[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1586 (Glob (None, 16)           0           dropout_2038[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1587 (Glob (None, 16)           0           dropout_2039[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1588 (Glob (None, 16)           0           dropout_2040[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1589 (Glob (None, 16)           0           dropout_2041[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1590 (Glob (None, 16)           0           dropout_2042[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1591 (Glob (None, 16)           0           dropout_2043[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1592 (Glob (None, 16)           0           dropout_2044[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1593 (Glob (None, 16)           0           dropout_2045[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1594 (Glob (None, 16)           0           dropout_2046[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1595 (Glob (None, 16)           0           dropout_2047[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1596 (Glob (None, 16)           0           dropout_2048[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1597 (Glob (None, 16)           0           dropout_2049[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling3d_1598 (Glob (None, 16)           0           dropout_2050[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 1296)         0           global_max_pooling3d_1518[0][0]  \n",
            "                                                                 global_max_pooling3d_1519[0][0]  \n",
            "                                                                 global_max_pooling3d_1520[0][0]  \n",
            "                                                                 global_max_pooling3d_1521[0][0]  \n",
            "                                                                 global_max_pooling3d_1522[0][0]  \n",
            "                                                                 global_max_pooling3d_1523[0][0]  \n",
            "                                                                 global_max_pooling3d_1524[0][0]  \n",
            "                                                                 global_max_pooling3d_1525[0][0]  \n",
            "                                                                 global_max_pooling3d_1526[0][0]  \n",
            "                                                                 global_max_pooling3d_1527[0][0]  \n",
            "                                                                 global_max_pooling3d_1528[0][0]  \n",
            "                                                                 global_max_pooling3d_1529[0][0]  \n",
            "                                                                 global_max_pooling3d_1530[0][0]  \n",
            "                                                                 global_max_pooling3d_1531[0][0]  \n",
            "                                                                 global_max_pooling3d_1532[0][0]  \n",
            "                                                                 global_max_pooling3d_1533[0][0]  \n",
            "                                                                 global_max_pooling3d_1534[0][0]  \n",
            "                                                                 global_max_pooling3d_1535[0][0]  \n",
            "                                                                 global_max_pooling3d_1536[0][0]  \n",
            "                                                                 global_max_pooling3d_1537[0][0]  \n",
            "                                                                 global_max_pooling3d_1538[0][0]  \n",
            "                                                                 global_max_pooling3d_1539[0][0]  \n",
            "                                                                 global_max_pooling3d_1540[0][0]  \n",
            "                                                                 global_max_pooling3d_1541[0][0]  \n",
            "                                                                 global_max_pooling3d_1542[0][0]  \n",
            "                                                                 global_max_pooling3d_1543[0][0]  \n",
            "                                                                 global_max_pooling3d_1544[0][0]  \n",
            "                                                                 global_max_pooling3d_1545[0][0]  \n",
            "                                                                 global_max_pooling3d_1546[0][0]  \n",
            "                                                                 global_max_pooling3d_1547[0][0]  \n",
            "                                                                 global_max_pooling3d_1548[0][0]  \n",
            "                                                                 global_max_pooling3d_1549[0][0]  \n",
            "                                                                 global_max_pooling3d_1550[0][0]  \n",
            "                                                                 global_max_pooling3d_1551[0][0]  \n",
            "                                                                 global_max_pooling3d_1552[0][0]  \n",
            "                                                                 global_max_pooling3d_1553[0][0]  \n",
            "                                                                 global_max_pooling3d_1554[0][0]  \n",
            "                                                                 global_max_pooling3d_1555[0][0]  \n",
            "                                                                 global_max_pooling3d_1556[0][0]  \n",
            "                                                                 global_max_pooling3d_1557[0][0]  \n",
            "                                                                 global_max_pooling3d_1558[0][0]  \n",
            "                                                                 global_max_pooling3d_1559[0][0]  \n",
            "                                                                 global_max_pooling3d_1560[0][0]  \n",
            "                                                                 global_max_pooling3d_1561[0][0]  \n",
            "                                                                 global_max_pooling3d_1562[0][0]  \n",
            "                                                                 global_max_pooling3d_1563[0][0]  \n",
            "                                                                 global_max_pooling3d_1564[0][0]  \n",
            "                                                                 global_max_pooling3d_1565[0][0]  \n",
            "                                                                 global_max_pooling3d_1566[0][0]  \n",
            "                                                                 global_max_pooling3d_1567[0][0]  \n",
            "                                                                 global_max_pooling3d_1568[0][0]  \n",
            "                                                                 global_max_pooling3d_1569[0][0]  \n",
            "                                                                 global_max_pooling3d_1570[0][0]  \n",
            "                                                                 global_max_pooling3d_1571[0][0]  \n",
            "                                                                 global_max_pooling3d_1572[0][0]  \n",
            "                                                                 global_max_pooling3d_1573[0][0]  \n",
            "                                                                 global_max_pooling3d_1574[0][0]  \n",
            "                                                                 global_max_pooling3d_1575[0][0]  \n",
            "                                                                 global_max_pooling3d_1576[0][0]  \n",
            "                                                                 global_max_pooling3d_1577[0][0]  \n",
            "                                                                 global_max_pooling3d_1578[0][0]  \n",
            "                                                                 global_max_pooling3d_1579[0][0]  \n",
            "                                                                 global_max_pooling3d_1580[0][0]  \n",
            "                                                                 global_max_pooling3d_1581[0][0]  \n",
            "                                                                 global_max_pooling3d_1582[0][0]  \n",
            "                                                                 global_max_pooling3d_1583[0][0]  \n",
            "                                                                 global_max_pooling3d_1584[0][0]  \n",
            "                                                                 global_max_pooling3d_1585[0][0]  \n",
            "                                                                 global_max_pooling3d_1586[0][0]  \n",
            "                                                                 global_max_pooling3d_1587[0][0]  \n",
            "                                                                 global_max_pooling3d_1588[0][0]  \n",
            "                                                                 global_max_pooling3d_1589[0][0]  \n",
            "                                                                 global_max_pooling3d_1590[0][0]  \n",
            "                                                                 global_max_pooling3d_1591[0][0]  \n",
            "                                                                 global_max_pooling3d_1592[0][0]  \n",
            "                                                                 global_max_pooling3d_1593[0][0]  \n",
            "                                                                 global_max_pooling3d_1594[0][0]  \n",
            "                                                                 global_max_pooling3d_1595[0][0]  \n",
            "                                                                 global_max_pooling3d_1596[0][0]  \n",
            "                                                                 global_max_pooling3d_1597[0][0]  \n",
            "                                                                 global_max_pooling3d_1598[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "dense_104 (Dense)               (None, 512)          664064      concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_105 (Dense)               (None, 512)          262656      dense_104[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_106 (Dense)               (None, 512)          262656      dense_105[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_107 (Dense)               (None, 1)            513         dense_106[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,226,177\n",
            "Trainable params: 1,226,177\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - 14s 1s/step - loss: 99.3202 - accuracy: 0.5181 - val_loss: 93.6610 - val_accuracy: 0.2308\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 93.66096, saving model to ./mod6.h5\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 91.8372 - accuracy: 0.5060 - val_loss: 86.3237 - val_accuracy: 0.2308\n",
            "\n",
            "Epoch 00002: val_loss improved from 93.66096 to 86.32366, saving model to ./mod6.h5\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 84.7048 - accuracy: 0.5422 - val_loss: 79.5640 - val_accuracy: 0.2308\n",
            "\n",
            "Epoch 00003: val_loss improved from 86.32366 to 79.56400, saving model to ./mod6.h5\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 77.9139 - accuracy: 0.5422 - val_loss: 72.8820 - val_accuracy: 0.2308\n",
            "\n",
            "Epoch 00004: val_loss improved from 79.56400 to 72.88203, saving model to ./mod6.h5\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 71.4001 - accuracy: 0.4940 - val_loss: 66.6196 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00005: val_loss improved from 72.88203 to 66.61961, saving model to ./mod6.h5\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 65.2090 - accuracy: 0.6386 - val_loss: 60.7270 - val_accuracy: 0.2308\n",
            "\n",
            "Epoch 00006: val_loss improved from 66.61961 to 60.72697, saving model to ./mod6.h5\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 59.3177 - accuracy: 0.5422 - val_loss: 55.0141 - val_accuracy: 0.2308\n",
            "\n",
            "Epoch 00007: val_loss improved from 60.72697 to 55.01412, saving model to ./mod6.h5\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 53.6899 - accuracy: 0.5422 - val_loss: 49.5867 - val_accuracy: 0.2308\n",
            "\n",
            "Epoch 00008: val_loss improved from 55.01412 to 49.58673, saving model to ./mod6.h5\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 48.3554 - accuracy: 0.6988 - val_loss: 44.4354 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00009: val_loss improved from 49.58673 to 44.43538, saving model to ./mod6.h5\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 43.3265 - accuracy: 0.4940 - val_loss: 39.6504 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00010: val_loss improved from 44.43538 to 39.65042, saving model to ./mod6.h5\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 38.5503 - accuracy: 0.5542 - val_loss: 35.1800 - val_accuracy: 0.2308\n",
            "\n",
            "Epoch 00011: val_loss improved from 39.65042 to 35.17996, saving model to ./mod6.h5\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 34.1031 - accuracy: 0.5422 - val_loss: 30.8796 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00012: val_loss improved from 35.17996 to 30.87962, saving model to ./mod6.h5\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 29.9236 - accuracy: 0.4940 - val_loss: 26.8734 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00013: val_loss improved from 30.87962 to 26.87341, saving model to ./mod6.h5\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 26.0231 - accuracy: 0.6867 - val_loss: 23.3334 - val_accuracy: 0.2308\n",
            "\n",
            "Epoch 00014: val_loss improved from 26.87341 to 23.33342, saving model to ./mod6.h5\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 22.4758 - accuracy: 0.5422 - val_loss: 19.9772 - val_accuracy: 0.2308\n",
            "\n",
            "Epoch 00015: val_loss improved from 23.33342 to 19.97717, saving model to ./mod6.h5\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 19.1438 - accuracy: 0.5663 - val_loss: 16.7693 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00016: val_loss improved from 19.97717 to 16.76932, saving model to ./mod6.h5\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 16.1240 - accuracy: 0.6747 - val_loss: 13.9978 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00017: val_loss improved from 16.76932 to 13.99783, saving model to ./mod6.h5\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 13.4341 - accuracy: 0.4940 - val_loss: 11.5233 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00018: val_loss improved from 13.99783 to 11.52330, saving model to ./mod6.h5\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 11.0164 - accuracy: 0.7590 - val_loss: 9.3676 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00019: val_loss improved from 11.52330 to 9.36761, saving model to ./mod6.h5\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 8.8994 - accuracy: 0.7952 - val_loss: 7.4985 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00020: val_loss improved from 9.36761 to 7.49849, saving model to ./mod6.h5\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 7.1006 - accuracy: 0.8313 - val_loss: 5.9301 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00021: val_loss improved from 7.49849 to 5.93010, saving model to ./mod6.h5\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 5.5908 - accuracy: 0.7590 - val_loss: 4.7081 - val_accuracy: 0.3077\n",
            "\n",
            "Epoch 00022: val_loss improved from 5.93010 to 4.70807, saving model to ./mod6.h5\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 4.4077 - accuracy: 0.5783 - val_loss: 3.6842 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00023: val_loss improved from 4.70807 to 3.68415, saving model to ./mod6.h5\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 3.4859 - accuracy: 0.7470 - val_loss: 3.0835 - val_accuracy: 0.3077\n",
            "\n",
            "Epoch 00024: val_loss improved from 3.68415 to 3.08354, saving model to ./mod6.h5\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 2.9290 - accuracy: 0.5422 - val_loss: 2.7019 - val_accuracy: 0.3077\n",
            "\n",
            "Epoch 00025: val_loss improved from 3.08354 to 2.70194, saving model to ./mod6.h5\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 2.6100 - accuracy: 0.6747 - val_loss: 2.4885 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00026: val_loss improved from 2.70194 to 2.48850, saving model to ./mod6.h5\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 2.4229 - accuracy: 0.8675 - val_loss: 2.3315 - val_accuracy: 0.4615\n",
            "\n",
            "Epoch 00027: val_loss improved from 2.48850 to 2.33152, saving model to ./mod6.h5\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 2.2076 - accuracy: 0.5904 - val_loss: 1.9584 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00028: val_loss improved from 2.33152 to 1.95837, saving model to ./mod6.h5\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 1.9366 - accuracy: 0.6506 - val_loss: 1.7041 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.95837 to 1.70410, saving model to ./mod6.h5\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 1.6390 - accuracy: 0.8795 - val_loss: 1.6178 - val_accuracy: 0.5385\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.70410 to 1.61784, saving model to ./mod6.h5\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.5454 - accuracy: 0.6024 - val_loss: 1.4392 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00031: val_loss improved from 1.61784 to 1.43920, saving model to ./mod6.h5\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 1.4037 - accuracy: 0.8554 - val_loss: 1.3644 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00032: val_loss improved from 1.43920 to 1.36439, saving model to ./mod6.h5\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 1.2832 - accuracy: 0.8434 - val_loss: 1.2309 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00033: val_loss improved from 1.36439 to 1.23087, saving model to ./mod6.h5\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 1.1642 - accuracy: 0.8193 - val_loss: 1.1179 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00034: val_loss improved from 1.23087 to 1.11786, saving model to ./mod6.h5\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.1615 - accuracy: 0.6747 - val_loss: 1.5369 - val_accuracy: 0.2308\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.11786\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 1.4561 - accuracy: 0.5542 - val_loss: 1.0602 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00036: val_loss improved from 1.11786 to 1.06016, saving model to ./mod6.h5\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 1.1854 - accuracy: 0.5904 - val_loss: 1.0734 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.06016\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 1.1035 - accuracy: 0.8313 - val_loss: 1.0968 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.06016\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 1.0434 - accuracy: 0.8193 - val_loss: 0.9749 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00039: val_loss improved from 1.06016 to 0.97490, saving model to ./mod6.h5\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.0530 - accuracy: 0.6627 - val_loss: 1.0057 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.97490\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.9768 - accuracy: 0.7952 - val_loss: 0.8820 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.97490 to 0.88198, saving model to ./mod6.h5\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.9801 - accuracy: 0.7470 - val_loss: 0.8841 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.88198\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.8437 - accuracy: 0.8675 - val_loss: 0.7975 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.88198 to 0.79752, saving model to ./mod6.h5\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.8139 - accuracy: 0.8675 - val_loss: 0.8012 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.79752\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.7885 - accuracy: 0.8675 - val_loss: 0.7455 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.79752 to 0.74545, saving model to ./mod6.h5\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.7695 - accuracy: 0.8795 - val_loss: 0.7266 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.74545 to 0.72663, saving model to ./mod6.h5\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.7352 - accuracy: 0.9036 - val_loss: 0.7424 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.72663\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.6824 - accuracy: 0.9157 - val_loss: 0.6814 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.72663 to 0.68135, saving model to ./mod6.h5\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.7367 - accuracy: 0.9036 - val_loss: 0.6414 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.68135 to 0.64143, saving model to ./mod6.h5\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 1s 236ms/step - loss: 0.7074 - accuracy: 0.8554 - val_loss: 0.6333 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.64143 to 0.63326, saving model to ./mod6.h5\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.6081 - accuracy: 0.9277 - val_loss: 0.6168 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.63326 to 0.61678, saving model to ./mod6.h5\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.6061 - accuracy: 0.9277 - val_loss: 0.5990 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.61678 to 0.59895, saving model to ./mod6.h5\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.5809 - accuracy: 0.9759 - val_loss: 0.6011 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.59895\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.5651 - accuracy: 0.9518 - val_loss: 0.5808 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.59895 to 0.58081, saving model to ./mod6.h5\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.6024 - accuracy: 0.9518 - val_loss: 0.8316 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.58081\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 1.0064 - accuracy: 0.7711 - val_loss: 1.1186 - val_accuracy: 0.6154\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.58081\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 1.0316 - accuracy: 0.7470 - val_loss: 0.6795 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.58081\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.7141 - accuracy: 0.8434 - val_loss: 0.7882 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.58081\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.7296 - accuracy: 0.8916 - val_loss: 0.6736 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.58081\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.8037 - accuracy: 0.7831 - val_loss: 0.6715 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.58081\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.6341 - accuracy: 0.9157 - val_loss: 0.6147 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.58081\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.5836 - accuracy: 0.9639 - val_loss: 0.5992 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.58081\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.5733 - accuracy: 0.9639 - val_loss: 0.6064 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.58081\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.5583 - accuracy: 0.9518 - val_loss: 0.5890 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.58081\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.5543 - accuracy: 0.9639 - val_loss: 0.5688 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.58081 to 0.56879, saving model to ./mod6.h5\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.5337 - accuracy: 0.9639 - val_loss: 0.5514 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.56879 to 0.55141, saving model to ./mod6.h5\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.4978 - accuracy: 1.0000 - val_loss: 0.5412 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.55141 to 0.54121, saving model to ./mod6.h5\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.4850 - accuracy: 0.9880 - val_loss: 0.5404 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.54121 to 0.54045, saving model to ./mod6.h5\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.4986 - accuracy: 0.9880 - val_loss: 0.5336 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.54045 to 0.53364, saving model to ./mod6.h5\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.4789 - accuracy: 0.9880 - val_loss: 0.5209 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.53364 to 0.52093, saving model to ./mod6.h5\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.4650 - accuracy: 1.0000 - val_loss: 0.5158 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.52093 to 0.51576, saving model to ./mod6.h5\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.4757 - accuracy: 0.9639 - val_loss: 0.5557 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.51576\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 1s 264ms/step - loss: 0.5196 - accuracy: 0.9518 - val_loss: 0.6382 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.51576\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.5949 - accuracy: 0.9398 - val_loss: 0.5168 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.51576\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.4587 - accuracy: 1.0000 - val_loss: 0.5291 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.51576\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.4764 - accuracy: 0.9880 - val_loss: 0.5199 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.51576\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.4688 - accuracy: 1.0000 - val_loss: 0.5016 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.51576 to 0.50161, saving model to ./mod6.h5\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.4537 - accuracy: 0.9880 - val_loss: 0.5138 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.50161\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.4905 - accuracy: 0.9759 - val_loss: 0.5488 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.50161\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.4940 - accuracy: 0.9518 - val_loss: 0.5195 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.50161\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.4983 - accuracy: 0.9759 - val_loss: 0.5001 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.50161 to 0.50006, saving model to ./mod6.h5\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.4811 - accuracy: 0.9759 - val_loss: 0.5326 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.50006\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 1s 265ms/step - loss: 0.4772 - accuracy: 0.9880 - val_loss: 0.5284 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.50006\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.4700 - accuracy: 0.9639 - val_loss: 0.5474 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.50006\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.4967 - accuracy: 0.9639 - val_loss: 0.5078 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.50006\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.4735 - accuracy: 0.9759 - val_loss: 0.4963 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00086: val_loss improved from 0.50006 to 0.49634, saving model to ./mod6.h5\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.4501 - accuracy: 1.0000 - val_loss: 0.4753 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.49634 to 0.47527, saving model to ./mod6.h5\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 1s 261ms/step - loss: 0.4498 - accuracy: 1.0000 - val_loss: 0.5354 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.47527\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 1s 272ms/step - loss: 0.5089 - accuracy: 0.9759 - val_loss: 0.5186 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.47527\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 1s 270ms/step - loss: 0.4948 - accuracy: 0.9398 - val_loss: 0.4943 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.47527\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.4686 - accuracy: 0.9639 - val_loss: 0.4809 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.47527\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.4739 - accuracy: 0.9639 - val_loss: 0.4768 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.47527\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.4687 - accuracy: 0.9759 - val_loss: 0.4734 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00093: val_loss improved from 0.47527 to 0.47344, saving model to ./mod6.h5\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.4503 - accuracy: 0.9759 - val_loss: 0.5687 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.47344\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.9291 - accuracy: 0.7349 - val_loss: 1.6413 - val_accuracy: 0.3846\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.47344\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 1.7941 - accuracy: 0.6145 - val_loss: 0.6063 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.47344\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 1.1768 - accuracy: 0.7108 - val_loss: 0.6433 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.47344\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.6889 - accuracy: 0.8916 - val_loss: 1.1993 - val_accuracy: 0.3846\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.47344\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 1.1771 - accuracy: 0.5542 - val_loss: 0.9751 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.47344\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 1s 239ms/step - loss: 0.8788 - accuracy: 0.7711 - val_loss: 0.8204 - val_accuracy: 0.7692\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.47344\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.9091 - accuracy: 0.6867 - val_loss: 0.7788 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.47344\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.7326 - accuracy: 0.9759 - val_loss: 0.7612 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.47344\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 1s 246ms/step - loss: 0.6955 - accuracy: 0.8916 - val_loss: 0.6978 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.47344\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.6286 - accuracy: 1.0000 - val_loss: 0.6407 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.47344\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.5651 - accuracy: 0.9759 - val_loss: 0.5947 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.47344\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.5430 - accuracy: 0.9639 - val_loss: 0.5926 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.47344\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.4882 - accuracy: 1.0000 - val_loss: 0.5454 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.47344\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 1s 285ms/step - loss: 0.4711 - accuracy: 1.0000 - val_loss: 0.5419 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.47344\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.4626 - accuracy: 1.0000 - val_loss: 0.5396 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.47344\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.4511 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.47344\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.4538 - accuracy: 1.0000 - val_loss: 0.5329 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.47344\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.4370 - accuracy: 1.0000 - val_loss: 0.4972 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.47344\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 1s 255ms/step - loss: 0.4253 - accuracy: 1.0000 - val_loss: 0.4809 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.47344\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.4246 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.47344\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.4253 - accuracy: 1.0000 - val_loss: 0.4949 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.47344\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.4124 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00116: val_loss improved from 0.47344 to 0.47329, saving model to ./mod6.h5\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.4125 - accuracy: 1.0000 - val_loss: 0.4895 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.47329\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.4099 - accuracy: 1.0000 - val_loss: 0.4697 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00118: val_loss improved from 0.47329 to 0.46975, saving model to ./mod6.h5\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.4058 - accuracy: 1.0000 - val_loss: 0.4540 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00119: val_loss improved from 0.46975 to 0.45396, saving model to ./mod6.h5\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.4132 - accuracy: 1.0000 - val_loss: 0.4747 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.45396\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.4097 - accuracy: 1.0000 - val_loss: 0.4586 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.45396\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.4040 - accuracy: 1.0000 - val_loss: 0.4509 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00122: val_loss improved from 0.45396 to 0.45088, saving model to ./mod6.h5\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.4074 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.45088\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.4066 - accuracy: 1.0000 - val_loss: 0.4626 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.45088\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.4056 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00125: val_loss improved from 0.45088 to 0.44586, saving model to ./mod6.h5\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3996 - accuracy: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.44586\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.4111 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00127: val_loss improved from 0.44586 to 0.43905, saving model to ./mod6.h5\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.4072 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.43905\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3905 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.43905\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3901 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.43905\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3878 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00131: val_loss improved from 0.43905 to 0.43645, saving model to ./mod6.h5\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 1s 240ms/step - loss: 0.3873 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.43645\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3844 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.43645\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3818 - accuracy: 1.0000 - val_loss: 0.4469 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.43645\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3806 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00135: val_loss improved from 0.43645 to 0.43213, saving model to ./mod6.h5\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.3812 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.43213\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3777 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.43213\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3772 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.43213\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3790 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00139: val_loss improved from 0.43213 to 0.43172, saving model to ./mod6.h5\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3790 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.43172\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 1s 266ms/step - loss: 0.3798 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.43172\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.3791 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00142: val_loss improved from 0.43172 to 0.43054, saving model to ./mod6.h5\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3764 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.43054\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 1s 259ms/step - loss: 0.3750 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.43054\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3743 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.43054\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3734 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.43054\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3791 - accuracy: 1.0000 - val_loss: 0.4670 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.43054\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3782 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.43054\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3729 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00149: val_loss improved from 0.43054 to 0.42812, saving model to ./mod6.h5\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3709 - accuracy: 1.0000 - val_loss: 0.4454 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.42812\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3764 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.42812\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3738 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.42812\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3708 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.42812\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3679 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.42812\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.3721 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.42812\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3652 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.42812\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 1s 244ms/step - loss: 0.3701 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.42812\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3694 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.42812\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 1s 257ms/step - loss: 0.3683 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.42812\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3661 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00160: val_loss improved from 0.42812 to 0.42605, saving model to ./mod6.h5\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3638 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.42605\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3665 - accuracy: 1.0000 - val_loss: 0.4429 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.42605\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.3700 - accuracy: 1.0000 - val_loss: 0.4206 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00163: val_loss improved from 0.42605 to 0.42061, saving model to ./mod6.h5\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.3661 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.42061\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3730 - accuracy: 1.0000 - val_loss: 0.4582 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.42061\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3707 - accuracy: 1.0000 - val_loss: 0.4334 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.42061\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.3661 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00167: val_loss improved from 0.42061 to 0.41502, saving model to ./mod6.h5\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 1s 263ms/step - loss: 0.3686 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.41502\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.3655 - accuracy: 1.0000 - val_loss: 0.4360 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.41502\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.3664 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.41502\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3663 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.41502\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 1s 243ms/step - loss: 0.3629 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.41502\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.3610 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00173: val_loss improved from 0.41502 to 0.41425, saving model to ./mod6.h5\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3622 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.41425\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 1s 262ms/step - loss: 0.3623 - accuracy: 1.0000 - val_loss: 0.4556 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00175: val_loss did not improve from 0.41425\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3646 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.41425\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3598 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00177: val_loss improved from 0.41425 to 0.41332, saving model to ./mod6.h5\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3628 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.41332\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3647 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.41332\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3570 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.41332\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 1s 245ms/step - loss: 0.3636 - accuracy: 1.0000 - val_loss: 0.4392 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.41332\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3597 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.41332\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3573 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00183: val_loss improved from 0.41332 to 0.41139, saving model to ./mod6.h5\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 1s 254ms/step - loss: 0.3588 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.41139\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 1s 242ms/step - loss: 0.3578 - accuracy: 1.0000 - val_loss: 0.4218 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.41139\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3585 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.41139\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 1s 249ms/step - loss: 0.3568 - accuracy: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.9231\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.41139\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3542 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.41139\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 1s 253ms/step - loss: 0.3580 - accuracy: 1.0000 - val_loss: 0.4190 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.41139\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 1s 248ms/step - loss: 0.3570 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.41139\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3565 - accuracy: 1.0000 - val_loss: 0.4252 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.41139\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 1s 252ms/step - loss: 0.3568 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.41139\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 1s 247ms/step - loss: 0.3544 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.41139\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 1s 256ms/step - loss: 0.3540 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.41139\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 1s 251ms/step - loss: 0.3558 - accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.41139\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.3515 - accuracy: 1.0000 - val_loss: 0.4143 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.41139\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 1s 258ms/step - loss: 0.3554 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.41139\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 1s 241ms/step - loss: 0.3546 - accuracy: 1.0000 - val_loss: 0.4184 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.41139\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 1s 250ms/step - loss: 0.3557 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.41139\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 1s 260ms/step - loss: 0.3521 - accuracy: 1.0000 - val_loss: 0.4183 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.41139\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 30ms/step - loss: 0.3866 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.7022 - accuracy: 0.8400\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4114 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvVEPB4XHLzU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KeWBKywEp6Ub",
        "outputId": "fb4e254c-6682-41d7-cec8-79153311538b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(7):\n",
        "  y_test_pred=load_model(f'./mod{i}.h5')\n",
        "  y_test_pred=y_test_pred.predict(x_test)\n",
        "\n",
        "  y_pred=y_test_pred.flatten()\n",
        "\n",
        "  y_test_pred=np.where(y_pred<0.5, 0,1)\n",
        "\n",
        "  c_matrix=confusion_matrix(y_test,y_test_pred)\n",
        "  ax=sns.heatmap(c_matrix,annot=True, xticklabels=['No ADHD','ADHD'],yticklabels=['No ADHD','ADHD'],cbar=False,cmap='Blues')\n",
        "  ax.set_xlabel('Prediction')\n",
        "  ax.set_ylabel('Actual')\n",
        "  plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f0102859e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f010341f0e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}